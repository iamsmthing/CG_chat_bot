{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9710fabb24fc46ea88b8fd0b6d1d70ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_31c5d52e42f44765966d3887096c188d",
            "placeholder": "Please enter your question:",
            "style": "IPY_MODEL_2418d3ce00e14ded9fb638f2543a080a",
            "value": ""
          }
        },
        "31c5d52e42f44765966d3887096c188d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2418d3ce00e14ded9fb638f2543a080a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aee538b285de44e89f54a94cdbdab4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_480f99cb7d49496e8b81f475260671bd",
            "placeholder": "​",
            "style": "IPY_MODEL_c48355fd1d9b4e9987f17cc2044a6878",
            "value": "<b>User:</b> Hi There :)"
          }
        },
        "480f99cb7d49496e8b81f475260671bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48355fd1d9b4e9987f17cc2044a6878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4facdd7fe5c844a2803bca9dff469236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9bce55f5b34927bf21d6c3c6ccc82b",
            "placeholder": "​",
            "style": "IPY_MODEL_f3ae760cfff54873b3dae77f6b6aa064",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Hello! I am the CG assistant. How can I assist you with CG Infinity today?"
          }
        },
        "fd9bce55f5b34927bf21d6c3c6ccc82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ae760cfff54873b3dae77f6b6aa064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec3e8202c3294f49bbe2c9c47026f215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae3b09c8c174083abe98c19d789ea20",
            "placeholder": "​",
            "style": "IPY_MODEL_c5d558388b184f40bbe8d044dd9c2e7d",
            "value": "<b>User:</b> What are the things you can help me with?"
          }
        },
        "bae3b09c8c174083abe98c19d789ea20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d558388b184f40bbe8d044dd9c2e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc7f520d516d4f749de894b400d68310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7843c43275da4919ba30d8b17300fad9",
            "placeholder": "​",
            "style": "IPY_MODEL_6d3ce767da27441391a05a4434cdc3cb",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> As a CG assistant, I can assist you with any questions or concerns you have related to CG Infinity. If you have any specific questions or topics in mind, feel free to ask and I'll do my best to provide you with the information you need."
          }
        },
        "7843c43275da4919ba30d8b17300fad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d3ce767da27441391a05a4434cdc3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "334934d764dc40bb99c27eff21872f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba1ed6a218c49f18f52bb709dff02c0",
            "placeholder": "​",
            "style": "IPY_MODEL_8614c9d285d8422faae4bd38eb6d1350",
            "value": "<b>User:</b> I think you can help me then."
          }
        },
        "bba1ed6a218c49f18f52bb709dff02c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8614c9d285d8422faae4bd38eb6d1350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c679226b251440c90c4f4c3ec207eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4f09ef538047ed87ccb455f0037de0",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0b4f62007f4d70938b0586e803d25c",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Of course! As a CG assistant, I am here to help with any questions or concerns you have related to CG Infinity. What can I assist you with today?"
          }
        },
        "db4f09ef538047ed87ccb455f0037de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0b4f62007f4d70938b0586e803d25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05b4b21c16294651a03c42531bca7d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c67a9e92ff4d4cb5c9e5cab10ecef4",
            "placeholder": "​",
            "style": "IPY_MODEL_36f57bbdd5284add9c59098984150053",
            "value": "<b>User:</b> Tell me about Mike Parish and Mrugank"
          }
        },
        "49c67a9e92ff4d4cb5c9e5cab10ecef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f57bbdd5284add9c59098984150053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b61d368959a48cba20494eef86a1c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f953d3021fb45d4b064bf9ff534adf8",
            "placeholder": "​",
            "style": "IPY_MODEL_2a522764f78b4f9e9b27ba9cc303fe13",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Mike Parish is the Vice President of Customer Experience at CG Infinity. He has over 10 years of experience in developing and deploying innovative system and automation-based solutions for maximum ROI and streamlining of business processes. Mrugank Dalal is one of the Principals at CG Infinity with over 12 years of software technology consulting experience. He excels in marketing technologies and provides automation solutions for customer retention, acquisition, digital communication, customer satisfaction, and social media marketing."
          }
        },
        "8f953d3021fb45d4b064bf9ff534adf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a522764f78b4f9e9b27ba9cc303fe13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01848f350adb466196d32b4afb5cefdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acdf2d6e3198414d94b5f6b3233488a0",
            "placeholder": "​",
            "style": "IPY_MODEL_e885fdaad7a348a18ecc9c742cdb21d7",
            "value": "<b>User:</b> Tell me their designations."
          }
        },
        "acdf2d6e3198414d94b5f6b3233488a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e885fdaad7a348a18ecc9c742cdb21d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8992b2250924825a62796dff621df57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04ad49268412445bb37418fed8b82804",
            "placeholder": "​",
            "style": "IPY_MODEL_84678d7d815545558547eb8e04098d7d",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Mike Parish is the Vice President of Customer Experience at CG Infinity and Mrugank Dalal is one of the Principals at CG Infinity."
          }
        },
        "04ad49268412445bb37418fed8b82804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84678d7d815545558547eb8e04098d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eb190a37fe540da962eef95965c1876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcefa9991d804df7a5a2bdf47f074715",
            "placeholder": "​",
            "style": "IPY_MODEL_0509758d00a7486783f85a91c58079b3",
            "value": "<b>User:</b> I think both are leading the team in this company."
          }
        },
        "bcefa9991d804df7a5a2bdf47f074715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0509758d00a7486783f85a91c58079b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69899c8789994524b1186b32ee9206d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_060ffdaf8d8741229ad1a0a05e91c2d4",
            "placeholder": "​",
            "style": "IPY_MODEL_2abfe10808c4451491a4cb6ac9498d18",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Mike Parish is the Vice President of Customer Experience at CG Infinity and Mrugank Dalal is one of the Principals at CG Infinity. They both hold important positions at the company and contribute to leading their respective teams."
          }
        },
        "060ffdaf8d8741229ad1a0a05e91c2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2abfe10808c4451491a4cb6ac9498d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5694a86a77c84da183ded9e488dd1bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e871b6ba1f49129b5da5ae39f4c8a8",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb60239a0164e5da75ee143bc86b093",
            "value": "<b>User:</b> Pretty amazing."
          }
        },
        "58e871b6ba1f49129b5da5ae39f4c8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb60239a0164e5da75ee143bc86b093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54735af1599b4cc1a7383d7027692772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b287ced5c64be7a69c3f8c7c723ff7",
            "placeholder": "​",
            "style": "IPY_MODEL_4e19b91926fc46f88e968d67df3a0f99",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Thank you for your feedback! We're glad to hear that you find our company's work pretty amazing. Is there anything specific you would like to know about CG Infinity or how we can assist you with our services?"
          }
        },
        "d8b287ced5c64be7a69c3f8c7c723ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e19b91926fc46f88e968d67df3a0f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "276762c68916448dbc759db3a98b5f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60c87d3a7e5240ffafef563a8abb1ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_1815b3a8dd364173b2a88e0faef503f0",
            "value": "<b>User:</b> Can you help me again? I forgot to ask one question."
          }
        },
        "60c87d3a7e5240ffafef563a8abb1ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1815b3a8dd364173b2a88e0faef503f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9519d1b821f647de8d30479f9c7a5aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6aef8d8d074a52ba6f2f0f582b1270",
            "placeholder": "​",
            "style": "IPY_MODEL_6abec72395f5489da2bb03b743e1a001",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Of course! I'm here to help. What would you like to know about CG Infinity or do you have any questions or concerns related to our services?"
          }
        },
        "7d6aef8d8d074a52ba6f2f0f582b1270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6abec72395f5489da2bb03b743e1a001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5eb46e9bc564175b3bd75e49c02efb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_557552419a404efd9b55bfded8395c66",
            "placeholder": "​",
            "style": "IPY_MODEL_63f05726654548be9ef7b0b53bc2982e",
            "value": "<b>User:</b> I heard that CG Infinity is pro in Salesforce Integration. Is it so?"
          }
        },
        "557552419a404efd9b55bfded8395c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f05726654548be9ef7b0b53bc2982e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "639f8251ab584923a8d476d890499e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa14df70ab94f71b2652bf297784cbc",
            "placeholder": "​",
            "style": "IPY_MODEL_071a2a802bbf4a7daa512faccc00399f",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Yes, that's correct! CG Infinity has a long and proven track record of success in building and implementing customer-focused retail energy platforms, including successful integration with Salesforce Energy and Utilities Cloud. They also use Amazon Connect, Salesforce Voice, and Mulesoft Integration to improve both data management and customer experience. Additionally, CG Infinity has been engaged for their expertise in Salesforce implementation and has helped clients with various implementations of other Salesforce products."
          }
        },
        "6aa14df70ab94f71b2652bf297784cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071a2a802bbf4a7daa512faccc00399f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe0de08e290f4b1ba2e8fe75012d5ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c9f825b3e024bcea20ed4ea33e96a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_357e032f699d4361876ea4a66941d8fe",
            "value": "<b>User:</b> Wow. Thats really really good. I mean really."
          }
        },
        "3c9f825b3e024bcea20ed4ea33e96a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357e032f699d4361876ea4a66941d8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "663015bb6a964408897b4832110922b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5484f88c3c03480196a2a2a58a2f4d09",
            "placeholder": "​",
            "style": "IPY_MODEL_6867456987de4c53b1709d4aa8146d3c",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> Thank you so much for your positive feedback! We're always striving to provide the best service possible to our clients and it's great to hear that our work is appreciated. Is there anything else I can assist you with regarding CG Infinity or our services?"
          }
        },
        "5484f88c3c03480196a2a2a58a2f4d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6867456987de4c53b1709d4aa8146d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931ccbde2fec4bda9d1cd5d754eff573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c606c7e05047b3891c1c14f3484907",
            "placeholder": "​",
            "style": "IPY_MODEL_a5a01cc52e524943be0e74705ba0c148",
            "value": "<b>User:</b> How your customers say about your work then?"
          }
        },
        "08c606c7e05047b3891c1c14f3484907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a01cc52e524943be0e74705ba0c148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a232ba1e22a43078ebaefc3abcd7145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ced82f7ba2614aebbd38b3260016f54a",
            "placeholder": "​",
            "style": "IPY_MODEL_4154e8886f504c13bd4031ab8558220a",
            "value": "<b><font color=\"blue\">Chatbot:</font></b> I'm sorry, but I'm not sure if I understand your question. Could you please clarify or provide more context? If you have any questions about CG Infinity or our services, I would be happy to assist you. Otherwise, you can also reach out to our email at info@cginfinity.com for more information. Thank you so much. Any other thing I can help you with?"
          }
        },
        "ced82f7ba2614aebbd38b3260016f54a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4154e8886f504c13bd4031ab8558220a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsmthing/cg_assist/blob/dev/Multiple_Files_Handled_Working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Installs, Imports and API Keys"
      ],
      "metadata": {
        "id": "Q24Y-g6h-Bg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FIRST!\n",
        "!pip install -q langchain==0.0.150 pypdf pandas matplotlib tiktoken textract transformers openai faiss-cpu\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import PromptTemplate\n",
        "from langchain.retrievers import TFIDFRetriever"
      ],
      "metadata": {
        "id": "gk2J2sYYjTkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59a5009-b005-4883-f220-f333a0ae736c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pdfplumber 0.9.0 requires pdfminer.six==20221105, but you have pdfminer-six 20191110 which is incompatible.\n",
            "yfinance 0.2.18 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets\n",
        "!pip install unstructured[local-inference] -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykviXzERrFq2",
        "outputId": "2c1595bb-1ccf-478f-e00e-13f42f23c044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.7)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.8)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.12.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.8.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2TokenizerFast\n",
        "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain,ConversationChain"
      ],
      "metadata": {
        "id": "l-uszlwN641q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "E2Buv5Y0uFr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Loading PDFs and chunking with LangChain"
      ],
      "metadata": {
        "id": "RLULMPXa-Hu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You MUST add your PDF to local files in this notebook (folder icon on left hand side of screen)\n",
        "\n",
        "loader = DirectoryLoader('./allFiles', glob=\"**/*.pdf\")\n",
        "# documents = loader.load()\n",
        "# print(documents)\n",
        "# Simple method - Split by pages\n",
        "# loader = PyPDFLoader(\"./CgBotTesting.pdf\")\n",
        "pages = loader.load()\n",
        "# print(pages[0])\n",
        "\n",
        "# loader = SimpleDirectoryReader('./').load_data()\n",
        "# index = GPTVectorStoreIndex.from_documents(documents)\n",
        "# text_splitter = CharacterTextSplitter(\n",
        "\n",
        "#             separator=\"\\n\",\n",
        "\n",
        "#             chunk_size=1000,\n",
        "\n",
        "#             chunk_overlap=200,\n",
        "\n",
        "#             length_function=len\n",
        "\n",
        "#         )\n",
        "\n",
        "# chunks = text_splitter.split_text(documents)\n",
        "\n",
        "# SKIP TO STEP 2 IF YOU'RE USING THIS METHOD\n",
        "# chunks = documents\n",
        "chunks = pages\n"
      ],
      "metadata": {
        "id": "KH546j3nkFwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result is many LangChain 'Documents' around 500 tokens or less (Recursive splitter sometimes allows more tokens to retain context)\n",
        "print(chunks)"
      ],
      "metadata": {
        "id": "KQ_gDkwep4q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac80dbd-93b6-4a8f-bd03-8e10caed8c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Implementation Partner Training: Day 1\\n\\nDallas, November 2022\\n\\nConfidential – Any use of this material without specific permission of OfferFit, Inc. is strictly prohibited\\n\\nNo speaking, only non-verbal communication!\\n\\nLine up by favorite ice cream brand\\n\\n– A to Z, Left to Right\\n\\nEnergizer Line up //\\n\\nLine up by days since your last 5+ day vacation\\n\\n– Most to least, left to right\\n\\nLine up by birthplace\\n\\n– West to East, Left to Right\\n\\n– Hawaii is the furthest west point on the globe\\n\\n– New Zealand is the furthest east point on the globe\\n\\nOfferFit – Confidential\\n\\n2\\n\\nDay 1\\n\\nOverview\\n\\n1a\\n\\nConfiguration & Launch (Exercise A)\\n\\n1b\\n\\nExercise B\\n\\n1c\\n\\nData and Features\\n\\n1d\\n\\nDay 2\\n\\nTable of Contents\\n\\nOfferFit’s Community of Bandits Approach\\n\\n2a\\n\\nUse Case Design\\n\\n2b\\n\\nUse Case Configuration\\n\\n2c\\n\\nData discovery & integration architecture\\n\\n2d\\n\\nReports and Insights\\n\\n2e\\n\\nDay 3\\n\\nTroubleshooting\\n\\n3a\\n\\nRoadmap and Q&A\\n\\n3b\\n\\nClosing\\n\\n3c\\n\\nOfferFit – Confidential\\n\\n3\\n\\nOfferFit accelerates the creation of knowledge\\n\\nTrial and error has always been the core of\\n\\nhuman progress.\\n\\nOfferFit automates experimentation using\\n\\nself-learning AI, making knowledge creation faster than ever before.\\n\\nOfferFit’s self-learning AI uses rich customer behavior data to tailor recommendations, then observes how customers react to those recommendations, and iteratively learns to target better recommendations to each customer.\\n\\nOfferFit – Confidential\\n\\n4\\n\\nImplementation Partners are the 1st teams to access OfferFit’s Portal OfferFit’s Portal is the GUI interface to interact with OfferFit’s Automated Experimentation Platform\\n\\nBenefits for Implementation Partners\\n\\n– Provides a leading new ML offering to clients with market leading capabilities\\n\\n– Provides an opportunity for Partners to provide strategic and integration consulting services to clients alongside\\n\\nOfferFit configurations\\n\\n– Allows access to OfferFit’s pipeline of enterprise clients considering automated experimentation\\n\\n– Significant ground floor influence on a powerful, developing product and experience\\n\\nBenefits for OfferFit\\n\\n– Enables OfferFit to focus on creating a best-in-class SaaS product\\n\\n– Provides clients with the integration and strategic consulting services they’ve needed but OfferFit does not offer\\n\\n– Provides increased leverage to configure OfferFit for more companies, sooner\\n\\nOfferFit – Confidential\\n\\n5\\n\\n1a\\n\\n1a\\n\\nOverview\\n\\nOfferFit – Confidential\\n\\n6\\n\\nOverview\\n\\nMany enterprises have unified their data These enterprises are looking to turn their unified data into decisions\\n\\nData Layer\\n\\nData Activation Layer\\n\\nExperimentation Layer\\n\\nExecution Layer\\n\\nCustomer data platform (CDP)\\n\\nOrchestration and activation systems\\n\\nData systems\\n\\n?\\n\\nNo existing product has established itself as a go-to solution for this need\\n\\nOfferFit – Confidential\\n\\n7\\n\\nOverview\\n\\nLifecycle marketers are frustrated with the slow pace of A/B testing Unified data significantly expands the number of experiments marketers can run\\n\\nTakes years to answer all questions\\n\\nCan’t address all levers (channel, timing, frequency, message, product, incentive, etc.)\\n\\nToo resource-intensive to test at microsegment level\\n\\nUnclear if results hold over time or in different contexts\\n\\nOfferFit – Confidential\\n\\n8\\n\\nOverview\\n\\nOfferFit enables continuous experimentation Daily customer-level recommendations continuously learn from customer interactions\\n\\nOfferFit\\n\\nFirst-party data (daily feed)\\n\\nCustomer-level recommendations (daily feed)\\n\\nWarehouse or CDP\\n\\nActivation platforms\\n\\nInteractions\\n\\nOffers\\n\\nIdentified customers\\n\\nOfferFit – Confidential\\n\\n9\\n\\nOverview\\n\\nEach client gets to design their experiment for maximum impact\\n\\nClients Select:\\n\\nSuccess Metric what is the business KPI you would like to maximize?\\n\\nOfferFit automatically experiments, discovering which customer-level choices maximize the success metric\\n\\nExperimentation dimensions what are the dimensions (e.g., offer, channel, timing, etc.) along which you’d like to test?\\n\\nOptions what are the choices available for each dimension\\n\\nOfferFit – Confidential\\n\\n10\\n\\nOverview\\n\\nBrinks Home personalizes contract renewal offers with OfferFit\\n\\nLiberty Latin America personalizes upsell offers with OfferFit\\n\\nTime\\n\\nTime\\n\\n11AM\\n\\nWednesday 2PM\\n\\n3PM\\n\\nThursday 9AM\\n\\n+ more\\n\\nSaturday 2PM\\n\\nPlan\\n\\nChannel\\n\\n+ more\\n\\n300 Megabytes\\n\\nPostal\\n\\n500 Megabytes\\n\\nSubject Line\\n\\nEmail\\n\\n+ more\\n\\nSubject Line\\n\\nMás velocidad, ¡exclusiva para ti!\\n\\nPhone call\\n\\nYour contract is about to expire\\n\\n¡Solo por hoy, incrementa tu velocidad y recibe $15 de descuento en tu próxima factura!\\n\\n▼ Reduce Your Rate Today\\n\\nCreative\\n\\n+ more\\n\\nFront yard security photo\\n\\nCall to action\\n\\nBackyard family photo\\n\\n+ more\\n\\nTerms\\n\\nCon un click aquí\\n\\n$5 monthly rate reduction\\n\\nClick aquí para obtener el beneficio\\n\\n+ more\\n\\nRate lock\\n\\nTerms\\n\\nFree doorbell camera\\n\\n+ more\\n\\n$15 one-time discount\\n\\n+ more\\n\\nNo discount\\n\\nOfferFit – Confidential\\n\\n11\\n\\nOverview\\n\\nOfferFit clients have seen significant business impact\\n\\nTop-3 US home security brand\\n\\nUplift in renewal offer profit impact\\n\\nAnnual benefit\\n\\n$5m\\n\\n200%\\n\\nParis-based electricity multinational\\n\\nAnnual benefit\\n\\nUplift in business line profit\\n\\n$3m\\n\\n25%\\n\\nUplift in revenue impact of upsells\\n\\nAnnual benefit\\n\\nLeading Latin American telco\\n\\n$1m\\n\\n120%\\n\\nOfferFit – Confidential\\n\\n12\\n\\nOverview\\n\\nOfferFit’s data pipeline Overview\\n\\nDetailed on next page\\n\\nValidate / Pre-process\\n\\nFeature Engineering\\n\\nData Asset 1\\n\\nUse Case 1\\n\\n360° view of the customer\\n\\nValidate / Pre-process\\n\\nFeature Engineering\\n\\nData Asset 2\\n\\nOne record per customer with a complete description\\n\\nUse Case 2\\n\\nValidate / Pre-process\\n\\nFeature Engineering\\n\\nData Asset 3\\n\\nOfferFit – Confidential\\n\\n13\\n\\nOverview\\n\\nOfferFit uses experimentation and rewards to learn optimal choices\\n\\nUse Case 1\\n\\nAgent 1: Offer\\n\\n360° view of the customer\\n\\nRecommendation sent to customer\\n\\nAgent 2: Channel\\n\\nOne record per customer with a complete description\\n\\nAgent Dimension N\\n\\nAgent 3: Time\\n\\nOfferFit – Confidential\\n\\n14\\n\\nOverview\\n\\nCharastics of a great first Use Case\\n\\nImpact\\n\\nEase of Implementation\\n\\n❏ High estimated financial & strategic value\\n\\n❏ Can start with one channel, preferably a digital one like email or app (then can add other channels later)\\n\\n❏ Confidence that the target business metric is “sensitive to the intervention” (i.e., the decisions the AI is making are able to impact the target metric)\\n\\n❏ Activation tools that the client has been using 3+\\n\\nmonths\\n\\n❏ At least one high-impact lever (compelling incentives or\\n\\n❏ Dedicated supporting personnel\\n\\npricing)\\n\\n❏ PM\\n\\n❏ Customer data provides sufficient features to\\n\\n❏ Data lead\\n\\npersonalize\\n\\n❏ Creative lead\\n\\n❏ Feedback loop is short (< 1 week)\\n\\n❏ Activation lead\\n\\nOfferFit – Confidential\\n\\n15\\n\\nOverview\\n\\nImplementation team roles and responsibilities Overview\\n\\nEngagement Manager\\n\\nData Engineer\\n\\nOwn all phases of OfferFit Use Case delivery working alongside data engineers and client executives, marketers and IT stakeholders\\n\\nCollaborate with client Analytics/BI teams on\\n\\nimplementations (Use Case definition, data integration, pipeline and ML model configuration, etc.)\\n\\nRun design session with client to decide on and\\n\\nDeeply understand client business needs and data to ensure the Use Case is optimizing for the correct solution\\n\\ndocument Use Case requirements and integration approach\\n\\nBuild relationships with key client stakeholders to\\n\\nCommunicate client needs to OfferFit’s product team\\n\\nensure timely project delivery\\n\\nWork closely with the OfferFit Customer Success team\\n\\nmember to run analyses on project health and deliverables\\n\\nCommunicate client needs to OfferFit’s product team\\n\\nOfferFit – Confidential\\n\\n16\\n\\n1b\\n\\n1b Configuration & Launch (Exercise A)\\n\\nOfferFit – Confidential\\n\\n17\\n\\nConfiguration & Launch (Exercise A)\\n\\nOverview Exercise A\\n\\nWelcome to the first hands-on portion of the training.\\n\\nThe goal of this session is to provide a simple introduction to the OfferFit product and key components within.\\n\\n– The aim is not to provide in-depth training and information on all of the components (this will come later in the\\n\\nweek).\\n\\n– Rather, the aim is to spend a couple of hours getting everyone’s hands dirty in the product so that things will\\n\\nseem a bit more familiar when the focus turns to the nuances and complexities of an implementation.\\n\\n– Each individual will create their own client and configure an example use case\\n\\nFollow the instructions in this document to begin learning about the Portal.\\n\\n– This exercise will skip over some more advanced functionality for the sake of simplicity.\\n\\n– Do not worry if there are tabs that are left blank, they will be used later in the training\\n\\nIf there are any questions or issues, don’t hesitate to flag someone down!\\n\\nOfferFit – Confidential\\n\\n18\\n\\nConfiguration & Launch (Exercise A)\\n\\nStructure of this training document Page background meaning and feedback\\n\\nConcepts, explanations, and documentation will be in black text on white/light grey background pages\\n\\nTasks and actions to take in the Portal will be in white text on purple background pages\\n\\nThroughout the week there is bound to be feedback related to the\\n\\nproduct, Portal, UI/UX, Training exercises, or other items.\\n\\nPlease fill out a feedback card either:\\n\\n– Digitally at go.OfferFit.ai/feedback\\n\\n– On the card sitting on each table\\n\\nAll fields are optional but the more detail provided the easier it\\n\\nwill be to incorporate, so please be specific!\\n\\nOfferFit – Confidential\\n\\n19\\n\\nConfiguration & Launch (Exercise A)\\n\\nScenario Exercise A\\n\\nDeliveryCo is an online delivery service that specializes in quick shipments of grocery store items directly to\\n\\nconsumers.\\n\\n– They have a website where customers can order various food items for delivery, and DeliveryCo tracks a few\\n\\nmetrics about the customer’s website visit for marketing purposes.\\n\\n– All of this information is provided to us by DeliveryCo (in-depth description in later sections).\\n\\nFor this limited engagement, DeliveryCo would like to improve their email marketing efficacy.\\n\\nThe objective is very straightforward:\\n\\n– They would like to optimize their emails (time of day, discount, featured item, etc.) to generate larger quantity\\n\\npurchases from their customers.\\n\\nThroughout this exercise, an OfferFit instance will be configured to help achieve DeliveryCo’s goals.\\n\\nOfferFit – Confidential\\n\\n20\\n\\nConfiguration & Launch (Exercise A)\\n\\nInitial Setup Create client\\n\\nLog into Portal.OfferFit.ai using your corporate email address\\n\\n– MFA will be enabled and you should set this up as you log in\\n\\nCreate a new client that matches the style of the screenshot posted to the\\n\\nright.\\n\\n\"N\" in the screenshot should be replaced with your first name\\n\\n– This will also help us to get you know you!\\n\\nOfferFit – Confidential\\n\\n21\\n\\nConfiguration & Launch (Exercise A)\\n\\nData Asset Inspection ● In OfferFit terminology, a “data asset” is just some dataset that OfferFit receives from a client.\\n\\n– Conceptually, this can be thought of as the rough equivalent of a table in a relational database.\\n\\n– So a data asset may contain information on customers, products, transactions, etc.\\n\\nThis exercise will be dealing with a single data asset (note, implementations typically have more than one data asset)\\n\\nTake some time to look through the asset provided on the next page. It contains a record of purchase transactions by\\n\\ncustomer.\\n\\nNote the following fields:\\n\\n– customer_identifier: The ID of the customer who made the purchase.\\n\\n– time_spent_on_page: The amount of time (in seconds) that the customer spent on the page before making the\\n\\npurchase.\\n\\n– purchase_item: The item that the customer purchased.\\n\\n– total_money_spent: The dollar amount of the purchase that the customer made.\\n\\n– used_discount_code: Whether or not the customer used a special discount code when making the purchase.\\n\\n– transaction_time: The timestamp of the purchase.\\n\\nOfferFit – Confidential\\n\\n22\\n\\nConfiguration & Launch (Exercise A)\\n\\nDownload the data asset for this exercise at: go.OfferFit.ai/assets\\n\\nNavigate to the Data & Features section.\\n\\nCreate a new data asset and call it “Transactions”\\n\\nUpload the sample file provided in the Upload Sample Data section.\\n\\nThe Customer Identifier Column field allows us to pinpoint the\\n\\nData Asset Creation\\n\\ncustomer_id that is contained within the dataset. In this case, that field is customer_identifier, so make that mapping.\\n\\nSimilarly, the Datetime Column allows us to identify which field in the\\n\\nasset represents the time component. In this example, it is the transaction_time, so input that value accordingly.\\n\\nYou can disregard the remaining fields and click Save.\\n\\nOfferFit – Confidential\\n\\n23\\n\\nConfiguration & Launch (Exercise A)\\n\\nFirst, on the Reports > Email Reports page, you should add\\n\\nData Asset Validation\\n\\nyour email to the Recipient(s) section of the Daily Validation Reports.\\n\\nNow, navigate back to your asset and enter the Validation\\n\\nOfferFit works by receiving data directly from clients.\\n\\nsection.\\n\\nSometimes, there can be issues with the client data that are completely outside of the implementation team’s control.\\n\\nVerify that all of the Field Type values look reasonable\\n\\ngiven what you know about the data.\\n\\n– There are ways of pre-populating with reasonable\\n\\n– In some cases, this could be as simple as the\\n\\ndefaults, but they should always be double-checked since the logic is not infallible.\\n\\nclient not actually sending the data they are supposed to send on a particular day.\\n\\nFor the customer_identifier field, add a Range validation that makes sure that the minimum value is 82176801 and the maximum value is 82176901.\\n\\n– Other times, there could be assumptions about the state of the data that are broken (e.g., a field that has always been a number is now text).\\n\\nOnce you are satisfied, click the Run Validation button at\\n\\nThis section allows the user to set information about what the data from the client should look like each day.\\n\\nthe top right.\\n\\n– This should launch the validation task, and you can\\n\\nsee the status of the task on the bottom left of the screen.\\n\\nIf the data deviates from what is set here, then a failure email will be dispatched so they can be investigated and the issue can be quickly resolved the issue (potentially with the help of the client).\\n\\nThis task should complete successfully. When it does, you should receive an email stating that validation passed.\\n\\nOfferFit – Confidential\\n\\n24\\n\\nConfiguration & Launch (Exercise A)\\n\\nNext, go to the Preprocessing section of the data asset.\\n\\nThis is where OfferFit takes the data from the cloud bucket and bring it\\n\\ninto its data warehouse for additional processing.\\n\\nThe Implementation team can also do a few other things.\\n\\n– For this exercise, please rename the total_money_spent field to\\n\\nData Asset Preprocessing\\n\\ndollars_spent.\\n\\n– Renaming allows us to increase clarity in cases where client field\\n\\nnames are vague or misleading.\\n\\nOne this is done, click the Run Sample Preprocessing button.\\n\\n– This should launch a task that eventually completes successfully.\\n\\nAfter that is done, you should be able to locate and select the Processed\\n\\nData button.\\n\\nClick on it to preview the data.\\n\\n– Notice that the field you renamed should be updated to reflect that\\n\\nnew name.\\n\\nOfferFit – Confidential\\n\\n25\\n\\nConfiguration & Launch (Exercise A)\\n\\nData Asset Data Joining & Transformation\\n\\nThis is an advanced feature that is not required for every setup.\\n\\nIt will be covered in detail in later exercises.\\n\\nOfferFit – Confidential\\n\\n26\\n\\nConfiguration & Launch (Exercise A)\\n\\nFeature engineering is arguably the most important part of any\\n\\nimplementation.\\n\\nIn general, you are unlikely to achieve a positive outcome in a ML project\\n\\nwithout good features.\\n\\nThis exercise will go into just some of the available functionality here.\\n\\nPlease compute the following features for the asset:\\n\\n– Count the number of purchases for each customer in the past 1000\\n\\ndays.\\n\\nData Asset Features\\n\\n– Using the Boolean operation, determine whether the customer used\\n\\na discount code at any point in the past 1000 days.\\n\\n– Using the Aggregation operation, compute the maximum amount that each customer has spent through a purchase in the past 1000 days.\\n\\nOnce this is done, click the Run Sample Features button to compute the\\n\\nconfigured features.\\n\\nAfter that executes successfully, select the Feature Preview button to see\\n\\nthe features that you just created for each customer.\\n\\nYou have completed pipeline setup! It is time to move on to Use Case\\n\\nconfiguration.\\n\\nOfferFit – Confidential\\n\\n27\\n\\nConfiguration & Launch (Exercise A)\\n\\nCustomer Population\\n\\nIn OfferFit terms, a “customer population” is the set of customers that is\\n\\nReturn to the base Data &\\n\\nrelevant for the purposes of the data pipeline.\\n\\nFeatures section in the Portal and locate the Customer Population button.\\n\\nIf an individual customer is present within the customer population then\\n\\nfeatures will be created for them.\\n\\n– This is where you can determine which customers you want to calculate features for.\\n\\n– Otherwise, no features will be created for that specific customer.\\n\\nIt is important to remember that a single pipeline can support multiple\\n\\nUse Cases. So, if an initial Use Case idea involves only a specific subset of customers, it is sometimes wise to expand the customer population beyond just that subset in the event that the client wants to add another Use Case to the same pipeline in the future or expand the customer audience of an existing Use Case.\\n\\nClick on it and set Include all\\n\\ncustomers for the Transactions asset.\\n\\nOfferFit – Confidential\\n\\n28\\n\\nConfiguration & Launch (Exercise A)\\n\\nNow, find the Use Cases section in the top panel.\\n\\nCreate a new Use Case and call it “Training Use Case”.\\n\\nUse Case Creation\\n\\nNow, click on that Use Case. The remaining setup will be done within the\\n\\nUse Case that you just created.\\n\\nOfferFit – Confidential\\n\\n29\\n\\nConfiguration & Launch (Exercise A)\\n\\nUse Case Decision Dimensions\\n\\nDecision dimensions are a core OfferFit concept.\\n\\nGoing with this example, you\\n\\nneed to create two dimensions:\\n\\nEach dimension represents a particular area that the Agent is trying to\\n\\noptimize in the recommendation landscape.\\n\\nOffer (represents the email\\n\\nImagine a simple example Use Case where the client wants OfferFit to find the best email to send to each customer at the best time of day.\\n\\nand its contents)\\n\\nTime\\n\\n– In that case, there are two things the Agent needs to decide:\\n\\nClick and drag the created dimensions such that Offer sends its decision to Time (you’ll learn what this means later)\\n\\n– the optimal email.\\n\\n– the optimal time of day to send the email.\\n\\nOfferFit – Confidential\\n\\n30\\n\\nConfiguration & Launch (Exercise A)\\n\\nUse Case Action Banks\\n\\nEach action is assigned a set of values that are used to uniquely represent it.\\n\\nThese values, called “action parameters”, is how OfferFit is informed of the differences and similarities between the\\n\\nactions.\\n\\nThe actions in this example have the following parameters:\\n\\n– Message\\n\\nAction Parameter Description\\n\\naction_id\\n\\nThe unique identifier of this message action.\\n\\ndiscount\\n\\nThe percentage discount that the email is offering. It is represented as a decimal (e.g., 0.1).\\n\\nfood_subject\\n\\nThe FoodCo item that is being offered in the email (e.g., taco).\\n\\nword_count\\n\\nThe number of words contained in the email that FoodCo will send to their customer.\\n\\n– Time\\n\\nAction Parameter Description\\n\\naction_id\\n\\nThe unique identifier of this time action.\\n\\nhour\\n\\nThe hour of the day that the email will be sent at (e.g., 8, 12, 15, etc. - military time)\\n\\nOfferFit – Confidential\\n\\n31\\n\\nConfiguration & Launch (Exercise A)\\n\\nAction Banks\\n\\nIn the action bank section, various actions that the\\n\\nNavigate to the Action bank section in your Use\\n\\nAgent can suggest to personalize the recommendation to individual customers are defined.\\n\\nCase.\\n\\nThere are two ways to set up an action bank:\\n\\n– type everything in the UI\\n\\nIt’s worth noting that each action relates to a\\n\\nparticular dimension that was defined in the previous section. Thus:\\n\\n– upload an Excel file with the actions.\\n\\nThis file is provided here: go.OfferFit.ai/assets.\\n\\n– A “message” action might be “send email X” or\\n\\n– Spend a bit of time looking through this file,\\n\\n“send email Y”\\n\\nparticularly the “Instructions” page which goes into more detail on the format.\\n\\n– A “time” action might be “send at 8 AM” or\\n\\n“send at 12 PM”.\\n\\nChoose the Import from XLXS button and upload the\\n\\nfile to import the actions.\\n\\nOfferFit – Confidential\\n\\n32\\n\\nConfiguration & Launch (Exercise A)\\n\\nCustomer Groups Audience\\n\\nThe Customer population was set up previously\\n\\nNavigate to the Customer groups tab within your Use\\n\\nCase.\\n\\nThis is the set of all customers that OfferFit should to\\n\\nSelect the Filter audience button.\\n\\ncompute features for.\\n\\n– However, a single set of features can support\\n\\n– Here, imagine that the Use Case involves trying\\n\\nmultiple Use Cases, with different (overlapping or non-overlapping) audiences.\\n\\nto market to “dormant” customers.\\n\\n– In this case, “dormant” means that the customer have not made any purchases within the past 1000 days.\\n\\nAs a result, OfferFit needs a way to further filter\\n\\ndown the customer population to those eligible for the given Use Case.\\n\\nSet your audience to only include non-dormant customers since the client is already targeting dormant customers in a separate campaign.\\n\\nThis is called the Audience.\\n\\n– To do this, you can leverage the feature you\\n\\ncreated a few steps ago that calculates the total number of purchases for each customer in the past 1000 days.\\n\\nOfferFit – Confidential\\n\\n33\\n\\nConfiguration & Launch (Exercise A)\\n\\nCustomer Groups Control Groups\\n\\nOfferFit works by making recommendations that, over time, maximize the\\n\\nCreate a single control group that contains customer_ids that end with the letters “a”, “b”, “c”, “d” or “e”.\\n\\ntarget metric.\\n\\nTo demonstrate efficacy, a control group receives “business as usual”\\n\\ncommunications.\\n\\n– By doing this, customers that receive OfferFit recommendations can be compared to a business-as-usual baseline to calculate uplift.\\n\\nControl groups should typically be assigned at random.\\n\\nA common trick to do this is splitting the customers into control groups\\n\\naccording to the last N digits of the customer_id\\n\\n– The customer_id is almost always generated in a manner that is\\n\\n“random” for OfferFit’s purposes.\\n\\n– For example, if customers that end in 4 or 7 should be in the\\n\\ncontrol group, then roughly 20% of customers will be placed into that group (assuming the customer ID values are numbers).\\n\\nOfferFit – Confidential\\n\\n34\\n\\nConfiguration & Launch (Exercise A)\\n\\nGuardrails\\n\\nThis functionality allows us to implement eligibility constraints and\\n\\nFirst, this restriction applies to emails, so select the Offer dimension.\\n\\nbusiness rules specifying customers who can’t be recommended specific actions.\\n\\nFor this example, imagine that the company is concerned with the\\n\\nNow, create a new guardrail\\n\\npossibility of appearing to give a “lowball” offer to certain customers.\\n\\nand name it no_lowball_offers..\\n\\nSpecifically, if the customer has previously used a discount code, then\\n\\nImplement the logic described to the left.\\n\\nthe client might expect discounts in the future to be reasonably impactful.\\n\\nAs a result, the company does not want to offer discounts below 5% to\\n\\ncustomers who have previously used a discount code.\\n\\n– Note that whether a customer has used a discount code is a feature created earlier and the discount amount of the offer is an action parameter.\\n\\nOfferFit – Confidential\\n\\n35\\n\\nConfiguration & Launch (Exercise A)\\n\\nOutputs\\n\\nThis tab allows us to select which information to send to the customer\\n\\nSet up the outputs by\\n\\nwhen OfferFit sends the recommendations.\\n\\nselecting the action ID for both dimensions\\n\\nIt allows us to augment the output by adding features or action parameters in the file that OfferFit provides the customer.\\n\\nThis could be useful if the customer wants to do reporting or analysis on\\n\\nthe file directly.\\n\\n– Or, the customer may want us to send a specific key for each action (which is defined as an action parameter) that matches up with something in their system.\\n\\nImagine that the client is going to take the file OfferFit creates and feed it\\n\\ndirectly into their marketing system.\\n\\nThe identifiers in their system are directly aligned with the ones defined\\n\\nin the Actions.\\n\\nOfferFit – Confidential\\n\\n36\\n\\nLunch (60 min)\\n\\nFrom A/B To AI\\n\\nOfferFit – Confidential OfferFit – Confidential\\n\\n37 37\\n\\nForm two equal sized lines facing each other 2 feet apart.\\n\\nPlace one index finger from each hand on the pole in the middle of the\\n\\ntwo lines.\\n\\nEnergizer Lower the stick to the ground\\n\\nYour hands must be touching the pole at all times\\n\\nTogether lower the stick to the ground\\n\\nIf either finger loses contact with the pole the entire group must restart\\n\\nOfferFit – Confidential\\n\\n38\\n\\n1c\\n\\n1c\\n\\nExercise B\\n\\nOfferFit – Confidential\\n\\n39\\n\\nExercise B\\n\\nScenario Exercise B ● FoodCo is a small to midsize grocery chain that operates in the Southwestern United States.\\n\\nLike some other grocery store chains (e.g., Costco, Sam’s Club, etc.) they require at least a base level of membership to\\n\\nbe able to shop at their stores.\\n\\nFoodCo also has a large online presence, allowing customers to choose between in-store pickup, delivery, or “regular”\\n\\nshopping if they desire.\\n\\nIn terms of data, FoodCo is able to provide us with general information about their customers.\\n\\n– They also have data on each item bought by each customer at their various locations, along with specific\\n\\ninformation about each product they sell. In addition to this, their engineering team tracks and logs certain customer activity that occurs on their web site.\\n\\nFoodCo heard about OfferFit at a local marketing conference and is interested in trying it out. They would like to use\\n\\nOfferFit to be able to maximize the number of purchases made by their customers.\\n\\nThey hope that by sending out specific, targeted emails with different discounts on different items, they can entice\\n\\ncustomers to return to their store or website and purchase items more frequently.\\n\\nIn the past, FoodCo has done independent research to determine that quantity of unique transactions is the best\\n\\nindicator of customer lifetime value.\\n\\nThey are not particularly concerned with the quantity of items bought in each transaction or the price of the items in\\n\\nquestion; pure volume of unique shopping interactions is the metric with the most impact for them.\\n\\nOfferFit – Confidential\\n\\n40\\n\\nExercise B\\n\\nReminder: Structure of this training document Page background meaning and feedback\\n\\nConcepts, explanations, and documentation will be in black text on white/light grey background pages\\n\\nTasks and actions to take in the Portal will be in white text on purple background pages\\n\\nThroughout the week there is bound to be feedback related to the\\n\\nproduct, Portal, UI/UX, Training exercises, or other items.\\n\\nPlease fill out a feedback card either:\\n\\n– Digitally at go.OfferFit.ai/feedback\\n\\n– On the card sitting on each table\\n\\nAll fields are optional but the more detail provided the easier it\\n\\nwill be to incorporate so please be specific!\\n\\nOfferFit – Confidential\\n\\n41\\n\\nExercise B\\n\\nOverview and setup of client\\n\\n\\n\\nYou already know the client\\n\\nThere are three key components to the implementation architecture:\\n\\nin this case, FoodCo.\\n\\n–\\n\\nClient: A single enterprise company which has purchased OfferFit’s product\\n\\nUse your first name and\\n\\ncreate a client of the format food_co_myfirstname\\n\\n–\\n\\nPipeline: A set of data assets that OfferFit receives from a client that are all conceptually related and are used for creating features.\\n\\n–\\n\\nUse Case: A user defined configuration that optimizes a single business objective using the features created in the Pipeline.\\n\\n\\n\\nA Client can have more than one Pipeline.\\n\\n\\n\\nA Pipeline can have more than one Use Case.\\n\\nOfferFit – Confidential\\n\\n42\\n\\n1e\\n\\n1d\\n\\nData and Features (Exercise B)\\n\\nOfferFit – Confidential\\n\\n43\\n\\nData and Features\\n\\nData Asset Overview Population\\n\\nThe population asset represents one of the most common asset types encountered in implementations. It contains one\\n\\nrecord per customer_id each per day. Each record has some pre-aggregated, high level information about the customer. The fields are:\\n\\n– customer_identifier: The unique ID of the customer. All features and predictions OfferFit generates will be on the\\n\\ncustomer level, so this is a critically important field.\\n\\n– favorite_food: The customer’s favorite food sold by FoodCo. This can be any of Pizza, taco, burrito\\n\\n– membership_tier: The FoodCo membership tier held by the customer. This can be any of: Bronze, silver, gold,\\n\\nplatinum\\n\\n– customer_employment_industry: The industry that during signup the customer optionally self-reported they are\\n\\nemployed in. This can be any of: Tech, Finance, Service, Consulting, Other, NULL\\n\\n– percentage_emails_opened: The percentage of emails that FoodCo sends that are actually opened by the\\n\\ncustomer.\\n\\n– location_tag: A general “tag” that gives some high level information about the customer’s location. It is the\\n\\nabbreviation of the state they live in, followed by the “/” character, followed by a designation of how populated the nearest city is. For example, this value might be “TX/LOW”.\\n\\n– marketing_opt_in: A boolean field that represents if the customer opted in to receive marketing materials.\\n\\n– signup_date: the date that the user signed up as a member with FoodCo.\\n\\nOfferFit – Confidential\\n\\n44\\n\\nData and Features\\n\\nData Asset Overview Population, Example Asset (go.OfferFit.ai/assets)\\n\\nOfferFit – Confidential\\n\\n45\\n\\nData and Features\\n\\nData Asset Overview Transactions\\n\\n\\n\\nThe transactions asset is another common type of asset in implementations. It can contain multiple records per customer_id per day. Each record in this table represents a single transaction by a customer (e.g., a unique purchase from the website, a unique visit to the store, etc.). The fields are:\\n\\n–\\n\\ntransaction_id: A unique identifier for this particular transaction.\\n\\n–\\n\\ncustomer_identifier: The unique ID of the customer (all features & predictions are generated against this field)\\n\\n–\\n\\nstore_id: The ID of the FoodCo store where the transaction occurred.\\n\\n–\\n\\nproduct_id: The unique ID of the particular product that the customer purchased as part of the transaction.\\n\\n–\\n\\nduring_discount_hour: Whether the transaction happened during the store’s “discount hour” or not. During discount hour, all items are 10% off.\\n\\n–\\n\\ntransaction_type: The type of transaction that occurred. This field can contain one of three values: in_store, pickup, delivery\\n\\n–\\n\\nquantity: The amount of the item that was purchased as part of the transaction.\\n\\n–\\n\\ntax_percent: A decimal value representing the percentage of the overall purchase price that the customer must pay in taxes for this transaction. Due to a large number of varied regulations and tax schemes, it depends on the state, city, item, and even quantity of item purchased.\\n\\n–\\n\\ntransaction_datetime: The exact time at which the transaction occurred.\\n\\nOfferFit – Confidential\\n\\n46\\n\\nData and Features\\n\\nData Asset Overview Transactions, Example Asset (go.OfferFit.ai/assets)\\n\\nOfferFit – Confidential\\n\\n47\\n\\nData and Features\\n\\nData Asset Overview Products\\n\\nThe Products asset is similar to the Population asset in the sense that there is one record per “entity”. However, in the\\n\\ncase of Products this entity is a product (identified by the product_id) instead of a customer.\\n\\nThis difference will become key in later sections, as this data must be joined onto another asset to use the information\\n\\ncontained here in feature engineering.\\n\\nThis is because features are only engineered per customer, i.e., on data that contains a customer_id.\\n\\nThe fields are:\\n\\n– product_id: The unique ID of the particular product that the customer purchased as part of the transaction.\\n\\n– product_name: The name of the product.\\n\\n– price: The price of the product in dollars.\\n\\n– is_healthy: Will be “True” if the product is classified as healthy, “False” otherwise.\\n\\nOfferFit – Confidential\\n\\n48\\n\\nData and Features\\n\\nData Asset Overview Products, Example Asset (go.OfferFit.ai/assets)\\n\\nOfferFit – Confidential\\n\\n49\\n\\nData and Features\\n\\nData Asset Overview Web Activity ● Like the transactions asset, this asset can contain multiple records per customer_id per day. Each record represents a\\n\\nsingle visit to a FoodCo web page. The fields for this asset are:\\n\\n– id: A unique identifier for this record.\\n\\n– customer_identitifier: The ID of the customer who has some recorded activity on FoodCo’s web page.\\n\\n– page: The specific page on FoodCo’s website where the web activity occurred. This can contain one of the\\n\\nfollowing values: home, order, help, contact\\n\\n– previous_page: The web page that brought the customer to the current page where the web activity occurred.\\n\\nThis can be one of the following values: home, order, help, contact, NULL (means the customer came from some external source directly to the page)\\n\\n– time_spent: The amount of time (in seconds) that the customer spent on the web page.\\n\\n– source_google_ads: This will be True if the customer came to this page from Google Ads, False otherwise.\\n\\n– source_facebook_ads: This will be True if the customer came to this page from Facebook Ads, False otherwise.\\n\\n– ts: The timestamp of when the customer visited this web page.\\n\\nOfferFit – Confidential\\n\\n50\\n\\nData and Features\\n\\nData Asset Overview Web Activity, Example Asset (go.OfferFit.ai/assets)\\n\\nOfferFit – Confidential\\n\\n51\\n\\nData and Features\\n\\nSet up all of the data assets\\n\\nData Asset Setup Properties Page ● Properties is the first step when “Create data asset” is selected.\\n\\ndescribed to the left using the provided sample files.\\n\\nThe following fields are\\n\\nrequired:\\n\\nThere are two options when bringing in input data for the asset:\\n\\n– Name\\n\\n– Upload a sample file the client has provided.\\n\\n– Source Format\\n\\n– Usually used when a Use Case is being set up for the first time..\\n\\n– CSV Separator (if source\\n\\n– Provide a path to a file the client has sent to a GCS bucket.\\n\\nformat is CSV)\\n\\n– This is used for live Use Cases but less often for initial setup.\\n\\n– Sample File\\n\\nSelecting the data asset column that contains the customer_id is required.\\n\\n– Partition Column\\n\\n– If the asset does not contain a customer_id, then select None.\\n\\n– Customer Identifier\\n\\n– “None” should be selected for this field if the assets does not have a customer_ids. These will require some special attention later on.\\n\\nColumn\\n\\n– Datetime Column\\n\\nSelecting the datetime column on the asset may be needed.\\n\\nYou will need to select a partition column. Select \"offerfit_received_ts\" for this column.\\n\\n– A field on the data asset generally exists which represents a\\n\\ntransaction time if it is a “transactional” asset (i.e., it contains more than one record per “entity” per day)\\n\\n– Otherwise, “offerfit_received_ts” is generally selected\\n\\nOfferFit – Confidential\\n\\n52\\n\\nData and Features\\n\\nData Asset Setup Validation\\n\\n\\n\\nOfferFit works by receiving data directly from clients. Sometimes, there can be issues with the client data that are completely outside of the implementation team’s control.\\n\\nAdd user email to the “Daily Validation Reports” in the Reports section\\n\\n\\n\\nFill out validation for all assets, focusing mainly on field types. All ID fields in all assets must be set as string data types.\\n\\n– In some cases, this could be as simple as the client not actually sending the data they are supposed to send on a particular day.\\n\\n– Other times, there could be aspects of the data that are inconsistent and broken (e.g., a field that has always been a number is now text).\\n\\n\\n\\nIn the Population asset, the percentage of emails opened should be between 0 and 1\\n\\nThe purpose of validation is to encode assumptions about the client data so the implementation team can be alerted if something does not match up.\\n\\n– These alerts often go out to the implementation team and the client\\n\\nNone of the ID values in any of the assets should ever be NULL.\\n\\nso any problems can be quickly fixed.\\n\\nA “Range” can be set for fields that are integers or floats:\\n\\n\\n\\nAll of the primary key ID values in all of the assets should be unique.\\n\\n– If field reaches the Warning threshold, then a warning is issued.\\n\\n– If field reaches the Critical threshold, the pipeline fails.\\n\\n– Thus, Warning thresholds should be more restrictive than Critical.\\n\\nOfferFit – Confidential\\n\\n53\\n\\nData and Features\\n\\nData Asset Setup Preprocess\\n\\n\\n\\n\\n\\nThis task (on the back end) is responsible for taking the data in the asset files in Google Storage and ingesting it into the data warehouse.\\n\\nFill out preprocess for all assets\\n\\n\\n\\nPrimary Keys:\\n\\n–\\n\\nPopulation: customer_id, offerfit_received_ts\\n\\n\\n\\nIt does a few other things:\\n\\n–\\n\\nDeduplicates data according to the primary key set\\n\\n–\\n\\nTransactions: transaction_id, offerfit_received_ts\\n\\n–\\n\\nAllows us to rename columns\\n\\n–\\n\\nProducts: product_id, offerfit_received_ts\\n\\n–\\n\\nStandardizes column names (e.g., remove whitespace). This happens in the background and is not something the user needs to explicitly do.\\n\\n– Web Activity: id, offerfit_received_ts\\n\\nOfferFit – Confidential\\n\\n54\\n\\nData and Features\\n\\nData Asset Joining 1 of 4\\n\\nIn the OfferFit platform, feature engineering can only be performed on data assets that contain a customer_id.\\n\\n– This is because features are meant to be computed at the customer level, so OfferFit must have some customer\\n\\nidentifier on the asset to accomplish this.\\n\\nAt the same time, it is common to receive data assets that do not contain a customer identifier.\\n\\nThe primary means to rectify this issue is joining\\n\\n– The asset that does not have a customer_id can have other assets iteratively joined onto it until the customer_id can\\n\\nbe associated with all of the data.\\n\\nFrom there, any desired features can be computed.\\n\\nOfferFit – Confidential\\n\\n55\\n\\nData and Features\\n\\nData Asset Joining 2 of 4\\n\\nImagine a simple case with two data assets:\\n\\n1. Customers\\n\\n2. Products\\n\\ncustomer_id favorite_product_id\\n\\nproduct_id\\n\\nproduct_price\\n\\n1\\n\\n4\\n\\n4\\n\\n8.49\\n\\n2\\n\\n8\\n\\n8\\n\\n119.99\\n\\n3\\n\\n17\\n\\n17\\n\\n14.79\\n\\nAssume a feature that gives us the price of the customer\\'s favorite product is required.\\n\\nAssume for this Use Case:\\n\\n– Price sensitivity of users is an important data point\\n\\n– Users who prefer products with lower prices are more price-sensitive.\\n\\nSince features can only be computed based on assets that contain a customer_id, and the product_price is in an asset\\n\\nthat does not have a customer_id, then without taking further steps it cannot be used as a feature.\\n\\nThis is where joining comes in.\\n\\nOfferFit – Confidential\\n\\n56\\n\\nData and Features\\n\\nData Asset Joining 3 of 4\\n\\nAt this point, the products asset should be augmented by joining the population asset onto it.\\n\\nThis would bring all of the data together in one place for feature engineering.\\n\\nWhen joining, there are a few decisions needed:\\n\\n– The asset to augment: Performing the join to augment the asset that does not contain the customer ID is\\n\\nrecommended and preferred in all but the most advanced Use Cases.\\n\\n– There is nothing to stop the converse (augmenting the asset with the customer_id to bring in the other data),\\n\\nbut this can add additional complication to an asset that is already usable for feature engineering.\\n\\n– The type of join: Default of left is recommended except for the most advanced Use Cases.\\n\\n– The join keys: The field(s) in each data asset that can be used to link the two assets together.\\n\\n– The columns to include: any fields from the data asset being joined onto the \"base\" data asset.\\n\\n– Sometimes, only a few fields in the new data asset are important, so keeping them all would be unnecessary.\\n\\nOfferFit – Confidential\\n\\n57\\n\\nData and Features\\n\\nData Asset Joining 4 of 4\\n\\nThe Products asset does not contain a customer_id field on its own.\\n\\nThe products asset would look like the following after being configured\\n\\n– However, the\\n\\nfor joining:\\n\\nTransactions asset does have a customer_id, and it also has a product_id field that can be used to get the product data associated with a customer_id.\\n\\ncustomer_id\\n\\nproduct_price\\n\\n1\\n\\n8.49\\n\\n2\\n\\n119.99\\n\\n3\\n\\n14.79\\n\\nDuring feature engineering, features can now be created on a customer\\n\\nPlease augment the Products\\n\\nlevel using the product_price field.\\n\\nasset by joining the Transactions data onto it using the product_id field that is in both tables.\\n\\n– Keep all fields from the Transactions asset.\\n\\nOfferFit – Confidential\\n\\n58\\n\\nBreak (30 min)\\n\\nFrom A/B To AI\\n\\nOfferFit – Confidential OfferFit – Confidential\\n\\n59 59\\n\\nData and Features\\n\\nData Asset Transformation Overview\\n\\nEven after data is loaded into OfferFit, preprocessing is completed, and data is joined, sometimes columns still aren\\'t in\\n\\nthe right format to create all the features needed for the OfferFit.\\n\\nSometimes this can be fixed by applying transforms to the asset, and creating new columns.\\n\\nArithmetic, string manipulation and data cleaning transformations are supported.\\n\\nOfferFit – Confidential\\n\\n60\\n\\nData and Features\\n\\nData Asset Transformations Arithmetic\\n\\nSum: The Sum transform operation creates a new column whose value is the sum of two or more existing columns. This operation only works for columns of numbers (integer, float, etc).\\n\\nTry finding this section and more on OfferFit’s help page: portal.offerfit.ai/help-center\\n\\nDifference: The Difference transform operation creates a new column whose value is the difference of exactly two columns. The columns must be numbers (integers, floats, etc) or datetimes. If both columns are datetimes, the new column will have the number of days between the two dates.\\n\\nMultiply: The Multiply transform operation creates a new column whose value is the product of two or more existing columns. This operation only works for columns of numbers (integer, float, etc).\\n\\nDivide: The Divide transform operation creates a new column whose\\n\\nvalue is the result of division between two columns, the numerator and the denominator. This operation only works for columns of numbers (integer, float, etc).\\n\\nOfferFit – Confidential\\n\\n61\\n\\nData and Features\\n\\nData Asset Transformations String ● Split: The Split transform operation creates two or more new columns whose contents are the result of splitting the value\\n\\nin the source column by the defined delimiter.\\n\\nfavorite_fruits\\n\\nfruit1\\n\\nfruit2\\n\\nfruit3\\n\\napple,banana,pear\\n\\napple\\n\\nbanana\\n\\npear\\n\\norange,guava,watermelon\\n\\norange\\n\\nguava\\n\\nwatermelon\\n\\npeach,orange,strawberry\\n\\npeach\\n\\norange\\n\\nstrawberry\\n\\n– The source column must be a string, and the resulting columns will all be strings. The delimiter must be exactly\\n\\none character in length.\\n\\n– Note that the number of new columns must be known in advance, and named when creating the transformation.\\n\\nThere is no way to automatically create as many columns as needed if the number of delimiters varies\\n\\nCombine: The Combine transform operation transforms two or more source columns into a single destination column\\n\\nby joining them on the delimiter.\\n\\nfruit1\\n\\nfruit2\\n\\nfruit3\\n\\nfavorite_fruits\\n\\napple\\n\\nbanana\\n\\npear\\n\\napple,banana,pear\\n\\norange\\n\\nguava\\n\\nwatermelon\\n\\norange,guava,watermelon\\n\\npeach\\n\\norange\\n\\nstrawberry\\n\\npeach,orange,strawberry\\n\\nOfferFit – Confidential\\n\\n62\\n\\nData and Features\\n\\nData Asset Transformations Data cleaning and standardization (1 of 2) ● Fill NA: creates a new column, where the value in the new column is identical to the source column, if a value exists,\\n\\nbut any rows where the column value is null/na are replaced with the Fill value.\\n\\n– A Fill NA configuration that sets the fill to “apple” (for a chosen column) will look like this:\\n\\nfruits (source)\\n\\nfruits_filled_na (destination)\\n\\nbanana\\n\\nbanana\\n\\nna\\n\\napple\\n\\nType cast: creates a new column whose value is identical to the source column, but whose data type is the new data\\n\\ntype.\\n\\n– The Type cast operation allows converting a column into Datetime, Integer, Float, or String data types, but all\\n\\nvalues in the source column must be compatible with the new data type, or the transform will fail.\\n\\nsource (string)\\n\\nafter_type_cast_to_integer\\n\\n‘1’\\n\\n1\\n\\n‘2’\\n\\n2\\n\\nOfferFit – Confidential\\n\\n63\\n\\nData and Features\\n\\nData Asset Transformations Data cleaning and standardization (2 of 2)\\n\\nMap: The Map transform operator works by taking the values in the source column, then creating the destination\\n\\ncolumn.\\n\\n– If a map is defined for the value in the source column, the destination column contains the replacement value of\\n\\nthe map\\n\\n– If no map is defined, the destination column contains the value of the default mapping if set, else it contains\\n\\nnull/na.\\n\\n– If the “fruits” column is configured to have the following mapping:\\n\\n– Default map → “apple”, “banana” → “pear”, “strawberry” → “strawberry”\\n\\n– The result will be: fruit (string)\\n\\nafter_type_cast_to_integer\\n\\nbanana\\n\\npear\\n\\nstrawberry\\n\\nstrawberry\\n\\ngrape\\n\\napple\\n\\nOfferFit – Confidential\\n\\n64\\n\\nData and Features\\n\\nData Asset Transformations\\n\\nPopulation\\n\\n– [Split] Create two new fields called state and population_density. These fields should be the left and right portion\\n\\nof the location_tag field.\\n\\n– [Fill NA] Replace all NULL values in the customer_employment_industry field with “Other”.\\n\\nProducts\\n\\n– Create a purchase subtotal field by multiplying the quantity by the price of the item in each record.\\n\\n– Create a total tax paid field by multiplying the purchase subtotal by the tax percentage for each record\\n\\n– Create a total price paid by summing the purchase subtotal with the total tax paid field.\\n\\nOfferFit – Confidential\\n\\n65\\n\\nData and Features\\n\\nEngineer Features Overview\\n\\nFeatures are created to encode customer behavior (as a vector of numbers) relevant to the Use Case so OfferFit’s\\n\\nalgorithm can use them to make better decisions.\\n\\nFeatures are created on data after it has been preprocessed, joined, and transformed (where the latter two steps are\\n\\noptional).\\n\\n– Features can only be created for a data asset that includes a customer_id .\\n\\n– If no customer_id column exists then one must be joined onto the data asset.\\n\\nWhile configuring features, the \"Preview\" button will show the features’ actual values and summarized statistics.\\n\\nLater, when setting up Use Cases, a subset of features needed for that use case can be selected.\\n\\nOfferFit – Confidential\\n\\n66\\n\\nData and Features\\n\\nEngineer Features Available features ● Aggregation:\\n\\nTry finding this section and more on OfferFit’s help\\n\\npage: portal.offerfit.ai/help-center\\n\\n– sum\\n\\n– average\\n\\n– standard deviation\\n\\n– maximum, minimum\\n\\n– number of unique values\\n\\nBoolean\\n\\nCount\\n\\nIdentity\\n\\nEncoding:\\n\\n– one-hot\\n\\n– ordinal\\n\\nTime since\\n\\nTime\\n\\nOfferFit – Confidential\\n\\n67\\n\\nData and Features\\n\\nEngineer Features Required fields\\n\\nEach type of feature operation requires different input fields. However, most features require a Days Back and a Filter\\n\\ninput. (Identity, Ratio and Time Since features do not have a days back input)\\n\\nDays Back is the number of days that OfferFit is aggregating over.\\n\\nThe input can be one or more integers, for example 7, 14.\\n\\n– This means that a Count feature on transactions with two inputs for Days Back is created (e.g., 7 and 14 days) then\\n\\ntwo features will be created:\\n\\n– Count rows where transactions occurred for 7 days back\\n\\n– Count rows where transactions occurred for 14 days back\\n\\n– The value of the feature for larger number of days back will be inclusive of the value of the feature for the smaller\\n\\ndays back. E.g., the count for 14 days back will be equal to or larger than the count for 7 days back.\\n\\nFilters are a set of conditions that can either be true or false for a particular customer.\\n\\n– All of the conditions specified in the set of filters must be met in order for a row to be considered.\\n\\n– The Aggregation operation also defaults all values to 0 if all records are removed due to the filtering conditions.\\n\\nOfferFit – Confidential\\n\\n68\\n\\nData and Features\\n\\nEngineer Features Aggregation\\n\\nAggregation\\n\\n– The aggregation operation allows us to compute the sum, average, standard deviation, maximum, minimum, or\\n\\nnumber of unique values of a particular column for each customer_id in a dataset.\\n\\n– Due to the fact that this operation aggregates over multiple rows for each customer.\\n\\n– The aggregation operation requires the following inputs:\\n\\n– Days back: the number of days that OfferFit is aggregating over.\\n\\n– Aggregation column: the values in the asset to sum, average, get the minimum of, etc.\\n\\n– This column should always be numerical.\\n\\n– Operation(s): the aggregation operations (e.g., standard deviation, maximum, sum, etc.) to perform over the\\n\\naggregation column.\\n\\n– Selecting multiple will create multiple features for each aggregation column.\\n\\n– Filters: a set of conditions that must be true for a row in order for it to be used in the aggregation.\\n\\nOfferFit – Confidential\\n\\n69\\n\\nData and Features\\n\\nEngineer Features Boolean & Count ● Boolean\\n\\n– The boolean operation allows us to check whether a particular condition is true or false for every customer_id in\\n\\nthe dataset (1 = True, 0 = False)\\n\\n– This operation is commonly used across different types of data assets: it does not matter whether there is one row\\n\\nper customer_id or if there are several.\\n\\n– The boolean operation requires the following inputs:\\n\\n– Days back: the number of days that OfferFit is checking the condition over.\\n\\n– Filters: a set of conditions that can either be true or false for a particular customer.\\n\\nCount\\n\\n– The count feature engineering operation allows us to count the number of occurrences of some event, per\\n\\ncustomer_id, in the dataset.\\n\\n– Because OfferFit is counting rows per customer, this operation typically only makes sense dealing with assets that\\n\\ncan contain multiple rows per customer_id each day.\\n\\n– The count operation requires the following inputs:\\n\\n– Days back: the number of days that OfferFit is checking the condition over.\\n\\n– Filters: a set of conditions that can either be true or false for a particular customer.\\n\\nOfferFit – Confidential\\n\\n70\\n\\nData and Features\\n\\nEngineer Features Identity\\n\\nIdentity\\n\\n– The identity operation allows us to extract raw values from a data asset and use them as features.\\n\\n– Since the value is being used as-is, this operation is most often applied on numerical fields (which are\\n\\nautomatically ready to be used as input to a ML model).\\n\\n– However, more advanced users may choose to retain some string values for Use Case setup (e.g., for\\n\\ndefining Guardrails).\\n\\n– Because this operation grabs a single column value, and feature engineering operations create one feature\\n\\nvalue per customer, this is mainly used on assets that contain a single record per customer.\\n\\n– The identity operation requires the following inputs:\\n\\n– Target Column: the name of the field in the asset that contains the values OfferFit should extract as\\n\\nfeatures.\\n\\n– Fill: the value that OfferFit should use for customers that are missing data in the target column. This can be a number, \"mean\", or \"median\" if the field is numeric or it can be a string value if the field is text.\\n\\n– Filters: a set of conditions that can either be true or false for a particular customer.\\n\\nOfferFit – Confidential\\n\\n71\\n\\nData and Features\\n\\nEngineer Features Ordinal encoding\\n\\nOrdinal Encoding\\n\\n– The ordinal encoding operation allows us to convert a string field into a numerical value that can be used by the\\n\\nMachine Learning model.\\n\\n– This operation is most often used when the values have some intrinsic ordering (e.g., \"low\", \"medium\", \"high\",\\n\\netc.).\\n\\n– Because single column values are being encoded without doing any aggregation or decreasing the number of\\n\\nrows, this operation is most commonly used on assets that contain one row per customer_id per day.\\n\\n– The ordinal encoding operation requires the following inputs:\\n\\n– Days back: the number of days that OfferFit should check the condition over.\\n\\n– Target Column: the column containing the values that OfferFit wants to ordinally encode.\\n\\n– Encoding Order: a list of possible values that can be inside of target column. The order of the values within the list determines the order in which the encoding values are assigned. The first element gets a value of \"1\" for the feature, the second gets a value of \"2\", and so on. If a value is not contained within this encoding order list, then it will receive a feature value of \"0\".\\n\\n– Filters: a set of conditions that can either be true or false for a particular customer.\\n\\n– Customers whose target column is not contained within the encoding order list will receive a value of “0”.\\n\\nOfferFit – Confidential\\n\\n72\\n\\nData and Features\\n\\nEngineer Features One-hot encoding ● One-Hot Encoding\\n\\n– Converts a string field into a numerical value that can be used by the Machine Learning model.\\n\\n– This operation is most often used when the values lack any intrinsic ordering.\\n\\n– Because single column values are being encoded without doing any aggregation or decreasing the number of\\n\\nrows, this operation is most commonly used on assets that contain one row per customer_id per day.\\n\\n– The one-hot encoding operation requires the following inputs:\\n\\n– Days back: the number of days that OfferFit is checking the condition over.\\n\\n– Target Column: the column containing the values that OfferFit should ordinally encode.\\n\\n– Encoding Order: a list of possible values that can be inside of target column. The order of the values within\\n\\nthe list determines the order in which the encoding values are assigned. If a value is not contained within this encoding order list, then it will receive a feature value of all \"0\".\\n\\n– Filters: a set of conditions that can either be true or false for a particular customer.\\n\\n– Unlike ordinal encoding, one-hot encoding produces more than one feature. The number of features produced\\n\\nmatches the length of the encoding_order list.\\n\\n– Similarly to Ordinal encoding, the customers whose target column is not contained within the encoding order list\\n\\nwill receive a value of \\'0\\' in every feature column generated by this feature.\\n\\nOfferFit – Confidential\\n\\n73\\n\\nData and Features\\n\\nEngineer Features Time since\\n\\nTime since\\n\\n– The Time Since operation allows us to compute the amount of time that has passed since some specific event in\\n\\nthe dataset.\\n\\n– This feature is typically used with assets of various formats, the only requirement is that the asset contains some\\n\\nfield that is either a date or a timestamp.\\n\\n– The time since operation requires the following inputs:\\n\\n– Granularity: the granularity at which OfferFit returns the difference in time. This can be either \"Day\", \"Hour\",\\n\\n\"Minute\", or \"Second\".\\n\\n– Order: this can be either \"First\" or \"Last\". It denotes whether OfferFit should use the first or last occurrence of an event that matches the specified condition when computing the amount of time that has passed.\\n\\n– Fill: a numerical value that represents the default amount of time to use if the condition is never met for a\\n\\nparticular customer.\\n\\n– Filters: a set of conditions that can either be true or false for a particular customer.\\n\\n– The following configuration → Granularity: Day, Order: First, Fill: 100, Filters: quantity >= 3\\n\\n– In plain words can be interpreted as \"for each customer, compute the number of days since the first time that\\n\\ncustomer ordered at least three items\".\\n\\nOfferFit – Confidential\\n\\n74\\n\\nData and Features\\n\\nEngineer Features Ratio\\n\\nRatio\\n\\n– The Ratio feature is unique compared to other feature engineering operations.\\n\\n– Unlike the others, this does not operate on a data asset directly. Instead, it is used to compute the ratio of features\\n\\nthat have already been created from a data asset.\\n\\n– As a result, the ratio feature can work with any data asset as long as at least two numerical features have already\\n\\nbeen created.\\n\\n– The ratio operation requires the following inputs:\\n\\n– Numerator: the feature that should be used as the numerator of the ratio.\\n\\n– Denominator: the feature that should be used as the denominator of the ratio.\\n\\n– Fill: the value that OfferFit should use if its unable to compute the ratio (e.g., the denominator is 0)\\n\\n– Often, the ratio_feature value is the result of dividing a numerical feature by another.\\n\\n– In the case where OfferFit cannot compute the ratio (because the denominator is 0), the feature will have the\\n\\nvalue of the “fill”.\\n\\nOfferFit – Confidential\\n\\n75\\n\\nData and Features\\n\\nEngineer Features Sample features\\n\\nAfter there are features configured, the user can “Run sample features”.\\n\\nIf this task runs successfully, it will result in two outputs (which can be viewed by clicking the links in the UI):\\n\\n– A feature preview table\\n\\n– A feature statistics table\\n\\nThese sample outputs can help determine whether a feature is potentially useful or not.\\n\\n– e.g., max_returns_10d in the table below is showing all zeros and considering its usefulness would be appropriate\\n\\ncustomer_id sum_quantity_10d\\n\\naverage_quantity_10d\\n\\nmin_quantity_10d\\n\\nmax_returns_10d\\n\\n1\\n\\n8\\n\\n4\\n\\n3\\n\\n0\\n\\n2\\n\\n8\\n\\n8\\n\\n8\\n\\n0\\n\\n3\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\nOfferFit – Confidential\\n\\n76\\n\\nData and Features\\n\\nEngineer Features Customer population ● The Customer Population is the set of customers for whom we calculate\\n\\nfeatures.\\n\\nOn the base Data & Features screen, locate and select the Customer population button.\\n\\nWhen defining the customer population, there are two common scenarios:\\n\\na.\\n\\nInclude all customers in a particular asset in the customer population.\\n\\n– This is a general catch-all that allows us to easily compute features\\n\\nChoose the Population asset from the dropdown and choose the Include all customers option.\\n\\nfor all customers that might appear and is typically viable\\n\\nb.\\n\\nInclude a subset of customers in a particular asset.\\n\\n– This only makes sense if no Use Cases (current or future) attached to this pipeline will ever need to make predictions for some customers.\\n\\n– Otherwise, OfferFit should not be excluding customers from the\\n\\ncustomer population for a pipeline.\\n\\nThe entire customer population set must be defined in a single asset.\\n\\nIf the customer population is defined across more than one asset, it must be\\n\\npre-joined before uploading to OfferFit.\\n\\nOfferFit – Confidential\\n\\n77\\n\\nData and Features\\n\\nEngineer Features 1 of 4\\n\\nCreate the following features\\n\\n– If the operation is one-hot encoding or ordinal encoding the days back value should be 1\\n\\n– All other features should use a “days back” value of 1000\\n\\nPopulation\\n\\n– ⬜\\n\\n[Ordinal] Create a feature that represents the customer’s membership tier.\\n\\n– ⬜\\n\\n[Ordinal] Create a feature that represents the customer’s location population density.\\n\\n– ⬜\\n\\n[One-hot] Create a feature that represents the customer’s favorite food.\\n\\n– ⬜\\n\\n[One-hot] Create a feature that represents the state in which the customer resides.\\n\\n– ⬜\\n\\n[Identity] Percentage of emails opened.\\n\\n– ⬜\\n\\n[Boolean] Whether the customer is opted into marketing or not.\\n\\nOfferFit – Confidential\\n\\n78\\n\\nData and Features\\n\\nEngineer Features 2 of 4\\n\\nWeb Activity\\n\\n– ⬜\\n\\n[Aggregation] Sum of all time spent on the home page.\\n\\n– ⬜\\n\\n[Aggregation] Average time spent on the home page during each visit.\\n\\n– ⬜\\n\\n[Aggregation] Sum of time spent on the help page.\\n\\n– ⬜\\n\\n[Aggregation] Max time spent on the help page.\\n\\n– ⬜\\n\\n[Boolean] Create a feature that is “1” if the customer has ever visited the help page, “0” otherwise.\\n\\n– ⬜\\n\\n[Boolean] Create a feature that is “1” if the customer has ever been sent to FoodCo’s website through Google\\n\\nads, “0” otherwise.\\n\\n– ⬜\\n\\n[Count] How many different times has the customer visited FoodCo’s website\\n\\n– ⬜\\n\\n[Count] How many different times has the customer arrived at FoodCo’s website organically (the previous\\n\\npage is None)?\\n\\n– ⬜\\n\\n[Ratio] Get the ratio of time spent on the help page to overall time spent on the home page.\\n\\nOfferFit – Confidential\\n\\n79\\n\\nData and Features\\n\\nEngineer Features 3 of 4\\n\\nTransactions\\n\\n– ⬜\\n\\n[Count] The number of transactions that the customer has been involved in.\\n\\n– ⬜\\n\\n[Count] The number of transactions that the customer has been involved in during discount hour.\\n\\n– ⬜\\n\\n[Count] The number of pick up orders that the customer has done.\\n\\n– ⬜\\n\\n[Count] The number of delivery orders that the customer has done.\\n\\n– ⬜\\n\\n[Count] The number of in store purchases that the customer has done.\\n\\n– ⬜\\n\\n[Ratio] The percentage of all of the customer’s transactions that were during discount hour.\\n\\n– ⬜\\n\\n[Ratio] The percentage of all of the customer’s transactions that were delivery.\\n\\n– ⬜\\n\\n[Ratio] The percentage of all of the customer’s transactions that were in store.\\n\\nOfferFit – Confidential\\n\\n80\\n\\nData and Features\\n\\nEngineer Features 4 of 4\\n\\nProducts\\n\\n– ⬜\\n\\n[Aggregation] Calculate the sum of all transaction total prices.\\n\\n– ⬜\\n\\n[Aggregation] Calculate the average of all transaction total prices.\\n\\n– ⬜\\n\\n[Aggregation] Calculate the maximum of all transaction total prices.\\n\\n– ⬜\\n\\n[Aggregation] Compute the total spent on transactions when the item was healthy.\\n\\n– ⬜\\n\\n[Ratio] Compute the ratio of money spent on healthy purchases to total purchases.\\n\\nOfferFit – Confidential\\n\\n81\\n\\nImplementation Partner Training: Day 2\\n\\nDallas, November 2022\\n\\nConfidential – Any use of this material without specific permission of OfferFit, Inc. is strictly prohibited\\n\\nCreate a circle in the front of the room\\n\\nPerson A will turn to Person B (next to them) and in unison, clap their hand together while making eye contact, as synced as possible.\\n\\nEnergizer Clap around the world…\\n\\nPerson B then turns to person C and they clap at the same time. The clap\\n\\ncontinues like this around the circle.\\n\\n– Try to pass the clap more and more quickly with as many perfectly\\n\\nsynchronized claps as possible.\\n\\nNow switch… (more details to come)\\n\\nOfferFit – Confidential\\n\\n83\\n\\nDay 1 Recap\\n\\nOfferFit – Confidential\\n\\n84\\n\\n2a OfferFit’s Community of Bandits Approach\\n\\nOfferFit – Confidential\\n\\n85\\n\\ng\\n\\nn\\n\\ni\\n\\nn\\n\\nr\\n\\na\\n\\ne\\n\\nl\\n\\ne\\n\\nn\\n\\ni\\n\\nh\\n\\nc\\n\\na\\n\\nM\\n\\nOfferFit’s Community of Bandits Approach\\n\\nOfferFit uses self-learning AI to automate experimentation\\n\\nOfferFit’s focus\\n\\nReinforcement learning\\n\\nUnsupervised learning\\n\\nSupervised learning\\n\\nExperimentally discover optimal\\n\\nIdentify patterns in data\\n\\nPredict an outcome from historical\\n\\nactions\\n\\ndata\\n\\nExample use: cluster analysis for\\n\\nExample use: empirically discover optimal action for each customer\\n\\nExample use: churn prediction\\n\\ncustomer segmentation\\n\\nOfferFit – Confidential\\n\\n86\\n\\nOfferFit’s Community of Bandits Approach\\n\\nEarly reinforcement learning models use “multi-armed bandit by segment”\\n\\nOld joke: a slot machine is a one-armed bandit.\\n\\nClassical game theory’s multi-armed bandit problem: try to get the best payout one can from a series of pulls at a row of slot machines, each of which has a fixed but unknown (by you) probability of producing a payout.\\n\\nMulti-armed bandit (MAB)\\n\\n– Reinforcement learning agent which tries to solve a multi-armed bandit problem, by experimenting to find choices which give best rewards.\\n\\nMany companies have replaced A/B testing with MAB by segment\\n\\n– Run MAB on each customer segment to discover optimal actions.\\n\\nLimitations:\\n\\n– Only uses 1 data point about each customer: the segment.\\n\\n– No more personalized than an A/B test.\\n\\n– MABs can\\'t coordinate their recommendations with each other: an agent\\n\\nselecting sending time can’t take into account the choice made by the agent selecting creative.\\n\\nOfferFit – Confidential\\n\\n87\\n\\nOfferFit’s Community of Bandits Approach\\n\\nContextual bandits enable 1:1 decisioning\\n\\nExploration strategy\\n\\nOracle\\n\\nThe exploration strategy manages the exploration/exploitation approach. Exploration strategies available in OfferFit include:\\n\\nThe oracle is a model responsible for estimating the expected reward value. Oracles available in OfferFit include:\\n\\nContextual bandits consider a set of choices and the individual customer they are choosing for. OfferFit uses several contextual bandit architectures, such as the “oracle agent,” which combines a distinct “oracle” and “exploration strategy.”\\n\\nEpsilon greedy: chooses highest expected value action some percentage of the time (e.g., 90%) and randomly explores the rest of the time (percentage decreases as experiences accumulate)\\n\\nLinear Elastic-net: a regularized\\n\\nregression which performs well in low-sample situations\\n\\nRandom forest: a parallelizable ensemble of decision trees\\n\\nGaussian Thompson sampling: samples from a\\n\\nCatboost: a particularly fast and robust gradient boosting machine algorithm\\n\\nnormal distribution for each action, decreasing SD proportionally to number of tries\\n\\nFALCON: a powerful and fast exploration\\n\\nstrategy that aims to minimize regret\\n\\nOfferFit – Confidential\\n\\n88\\n\\nOfferFit’s Community of Bandits Approach\\n\\nOfferFit automates experimentation with a community of bandits\\n\\nDeciding Agent Non-deciding Agent\\n\\nElastic net contextual bandit\\n\\nRandom forest contextual bandit\\n\\nGradient boosting contextual bandit\\n\\nCadence\\n\\nMulti-armed bandit\\n\\nFor each experimentation dimension, several bandits are active, but only one is the deciding Agent. As the community learns, a meta-bandit allows higher-flexibility Agents to serve as the deciding Agent.\\n\\nElastic net contextual bandit\\n\\nRandom forest contextual bandit\\n\\nGradient boosting contextual bandit\\n\\nChannel\\n\\nMulti-armed bandit\\n\\nEach Agent’s decisions are passed as context to the following ones; this allows for coordinated recommendations while maintaining a small action space enabling exceptionally high sample efficiency\\n\\nElastic net contextual bandit\\n\\nRandom forest contextual bandit\\n\\nGradient boosting contextual bandit\\n\\nTime of day\\n\\nMulti-armed bandit\\n\\nElastic net contextual bandit\\n\\nRandom forest contextual bandit\\n\\nGradient boosting contextual bandit\\n\\nOffer\\n\\nMulti-armed bandit\\n\\nOfferFit – Confidential\\n\\n89\\n\\n2b Use Case Design\\n\\nOfferFit – Confidential\\n\\n90\\n\\nUse Case Design\\n\\nCore design components of all OfferFit Use Cases\\n\\nNumber that OfferFit aims to maximize when generating recommendations\\n\\n1\\n\\nTarget Metric\\n\\ne.g., total basket size\\n\\ne.g., customers with no purchase in past 100 days (dormant)\\n\\nUniverse of customers for which OfferFit produces recommendations\\n\\n2 Audience\\n\\nOptions that OfferFit can select for each customer in audience to maximize target metric\\n\\ne.g., offer/incentive, featured item, time of day\\n\\n3\\n\\nExperiment Dimensions\\n\\nBusiness rules that limit which actions certain customers can receive\\n\\ne.g., min discount of 5% if previously used discount\\n\\n4 Guardrails\\n\\ne.g., randomized 20% of audience receive BAU offers\\n\\nSubset(s) of population that are set aside for performance comparison vs. OfferFit\\n\\n5 Control(s)\\n\\nOfferFit – Confidential\\n\\n91\\n\\nUse Case Design\\n\\nExample: Increasing online purchase count at a fast food chain 1 of 3\\n\\nTarget Metric\\n\\nPurchase count ● Secondary metric: Clicks ● Penalty: Unsubscribes\\n\\nCustomer has created an online account ● Customer has made less than 3 purchases in the 90 days since account creation date ● Customer has opted-in to email communications\\n\\nAudience\\n\\nMessage ● Time of day ● Cadence ● Sample action bank: go.OfferFit.ai/assets\\n\\nExperiment Dimensions\\n\\nGuardrails\\n\\nNone\\n\\nControls\\n\\n2 control groups: ● 10% of the audience receives no communications ● 15% of the audience receives rules-based communications, representing business as\\n\\nusual\\n\\nOfferFit – Confidential\\n\\n92\\n\\nUse Case Design\\n\\nExample: New Zealand telco 2 of 3\\n\\nPlan upgrades ● Secondary metric: Clicks ● Penalty: Unsubscribes ● Customer is on a paid monthly plan ● Current customer plan is not the highest tier plan ● Customer hasn’t modified their plan in past 90 days ● Customer has opted-in to email communications ● Offer ● Time of day ● Sample action bank: go.OfferFit.ai/assets ● Customers cannot be sent downgrade offers ● Customers should not be sent duplicate offers ● Customers cannot be offered more than $10 off if their current plan less than $15 ● Maximum of 2 comms per customer annually ● 10% of the audience receives no communications ● 15% of the audience receives a subset of offers (specifically financial incentives),\\n\\nTarget Metric\\n\\nAudience\\n\\nExperiment Dimensions\\n\\nGuardrails\\n\\nControls\\n\\nrepresenting business as usual\\n\\nOfferFit – Confidential\\n\\n93\\n\\nUse Case Design\\n\\nExample: Home security plan extensions 3 of 3\\n\\nNPV\\n\\nTarget Metric\\n\\nCustomer is currently on a plan ● Customer has not modified plan in the past 90 days ● Customer is not past due ● Customer is opted-in to communications ● Extension offer ● Day of week ● Time of day ● Sample action bank: go.OfferFit.ai/assets ● Daily limit of 44k send recs ● Various restrictions around what offers can be sent to customers with particular\\n\\nAudience\\n\\nExperiment Dimensions\\n\\nGuardrails\\n\\nproducts\\n\\n5% of the audience receives rules-based communications, representing business as\\n\\nControls\\n\\nusual\\n\\nOfferFit – Confidential\\n\\n94\\n\\nUse Case Design\\n\\nBest practices when working to design and plan Use Cases with clients OfferFit Sales and Customer Success team will always be involved to help make design decisions!\\n\\n1.\\n\\nTarget metric should be a financial KPI (i.e., profit, revenue per user), and aligned with how the client measures the success of the project\\n\\n2.\\n\\nShorter feedback loops (i.e., 1 week or less) speeds up the training process because there can be more training iterations\\n\\n3. Having a strong parameterization can make or break project\\n\\n4. Where possible, compelling incentives are available as a decision option, and there is variability among the incentives\\n\\n(e.g., they aren’t all either large or small discount options)\\n\\n5. Data sources should be stable, and provide rich customer-level data that can support personalization\\n\\nOfferFit – Confidential\\n\\n95\\n\\ne\\n\\ns\\n\\na\\n\\nE\\n\\nUse Case Design\\n\\nScorecard for a great Use Case\\n\\nConcerns\\n\\nGood\\n\\nGreat\\n\\nLow priority\\n\\nHigh priority\\n\\nCEO level priority\\n\\nIs the success metric a priority?\\n\\nAlready fully optimized at microsegment level\\n\\nSome testing, but room for more optimization\\n\\nHow much testing & optimization has already been done?\\n\\nLimited testing (“blank slate”)\\n\\nImpact\\n\\nCan significantly vary 1–2 aspects (e.g., message, time)\\n\\nCan significantly vary 3 or more aspects\\n\\nHow much room is there to vary the actions taken for each customer?\\n\\nVery little room\\n\\nSome relevant individual-level data\\n\\nHow rich is the data to inform personalization?\\n\\nNo ability to personalize\\n\\nVery rich individual-level data\\n\\nData in 4+ systems and/or unclear how to unify & share\\n\\nData in 2–3 systems, with clear path to share & unify\\n\\nData in one system & unified at customer level (e.g., CDP)\\n\\nHow convenient is it to access the data?\\n\\nHow convenient is it to automatically activate based on personalized decisions?\\n\\nRequires manual intervention to activate\\n\\nRequires automating separately by channel\\n\\nCan activate through a single system (e.g., CDP)\\n\\nExtensive creation of new assets (e.g., emails)\\n\\nLimited creation of assets (or can modify existing)\\n\\nHow much new marketing asset development is needed?\\n\\nSome creation of new assets\\n\\nOfferFit – Confidential\\n\\n96\\n\\nBreak (30 min)\\n\\nFrom A/B To AI\\n\\nOfferFit – Confidential OfferFit – Confidential\\n\\n97 97\\n\\n2c\\n\\nUse Case Configuration\\n\\nOfferFit – Confidential\\n\\n98\\n\\nUse Case Configuration\\n\\nUse Case Creation\\n\\nFind the Use Cases section in the top panel.\\n\\nCreate a new Use Case and call it “Maximize Transactions”.\\n\\nNow, click on that Use Case. The remaining setup will be done within the Use Case that you just created.\\n\\nOfferFit – Confidential\\n\\n99\\n\\nUse Case Configuration\\n\\nDecision Dimensions Overview\\n\\nDecision dimensions are a core OfferFit concept.\\n\\nEach dimension represents a particular area that the Agent is trying to optimize in the recommendation landscape.\\n\\nImagine a simple example Use Case (like ours) where the client wants OfferFit to find the best email to send to each\\n\\ncustomer at the best time of day.\\n\\n– In that case, there are two things the Agent needs to decide:\\n\\n– the optimal email\\n\\n– the optimal time of day to send the email.\\n\\nOfferFit – Confidential\\n\\n100\\n\\nUse Case Configuration\\n\\nDecision Dimensions Types ● When creating dimensions, it is strongly encouraged to select one of the preset dimensions (although new types can be\\n\\nmanually defined):\\n\\n–\\n\\nCadence: Used to limit recommendations to a particular “cadence”.\\n\\n–\\n\\nFor example, OfferFit may only be allowed to send two emails to a particular customer per week.\\n\\n–\\n\\nCadence is used to determine the optimal cadence at which OfferFit should send its predictions: one action may be to send many times per week, another action may be to send only once\\n\\n–\\n\\nChannel: Used to determine which channel (e.g., email, phone call, text, etc.) is optimal for outreach.\\n\\n–\\n\\nIf the Use Case only involves one channel, then we don’t need to create this dimension.\\n\\n–\\n\\nTime: Used to determine which time of day (e.g., 10 AM, 12 PM, etc.) is optimal for outreach.\\n\\n–\\n\\nDevice: Used to determine which device (e.g., computer, mobile) should be targeted for outreach.\\n\\n– Offer: Used to represent the content of the different offers.\\n\\n– May include an related item, a discount on the item, or anything that is relevant to the Use Case.\\n\\n–\\n\\nPlan: Used to represent various subscription plans that the customer may be offered.\\n\\n–\\n\\nThis is a much more specific version of the “Offer” dimension.\\n\\n–\\n\\nCreative: The different creatives that can be attached to the offer, this could be images, videos, GIFs, etc.\\n\\nOfferFit – Confidential\\n\\n101\\n\\nUse Case Configuration\\n\\nDecision Dimensions “Send Decision To”\\n\\nDimensions are configured, they must specify the hierarchy which dimensions send\\n\\nCreate the Offer dimension (represents the emails)\\n\\ntheir decisions to one another.\\n\\nThis is important because the Agents for each dimension can take the decisions from their predecessors into account when deciding which action to take in their dimension.\\n\\nCreate the Time dimension\\n\\nCreate the Cadence\\n\\nBecause the “child” dimensions take the decision from the “parent”, it is important to set things up such that the decisions from the “parent” dimension might have an impact on the “child”.\\n\\ndimension\\n\\nConfigure things such that Offer sends its decision to Time\\n\\nHere are a couple of examples to illustrate this concept:\\n\\na. A “channel” dimension might want to receive decisions from a “time”\\n\\ndimension because emails, for example, can probably go out any time of day. But a phone call should not be late at night or early in the morning.\\n\\nb. A “channel” dimension might want to send its decisions to an “offer”\\n\\ndimension because people who respond to different channels (e.g., email, phone calls, texts, etc.) may be more prone to responding to different offer types (e.g., certain types of food, specific discount ranges, etc.)\\n\\nNote: a “cadence” dimension cannot have any parent dimensions.\\n\\nOfferFit – Confidential\\n\\n102\\n\\nUse Case Configuration\\n\\nActions Conceptual understanding\\n\\nExercise A had a simple overview of actions but did not dive into actions on a conceptual level.\\n\\nAnyone in a client facing role would benefit greatly from having a reasonable understanding of actions.\\n\\n– This is because actions are one of the few areas of Use Case setup that require significant iteration with clients and\\n\\nalso have a large impact on the outcome of a Use Case.\\n\\nFeatures, for example, are an internal Machine Learning concept that are unlikely to have a clear business meaning to\\n\\nthe client in many cases. But actions cut to the core of what OfferFit does and why the product is powerful.\\n\\nThe entire purpose of OfferFit is to tell clients what to do to best market to their customers. The “what” in this case is\\n\\ndetermined by actions defined as part of the implementation.\\n\\nImagine a simple Use Case, like the one explored in the exercise, where a food business is trying to optimize their\\n\\noffers to customers to get them to spend more money.\\n\\nThe client has a few requirements:\\n\\n– Under no circumstances can OfferFit give a discount of greater than 15%.\\n\\n– Discounts are only allowed on pizza, tacos, and burritos (no other items allowed).\\n\\n– Based on prior research, they know that emails to customers outside of business hours are extremely ineffective and may even create communication fatigue for customers, so they only want to allow communication between 9AM and 5PM.\\n\\nOfferFit – Confidential\\n\\n103\\n\\nUse Case Configuration\\n\\nActions Selecting possible actions\\n\\nAt first glance, it may seem trivial to derive a set of possible actions from these business requirements.\\n\\n– One action (in plain English) might be the following:\\n\\n– “Send the customer an email offering a 5% discount on pizza”\\n\\nHowever, things become a bit more complicated when considering exactly which options to pick and combine together.\\n\\n– With the discount, for example could be:\\n\\n– Offer discounts at 5% increments (e.g., 5%, 10%, 15%)\\n\\n– Offer discounts at 1% increments (e.g., 1%, 2%, 3%, etc.)\\n\\n– Offer discounts at arbitrarily granular increments (e.g., 1.01%, 2.27%, etc.)\\n\\nSimilar decisions exist for the other aspects, particularly the time of day.\\n\\n– E.g., Should the increments be minutes, hours, or more?\\n\\nOfferFit – Confidential\\n\\n104\\n\\nUse Case Configuration\\n\\nActions Large vs. small action space\\n\\nOn the one hand, having a large number of specific actions can be beneficial because it can allow the Agent to find\\n\\nvery specific patterns and optimize to a very fine point.\\n\\nHowever, a large action space comes with drawbacks, particularly the fact that learning these patterns takes longer and\\n\\nbecomes more difficult.\\n\\n– For example, if a Use Case only has three actions, exploring the entire action space for all kinds of customers is a\\n\\nquick endeavor.\\n\\n– The Agent will quickly learn which of the three actions is best in particular circumstances.\\n\\n– But at the same time, the outcomes may not be anything to brag about.\\n\\n– If there are only three actions, the “best” action may still not make a sufficient dent at the Use Case’s success\\n\\nmetric.\\n\\nContrast this with a case where the Agent has 1,000 actions to choose from.\\n\\n– The Agent will take a long time to be able to explore every different action under various circumstances, and it will\\n\\nbe slow to converge to a situation where it can comfortably produce “optimal” recommendations for each customer.\\n\\n– But when it does converge to that optimal solution, the results are likely to outperform the “three action” Use Case.\\n\\nOfferFit – Confidential\\n\\n105\\n\\nUse Case Configuration\\n\\nActions Achieving reasonable results with large action spaces\\n\\nThere are a couple of tricks to achieve reasonable results while still maintaining a relatively large action space.\\n\\nThe first one isn’t so much a trick as it is a property of the Use Case:\\n\\n– If there are a large number of customers in the audience, then a larger action bank is possible.\\n\\n– This is because OfferFit can explore the full range of actions in various scenarios by gathering experience over a\\n\\nlarge sample size.\\n\\n– With smaller customer populations, it would take much longer to gather comparable data.\\n\\n– Similarly, if customers are given recommendations frequently, the Agents gather experiences quicker than if\\n\\ncustomers are rarely given recommendations (e.g., 1 email per week vs 1 email per month)\\n\\nUnfortunately, OfferFit and/or the client cannot always control the size of the Use Case audience.\\n\\n– In these cases, there are still some things that can be done to alleviate the situation, but it requires a bit of thought.\\n\\n– This step is called “action parameterization”\\n\\n– The substance of the action is broken down to smaller components that can be used to summarize and\\n\\nuniquely identify an action.\\n\\nOfferFit – Confidential\\n\\n106\\n\\nUse Case Configuration\\n\\nActions Example breakdown of Action bank\\n\\nIt’s probably best to learn with an example. Consider the following three actions:\\n\\n– Send an email to the customer offering them a 5% discount on pizza.\\n\\n– Send an email to the customer offering them a 10% discount on tacos.\\n\\n– Send an email to the customer offering them a 15% discount on burritos.\\n\\nThe goal is to break down these actions into discrete components that can be used to represent the substance of what\\n\\nthe Agent is offering.\\n\\nIn this case, it’s pretty straightforward. The action parameterization can be summarized through the following table:\\n\\nDiscount\\n\\nFood Item\\n\\n5\\n\\npizza\\n\\n10\\n\\ntaco\\n\\n15\\n\\nburrito\\n\\nOfferFit – Confidential\\n\\n107\\n\\nUse Case Configuration\\n\\nActions Example breakdown of Action bank\\n\\nDiscount\\n\\nFood Item\\n\\n5\\n\\npizza\\n\\n10\\n\\ntaco\\n\\n15\\n\\nburrito\\n\\nThere are really only two items needed to capture the “meaning” of these actions:\\n\\n– the discount\\n\\n– the food item\\n\\nAlso note that each action (row) is completely different from every other row.\\n\\n– Individual columns can have repeated values.\\n\\n– If a 10% discount on pizza is offered, it is fine that the “food item” has been repeated.\\n\\nBut all of the columns, in combination, must be distinct from row to row.\\n\\n– Otherwise, the exact same action is being repeated, which could lead to undesirable results when the Agent starts\\n\\nlearning.\\n\\nOfferFit – Confidential\\n\\n108\\n\\nUse Case Configuration\\n\\nActions Messages and content ● Imagine that information on the contents of the message also exists, such as the body of the email. Here are a few example options (matching above):\\n\\nTake some time and try to think of some other parameterizations you would add to fully capture the example messages to the left.\\n\\na.\\n\\n“Hello! Come try our delicious pizza, cooked to order! We can also deliver right to your doorstep if you don’t feel like making the trip. Here is a discount to get your order started!”\\n\\nb.\\n\\n“For a limited time only, come and buy some tacos with this great discount. We recommend you enjoy them at a candle light dinner at our beautiful restaurant along with our famous wine pairings.”\\n\\nc.\\n\\n“Burritos, burritos, burritos! Big discounts, act now or regret it later!”\\n\\nTo get started, here are a couple of parameterizations that could be created\\n\\nbased on the above examples:\\n\\nUses Exclamation True False True\\n\\nMentions Delivery True False False\\n\\nHowever, many others may work as well. This type of parameterization is\\n\\nmore subjective (but just as important).\\n\\nOfferFit – Confidential\\n\\n109\\n\\nUse Case Configuration\\n\\nActions Speeding up learning\\n\\nParameterization is useful because it speeds up OfferFit’s learning.\\n\\nReminder of the action space dilemma discussed earlier:\\n\\n– A large action space gives the Agent ample opportunity to optimize, but can also slow down learning.\\n\\nThe core purpose of action parameterization is to speed up this learning by allowing the model to identify similarities\\n\\nbetween different actions.\\n\\nInstead of simply assigning each action a unique identifier and having the Agents work with that (which is still possible), a more detailed representation of the actions can be created so OfferFit can quickly find and exploit patterns between them.\\n\\n– Specifically, two actions that both offer pizza at a 10% discount (but have a different message) are more similar\\n\\nthan two actions that offer different food at different discounts with different messages.\\n\\nWith proper parameterization, OfferFit can become aware of these similarities and supercharge the speed at which it\\n\\nlearns\\n\\nOfferFit – Confidential\\n\\n110\\n\\nUse Case Configuration\\n\\nActions Final Reminders\\n\\nTo wrap up, remember to consider the following factors when selecting actions for a Use Case:\\n\\na. How granular are the actions (e.g., 1% discount vs 1.01% discount)?\\n\\nb. How many customers are in the Use Case audience?\\n\\nc. Can similarities and differences between the actions be highlighted with proper parametrization?\\n\\nWith these three things in mind, the chances of Use Case success radically increase.\\n\\nOfferFit – Confidential\\n\\n111\\n\\nUse Case Configuration\\n\\nAction Banks Overview\\n\\nIn the action bank section, various actions were defied that the Agent can suggest to best personalize the\\n\\nrecommendation to each individual customer.\\n\\nIt’s worth noting that each action relates to a particular dimension that was defined in the previous section. So a\\n\\n“message” action might be “send email X” or “send email Y”. And a “time” action might be “send at 8 AM” or “send at 12 PM”.\\n\\nEach action is assigned a set of values that are used to uniquely represent it.\\n\\nThese values, called action parameters, are the means through which the models are informed of the differences and\\n\\nsimilarities between the actions.\\n\\nTo summarize:\\n\\n– Each dimension has a set of options, these are called actions.\\n\\n– For example, the “time” dimension may have “10 AM”, “12 PM”, and “6 PM” actions in the action bank.\\n\\n– Each action has parameters that describe the action. These are called action parameters.\\n\\n– For example, the “Offer” action may include the percentage discount, the item that the offer relates to, and\\n\\nmuch more.\\n\\n– The entire set of these actions & action parameters is called the Action Bank.\\n\\nOfferFit – Confidential\\n\\n112\\n\\nUse Case Configuration\\n\\nAction Banks Template\\n\\nSince the Action bank creation process can often be a back-and-forth, as well as a cross-functional effort, it is often easier to use an excel external to the UI, especially to set up the initial action bank.\\n\\nNavigate to the Action bank section in your Use Case.\\n\\nOpen the Help Center side bar and click the “Add and remove actions” header to navigate to the help docs and download the Sample Actions file.\\n\\nTherefore, using the excel option for creating the Action bank may be\\n\\neasier than using the Portal itself.\\n\\nOften, Excel is used to align on with marketing team and upload the initial Action Bank. But, as the Use Case progresses and the client marketing team get ideas for new actions to try, these new actions can be added in the Portal interface directly.\\n\\nOfferFit – Confidential\\n\\n113\\n\\nUse Case Configuration\\n\\nAction Banks Excel Structure\\n\\nThere should be 2 sheets per dimension: dimension_fields & dimension_actions.\\n\\nEach dimension has a dimension_fields sheet.\\n\\n– This should contain one row for every action parameter that is associated with an action.\\n\\n– Each row in this table is an action parameter.\\n\\nEach dimension has a dimension_actions sheet.\\n\\n– This should contain every possible choice of actions for this dimension.\\n\\n– For each action, there is a column for each action parameter defined in the dimension_fields sheet.\\n\\n– Each row in this table is an action.\\n\\nNote that a category for each action parameter is a requirement in the dimension_actions sheet.\\n\\n– An action parameter can be classified as either a “parameter” or a “feature”.\\n\\n– The difference is that when the action parameter is classified as a “feature”, it is used by the Agents to make\\n\\nrecommendations. We provide guidelines for when to use a parameter as a features in the next explanatory page.\\n\\nOfferFit – Confidential\\n\\n114\\n\\nUse Case Configuration\\n\\nAction Bank\\n\\nTake 5-10 minutes to read the “INSTRUCTIONS” sheet of the file.\\n\\nMake a copy of this action bank file and name it “{usecase}_action_bank”, and in the new file:\\n\\n– Create the general structure of the excel by creating 2 sheets for each dimension:\\n\\n– Create the dimension_fields & dimension_actions sheet for the Offer dimension\\n\\n– Create the dimension_fields & dimension_actions sheet for the Time dimension\\n\\n– Create the dimension_fields & dimension_actions sheet for the Cadence dimension\\n\\nOfferFit – Confidential\\n\\n115\\n\\nUse Case Configuration\\n\\nAction Banks Configuration\\n\\nTo configure the action parameters in the dimension_fields sheets, an understanding of how action parameters\\n\\nclassified as “features” can be encoded is needed.\\n\\nAn action parameter only needs to be categorized as a feature if using it to make recommendations/predictions.\\n\\n– Specifically, if the model should to learn the similarity between actions by looking at this parameter, then it needs\\n\\nto be encoded as a feature.\\n\\nFor example, an “Offer” dimension may contains a field that represents the discount offered.\\n\\n– In that case, “discount” should be encoded as a feature because actions with similar discounts (e.g., 0.05, 0.06)\\n\\nare more similar to each other than actions with different discounts (e.g., 0.01, 0.20).\\n\\nOn the other hand, action parameters sometimes simply exist to help us understand the actions in plain language or are\\n\\nuseful for reporting purposes.\\n\\n– In these cases, the parameter does not need to be encoded as a feature.\\n\\nOfferFit – Confidential\\n\\n116\\n\\nUse Case Configuration\\n\\nAction Banks Encoding Options\\n\\nThere are 3 different encoding options for action features.\\n\\na.\\n\\nIdentity (allows us to extract raw values from a data asset and use them as features)\\n\\nb. One hot\\n\\nc. Ordinal\\n\\nIf an action feature is numeric (integer or float), then it will always be identity encoded.\\n\\nOtherwise, the feature can be encoded either by one-hot or ordinal.\\n\\nFeatures should be:\\n\\na. One-hot encoded if there is no intrinsic ordering between them (e.g., a type of food such as apple or banana).\\n\\nb. Ordinally encoded if there is an intrinsic ordering (e.g., low, medium, high).\\n\\nThe encoding order column in the dimension_fields sheet reflects this order. For ordinal, list the items from lowest to\\n\\nhighest. For one-hot feel free to order them in any way.\\n\\nOfferFit – Confidential\\n\\n117\\n\\nUse Case Configuration\\n\\nAction Bank Configuration (1 of 3)\\n\\nStart with configuring the action bank for the Offer dimension.\\n\\nUse the action options listed in the dimensions_actions sheets to deduce the parameter data type and configure the\\n\\noffer_fields sheet:\\n\\n– Offer dimension actions should have 4 parameters: action_id, discount, food_subject and message_length\\n\\n– The action_id parameter is required, and should be of the “parameter” category with an integer data_type. (Since\\n\\nit is NOT a feature, it does not need the encoding columns to be populated)\\n\\n– The discount, food_subject, and message_length parameter should be a feature.\\n\\nConfigure the offer_actions sheet\\n\\n– The columns in the sheet should be the 4 action parameters configured in the offer_fields sheet with the action_id\\n\\ncolumn as a column of unique integers\\n\\n– Create actions using the following option information:\\n\\n– The food_options include: pizza, taco, burrito, apple, banana\\n\\n– The options for discounts are: 0.01, 0.05, 0.1, 0.15, 0.2\\n\\n– The options for message_length are: short, long\\n\\n– Use this info to create 10 actions per food_subject\\n\\nOfferFit – Confidential\\n\\n118\\n\\nUse Case Configuration\\n\\nAction Bank Configuration (2 of 3) ● Configure the action bank for the Time dimension\\n\\n– Configure the time_fields sheet:\\n\\n– The time actions should have 2 action parameters. The required action_id and hour.\\n\\n– The hour parameter should be a feature, and is generally an integer data type.\\n\\n– Configure the time_actions sheet:\\n\\n– The columns in the sheet should be the 2 action parameters configured in the time_fields sheet with the\\n\\naction_id column as a column of unique integers.\\n\\n– The options for hour include: 8, 10, 12, 16\\n\\nConfigure the action bank for the Cadence dimension\\n\\n– Configure the cadence_fields sheet:\\n\\n– Cadence actions should have 8 action parameters (action_id and 1 parameter for each day of the week).\\n\\n– Each of the ‘day of the week‘ parameters should be “features”.\\n\\n– For cadence parameters, each value is a probability (between 0 and 1 inclusive) and data type is float\\n\\n– The parameter description for “monday” is “The probability that the user should receive a\\n\\ncommunication on a Monday.”\\n\\nOfferFit – Confidential\\n\\n119\\n\\nUse Case Configuration\\n\\nAction Bank Configuration (3 of 3)\\n\\nConfigure the action bank for the Cadence dimension (continued):\\n\\n– Create three actions\\n\\n– 3 sends per week\\n\\n– 5 sends per week\\n\\n– 7 sends per week\\n\\nThe probabilities (0-1) of sending each day should reflect the desired cadence. The probability value should be the\\n\\nnumber of desired sends per week / 7\\n\\nUpload the excel using the Import from XLSX button.\\n\\nTake a moment to see how this excel is transferred to the UI.\\n\\nToggle the dimensions dropdown to see the actions per dimension\\n\\nClick the table headers to see the action parameter details (info from dimension_fields)\\n\\nOfferFit – Confidential\\n\\n120\\n\\nUse Case Configuration\\n\\nEvents Overview\\n\\n\\n\\nFour types of events:\\n\\n–\\n\\nActivation: corresponds to some marketing action (e.g., sending an email) [Required]\\n\\n–\\n\\nEngagement: customer actions that are relevant to the Use Case (e.g., clicking on an email) [Recommended]\\n\\n–\\n\\nConversion: events that correspond to a “conversion” in the Use Case and form the basis of the target metric [Required]\\n\\n–\\n\\nPenalty: events corresponding to some undesired behavior (e.g., the customer unsubscribes from the email that was sent) [Recommended]\\n\\n\\n\\nThe data for events must be present on an asset that the client sends us. This becomes particularly important with Activation events.\\n\\n–\\n\\nIf customers actually take actions (e.g., send emails) based on OfferFit’s recommendations, that information needs to flow back into OfferFit’s data pipeline. Ideally this will be sent back with the rec ID and the action IDs.\\n\\nMarking some events as “events required for conversion attribution” provides more granular control over the attribution logic, especially in cases where multiple engagement events may exist prior to a conversion.\\n\\n–\\n\\nFor example, OfferFit could be configured to not associate any email with a conversion unless the customer has already opened the email.\\n\\n– Or the customer may even be required to click on the email link for the conversion to count.\\n\\nOfferFit – Confidential\\n\\n121\\n\\nUse Case Configuration\\n\\nEvents “Match By”, Attribution of outcomes (1 of 2)\\n\\nA lot important information (e.g., whether a customer opens an email) is stored purely on the client side.\\n\\n– OfferFit can make recommendations for each customer, but attributing certain outcomes (e.g., conversions) to\\n\\nthose recommendations is difficult without receiving additional information from the client.\\n\\nEvent data can be used to attribute outcomes to the actions OfferFit recommended in one of 4 ways:\\n\\n– Recommendation ID: When OfferFit generates recommendations for each customer, each set of recommendations (one for each dimension) is packaged together and assigned a single rec_id.\\n\\n– The client may elect to send the event data back to us with the rec_id attached, which would allow us to\\n\\nmatch the actions they took with the recommendations that OfferFit made.\\n\\n– Action ID: When OfferFit generates recommendations for each customer, in addition to the rec_id, OfferFit also\\n\\nsends the recommended action_id for each dimension.\\n\\n– This ID that OfferFit sends for each action should correspond to some identifier that the client has within their marketing system (e.g., OfferFit sends ID “7”, which corresponds to a specific email with specific content that should be sent to the customer).\\n\\n– The client may be able to send the event data to us with the action_ids attached, which allows us to match the\\n\\nevent to the recommendation OfferFit made.\\n\\nOfferFit – Confidential\\n\\n122\\n\\nUse Case Configuration\\n\\nEvents “Match By”, Attribution of outcomes (2 of 2)\\n\\n– Action Parameters: In cases where the clients are not able to send back identifiers that match IDs in OfferFit’s data pipeline, they may still have descriptive information in their system that can allow us to link back to specific actions.\\n\\n– For example, if the client has an action parameter called “discount”, and their marketing system stores the discount associated with emails, OfferFit can narrow down the list of possible matches by using this field.\\n\\n– Proximity: This is for instances where the client is unable to send us any data that is helpful in linking events to\\n\\nOfferFit’s recommendations.\\n\\n– If this option is selected, OfferFit will attribute all actions (e.g., conversions) that occurred after the\\n\\nrecommendation was made to the last recommendation.\\n\\nOfferFit – Confidential\\n\\n123\\n\\nUse Case Configuration\\n\\nEvents “Match By”, Precision of outcome attribution methods\\n\\nLeast Precise & Worst Performance\\n\\nMost Precise & Best Performance\\n\\nAction Parameters\\n\\nRecommendatio n ID\\n\\nProximity\\n\\nAction ID\\n\\nOfferFit – Confidential\\n\\n124\\n\\nUse Case Configuration\\n\\nEmails Asset Activation Events\\n\\nAs mentioned in the previous section, a Use Case cannot be fully implemented without an asset containing activation\\n\\nevents.\\n\\nPlease go back and configure the Emails asset in the pipeline\\n\\n– You can stop after Pre-process (Features are not needed for this asset).\\n\\nOfferFit – Confidential\\n\\n125\\n\\nUse Case Configuration\\n\\nEvents Set up Activation and Conversion events for this Use Case\\n\\nConversion Events\\n\\n– Create a conversion event based on the Transactions asset\\n\\n– Note that this asset does not contain any recommendation IDs or action IDs, or other action parameters [so, we will\\n\\nhave to match by Proximity]\\n\\n– Currently, there must be a field on the table defined as a target column for each conversion.\\n\\n– In this case, since the target metric is simply the number of records present in the transaction asset, the\\n\\nconversion_flag field had to be added, which always has a value of 1.\\n\\n– A more robust way of handling this type of conversion is coming to the product soon, but this is a required\\n\\nworkaround currently.\\n\\nActivation Events:\\n\\n– The emails asset tells us each time an email is sent to a customer.\\n\\n– The events matched based on proximity\\n\\nOfferFit – Confidential\\n\\n126\\n\\nUse Case Configuration\\n\\nReward Configuration Conversion Attribution Method\\n\\nThe events section specifies how observed outcomes are attributed to recommendations. Here, we decide how much to\\n\\n“reward” the agent for choosing an action that lead to some notable result.\\n\\nThere are two attribution methods for conversions currently implemented:\\n\\n– “Last Touch” if the Agent should be rewarded for the most recent matched recommendation to the customer.\\n\\n– For example, assume a conversion event is observed that was associated with a recommended action ID of 7.\\n\\n– During three different occasions over the last month, the Agent has recommended the action ID 7.\\n\\n– If Last Touch is the selected option, then only the most recent of the three will be credited with the result.\\n\\n– “All Touches” if the Agent should be rewarded for all matching recommendations that preceded the event.\\n\\n– Using the previous example, selecting this option will credit all of the prior recommendations with the result.\\n\\n– If multiple interactions leading up to a event can influence the event’s occurrence, then select this option.\\n\\nDays to Wait refers to the number of days OfferFit waits to check for the result and generate a training experience.\\n\\n– If a conversion, email open, or click occurs before the \"days to wait\", a training experience will not be created.\\n\\n– Waiting different amounts of time (e.g., 3 days for an email click, 7 days for a conversion) may be appropriate\\n\\ndepending on the Use Case.\\n\\nOfferFit – Confidential\\n\\n127\\n\\nUse Case Configuration\\n\\nReward Configuration Reward Types (2 of 2)\\n\\nPrimary Reward: This is almost always linked directly to the specified “conversion event”.\\n\\n– This is the main source of reward for the Agent and the core event that the recommendations are hoping to drive.\\n\\nSecondary Reward: Each trigger can have one (optional) secondary reward.\\n\\n– This is not something that qualifies as a full “conversion”, but it is something that is sufficiently proximate to a conversion such that encouraging the occurrence of this event is likely to indirectly lead to an increase in conversions.\\n\\n– A secondary reward can be defined to allow the Agents to learn initially, after the Use Case goes live, since there will be few Conversion experiences to begin with. The secondary rewards will guide the Agents toward actions that result in earlier indicators of later conversion (e.g., email clicks).\\n\\n– A couple of notes here:\\n\\n– The trigger event for the secondary reward should be in the middle between the activation event (e.g., email\\n\\nsent) and the conversion event (e.g., purchase made).\\n\\n– Email clicks are much better secondary reward triggers than email opens, since email opens are often not accurately reported by the customer’s email system while email clicks are more reliable (this is assuming a Use Case with email offers where the customer needs to go to a link in the email to redeem).\\n\\nOfferFit – Confidential\\n\\n128\\n\\nUse Case Configuration\\n\\nReward Configuration Reward Types (2 of 2)\\n\\nPenalty Reward: This should be directly linked to a defined penalty event (if applicable). Unlike the other rewards, a\\n\\nvalue (magnitude) must be set to penalize the Agent when the penalty event occurs.\\n\\n– This value should be the expected loss in the target metric if that customer unsubscribes (i.e., the difference in\\n\\nvalue of the customer being subscribed to the marketing channel vs not being subscribed).\\n\\n– Notice that a unsubscribed customer can still convert, that\\'s why we define the penalty value as “difference in\\n\\ntarget metric value from being subscribed”\\n\\n– In some cases this value may not be simple estimate\\n\\n– For example, the unsubscription may not only affect OfferFit Use Cases, but all communications from the\\n\\nClient. This should lead to a larger penalty.\\n\\n– In these scenarios, case-by-case estimation is required\\n\\nOfferFit – Confidential\\n\\n129\\n\\nUse Case Configuration\\n\\nCustomer Groups Audience\\n\\nSeveral sections ago, the Customer population was configured.\\n\\nAudience\\n\\n– This is the set of all customers that OfferFit will compute features\\n\\n– For both the offer and the\\n\\nfor.\\n\\ntime dimension:\\n\\nHowever, there can be multiple Use Cases for a single set of features.\\n\\n– Create a Trigger Event based on email sends\\n\\nAs a result, OfferFit needs a way to further filter down the customer\\n\\npopulation to those eligible for the given Use Case.\\n\\n– Set the Days to Wait to 1\\n\\nCustomer Groups\\n\\n– This is called the Audience.\\n\\nThe purpose of the audience is to allow multiple Use Cases with different target audiences to re-use the same pipeline logic without needing to build a new pipeline.\\n\\n– Set the audience for this Use\\n\\nCase to only include customers who are opted into marketing.\\n\\nOfferFit – Confidential\\n\\n130\\n\\nUse Case Configuration\\n\\nCustomer Groups Audience Breakdown\\n\\nIn this section, customers are split into the “treatment” group and the control group(s).\\n\\n\\n\\nThe treatment group will receive the predictions generated by the OfferFit product, and the control groups will receive actions according to one of several possibilities:\\n\\n–\\n\\nRandom action: the customer will be recommended an action from the action bank at random\\n\\n–\\n\\nSpecified action: all customers will receive the same specific action from the action bank\\n\\n–\\n\\nSend no action: OfferFit will not recommend any actions from the action bank for the customers in this control group. This is most often used when the client wants to operate “business as usual” for this control group and they do not need any information at all from OfferFit about these customers.\\n\\nOfferFit has two common ways of splitting the groups:\\n\\n–\\n\\nThe client may send us their desired group for each customer directly on the asset, in which case OfferFit uses the filters on that field to assign the customers to the group\\n\\n–\\n\\nAssuming that the customer_ids are generated at random (virtually always true), the “endswith” operation can split up the groups according to the last few digits of the customer_id.\\n\\n–\\n\\nFor example, if 20% of customers should be in control A (and all IDs are numeric), then OfferFit can be configured to put all customers that end with 4 or 7 in the control group.\\n\\nOfferFit – Confidential\\n\\n131\\n\\nUse Case Configuration\\n\\nCustomer Groups Audience Breakdown\\n\\nA maximum number of recommendations per day for\\n\\nFor this example, there will just be the OfferFit group\\n\\neach customer can be set.\\n\\nand the Control group.\\n\\nFor the control group:\\n\\n– This is typically used during the go-live period\\n\\nas part of an incremental rollout.\\n\\n– Customers with an ID that end in 3 or 7 should\\n\\n– E.g., by increasing the maximum after an initial week, once we see that all recommendations are correctly activated and all expected events are being received.\\n\\nbe in the group\\n\\n– Set no max recommendations per day\\n\\n– Select random action\\n\\nWhen OfferFit is first starting to send\\n\\nrecommendations, it is a best practice to limit the number of sends until everything is working smoothly.\\n\\nThis limit may be changed as data stability,\\n\\nconfidence, and understanding in the Use Case increases. The limit is often lifted over time.\\n\\nOfferFit – Confidential\\n\\n132\\n\\nCreate the following guardrails\\n\\nUse Case Configuration\\n\\naccording to the client’s business requirements\\n\\nGuardrails\\n\\nFoodCo research has shown that customers who prefer apples hate burritos:\\n\\nGuardrails allow for the elimination of specific pairings (e.g., customer, action) to eliminate the possibility that those customers will receive specific action(s).\\n\\n– Create a guardrail on the Offer\\n\\ndimension that will prevent users from receiving offers on Burrito if their favorite food is Apple.\\n\\nMost often needed when the client wants to place restrictions on the type\\n\\nof customer who can receive particular offers.\\n\\nFor example, if the client is a Pet Food store, they may want to prohibit customers who do not own a dog from receiving discounted dog food.\\n\\nFoodCo does not want to insult their best customers with low offers:\\n\\nGuardrails can be created from:\\n\\n– Create a guardrail that prevents\\n\\ncustomers in the platinum tier from receiving offers that are less than a 5% discount.\\n\\n– Customer features\\n\\n– Action parameters\\n\\nFoodCo does not open for delivery\\n\\n– Predicted values\\n\\norders until 10 AM\\n\\nFor example, if the client does not want to send recommendations if the\\n\\nAgent thinks the offer would result in losing money.\\n\\n– Create a guardrail that does not\\n\\nsend emails at 8 AM to customers who do delivery 50% or more of the time.\\n\\n– In this case, the guardrail would be keeping recs if\\n\\nexpected_reward >= 0.\\n\\nOfferFit – Confidential\\n\\n133\\n\\nUse Case Configuration\\n\\nFeatures to Use\\n\\nThis tab allows us to determine which features are used in the model vs\\n\\nRemove all features that add no value to the project\\n\\nthose that are not.\\n\\nGenerally speaking, the main purpose of this screen is to remove\\n\\nfeatures that do not have any value to us.\\n\\nThese “useless” features can most commonly be identified by looking at\\n\\nthe standard deviation value.\\n\\n– If the standard deviation is 0 for a feature, it means that all of the\\n\\nvalues are identical and cannot be used to distinguish between customers.\\n\\nAs a result, they might as well be removed from the model since they do\\n\\nnot provide us with any information.\\n\\nKeep in mind that setup often occurs with sample data.\\n\\n– So, even if the features are all identical in the sample, this may not\\n\\nhold true when OfferFit start receiving daily product data.\\n\\nOfferFit – Confidential\\n\\n134\\n\\nUse Case Configuration\\n\\nOutputs\\n\\n\\n\\nSend all action parameters to\\n\\nAt this point, we have everything need to send recommendations to the client.\\n\\nthe client\\n\\n\\n\\nSend the feature that\\n\\nThis screen is simply concerned with what data will actually be sent to the client in each recommendation.\\n\\nrepresents the percentage of emails opened\\n\\n\\n\\nAt an absolute minimum, OfferFit needs to be able to send the actions that it recommends to the client so the client can take this information and activate the appropriate recommendation to the customer.\\n\\n– The client wants to use\\n\\nthis in reporting\\n\\n–\\n\\nImportant to note here that OfferFit does not take action/activate recommendations on behalf of clients.\\n\\n– OfferFit sends the client recommendations, and the client triggers the activation events from their own systems.\\n\\n\\n\\nHowever, the client might want more information, such as customer features or action parameters, so they can do additional reporting/analysis internally.\\n\\nOfferFit – Confidential\\n\\n135\\n\\nLunch (60 min)\\n\\nFrom A/B To AI\\n\\nOfferFit – Confidential OfferFit – Confidential\\n\\n136 136\\n\\nStand up!\\n\\nWhen you hear “Up”, tilt your head up and look at the ceiling (only your\\n\\nhead, not the body).\\n\\nEnergizer Old habits die hard…\\n\\nWhen you hear “Down”, “left,” or “right” tilt your head in the appropriate\\n\\ndirection\\n\\nOfferFit – Confidential\\n\\n137\\n\\n2d\\n\\nData discovery & integration architecture\\n\\nOfferFit – Confidential\\n\\n138\\n\\nData discovery & integration architecture\\n\\nTypical data companies feed into OfferFit varies by company More data is generally better, but should be balanced with ease of implementation\\n\\nEssential:\\n\\n– Unique customer identifier: needed for OfferFit to generate recommendations per customer\\n\\n– Success metric outcomes: what actually happened after OfferFit-recommended actions were executed\\n\\n– Activations based on OfferFit: what was actually sent based on OfferFit’s recommendations\\n\\nGood to have:\\n\\n– Customer profile: years as customer; demographics, if allowed in this industry (age, sex, education, income); geography, if allowed in this industry; psychographics (e.g., interests/affinities, lifestyle, values/motivations); acquisition channel (e.g., web, phone); satisfaction level; model scores (e.g., churn propensity); lifetime value estimate\\n\\n– Transactions: products purchased by date (including product attributes); transaction amounts; transaction\\n\\nchannels (e.g., in-store, online); payment methods\\n\\n– Marketing: outbound communications sent (e.g., emails, SMS, postal); email engagement (e.g., opens,\\n\\nclicks); survey responses (e.g., NPS, engagement); web and mobile app activity (e.g., pages browsed/products viewed)\\n\\n– Usage: account logins; device type and operating system used for logins; customer service interactions\\n\\n(e.g., number of calls, topics); product usage (e.g., hours used per day, features accessed)\\n\\nOfferFit – Confidential\\n\\n139\\n\\nData discovery & integration architecture\\n\\nExample: New Zealand telco data Customer level data\\n\\nCustomer data\\n\\nProduct data\\n\\nBilling and payment data\\n\\nCustomer usage data\\n\\nNon-PII data\\n\\nProduct attributes such as services included\\n\\nHow much is the\\n\\nData usage (uploads,\\n\\ncustomer charged for all the services\\n\\ndownloads)*\\n\\nIncludes location\\n\\n*Important to see how fast the customer is consuming his/her data\\n\\nHow long does the customer take to pay\\n\\nTechnical customer experience data\\n\\nCustomer interaction data\\n\\nCustomer acquisition data\\n\\nCustomer device data\\n\\nWhy is the customer calling to company\\n\\nHow did the company acquire the customer\\n\\nMobile technology\\n\\nDowntime or network\\n\\nfailure\\n\\nQ&A (complaints,\\n\\nCustomer tenure\\n\\nReduced quality of service because of network congestion\\n\\nbilling understanding, balance check, among others)\\n\\nOfferFit – Confidential\\n\\n140\\n\\nData discovery & integration architecture\\n\\nExample: Bank small business credit card referrals data\\n\\nOfferFit – Confidential\\n\\n141\\n\\nData discovery & integration architecture\\n\\nStandard integration approach Fully supported without custom work by implementation team\\n\\n3rd party\\n\\nweb\\n\\nmobile\\n\\nothers\\n\\nSystem component\\n\\nInformation flow, i/o\\n\\nChannel specific\\n\\nActivation Tool(s)\\n\\nClient Data Lake\\n\\n4. Client sets up process for activating recommendations (e.g., send email X to customer Y)\\n\\n1. Client sets up pipeline to upload data files into OfferFit GCP bucket\\n\\n3. Client sets up pipeline for downloading recommendation file back into their data lake\\n\\nCommunication\\n\\nEngagement (e.g., opens, clicks)\\n\\nCustomers\\n\\nOfferFit Google Cloud Environment\\n\\nweb\\n\\nmobile\\n\\n2. OfferFit software processes input datasets and produces recommendations\\n\\nDecisioning Engine\\n\\nInput Data Storage\\n\\nOfferFit\\n\\nGCP Cloud Storage\\n\\nOfferFit – Confidential\\n\\n142\\n\\nData discovery & integration architecture\\n\\nIntegration approach Custom input integration web\\n\\nSystem component\\n\\nInformation flow, i/o\\n\\n3rd party\\n\\nmobile\\n\\nothers\\n\\nChannel specific\\n\\n4. Client sets up process for activating recommendations (e.g., send email X to customer Y)\\n\\nClient Data Lake\\n\\nActivation Tool(s)\\n\\n1a. Client cannot upload data directly into GCP bucket, instead, uploads somewhere else\\n\\n3a. Client downloads recommendation file back into their data lake.\\n\\nCommunication\\n\\nEngagement (e.g., opens, clicks)\\n\\nData Landing (e.g., SFTP)\\n\\n1b. Implementation team builds a cloud function that transfers the files into the GCP bucket.\\n\\n3b. Implementation team builds a custom process for moving recommendation file back to data landing.\\n\\nGoogle cloud functions\\n\\nCustomers\\n\\nOfferFit Google Cloud Environment\\n\\nweb\\n\\nmobile\\n\\nDecisioning Engine\\n\\nInput Data Storage\\n\\n2. OfferFit software processes input datasets and produces recommendations\\n\\nOfferFit\\n\\nGCP Cloud Storage\\n\\nOfferFit – Confidential\\n\\n143\\n\\nData discovery & integration architecture\\n\\nIntegration approach Custom output integration\\n\\nSystem component\\n\\nInformation flow, i/o\\n\\n3rd party\\n\\nweb\\n\\nmobile\\n\\nothers\\n\\nChannel specific\\n\\nActivation Tool(s)\\n\\nClient Data Lake\\n\\n3. Implementation team builds a pipeline for interacting with activation tool REST API to directly deliver recommendations\\n\\nCommunication\\n\\nEngagement (e.g., opens, clicks)\\n\\n1. Client sets up pipeline to upload data files into OfferFit GCP bucket\\n\\nGoogle cloud functions\\n\\nCustomers\\n\\nOfferFit Google Cloud Environment\\n\\nweb\\n\\nmobile\\n\\nDecisioning Engine\\n\\nInput Data Storage\\n\\n2. OfferFit software processes input datasets and produces recommendations\\n\\nOfferFit\\n\\nGCP Cloud Storage\\n\\nOfferFit – Confidential\\n\\n144\\n\\nData discovery & integration architecture\\n\\nExample integration approach Fast food company that used mParticle (CDP) and Braze (Email)\\n\\nSystem component\\n\\nInformation flow, i/o\\n\\n3rd party\\n\\nweb\\n\\nmobile\\n\\nothers\\n\\nChannel specific\\n\\nEmail Activation\\n\\n4. Client set up process for activating recommendations\\n\\nInput Data\\n\\nOutput Decisions\\n\\n1. Client set up mParticle native integration to upload data files into OfferFit GCP bucket\\n\\n3. Implementation team built a pipeline for interacting with activation tool REST API to directly deliver recommendations\\n\\nCommunication\\n\\nEngagement (e.g., opens, clicks)\\n\\nGoogle cloud functions\\n\\nCustomers\\n\\nOfferFit Google Cloud Environment\\n\\nweb\\n\\nmobile\\n\\nDecisioning Engine\\n\\nInput Data Storage\\n\\n2. OfferFit software processes input datasets and produces recommendations\\n\\nOfferFit\\n\\nGCP Cloud Storage\\n\\nOfferFit – Confidential\\n\\n145\\n\\nBreak (30 min)\\n\\nFrom A/B To AI\\n\\nOfferFit – Confidential OfferFit – Confidential\\n\\n146 146\\n\\nUse Case Design Simulation World Sail We have been running a pilot with an international cruise ship company called World Sail, helping them personalize offers for loyal customers. The scope of the pilot is to cross-sell credit cards to customers who have booked packaged cruises & flights to Europe or the Caribbean. Our current cross-sell Use Case targets maximizing credit card sign ups by ingesting passenger loyalty information, preferences, and purchase history. Decisions are passed to email, in-app, and “in cruise” offers where a customer is offered a specific offer while boarding their next cruise.\\n\\nThe CMO is thrilled with the results and wants to expand OfferFit throughout the organization. Your next step is to identify the possible expansion use cases and design what that use case may look like.\\n\\nOver the next 15 minutes please:\\n\\n1.\\n\\nBrainstorm potential Use Cases for World Sail\\n\\n2.\\n\\nSelect the best Use Case\\n\\n3. Develop a Use Case Design proposal which includes:\\n\\na.\\n\\nTarget Metric\\n\\nb. Audience\\n\\nc.\\n\\nExperiment Dimensions\\n\\nd. Guardrails\\n\\ne. Control(s)\\n\\nIn 40 minutes our judges will use the best-practices and rubrics provided in this training to rate each use case’s probability of success and easy of implementation.\\n\\nOfferFit – Confidential\\n\\n147\\n\\nImplementation Partner Training: Day 3\\n\\nDallas, November 2022\\n\\nConfidential – Any use of this material without specific permission of OfferFit, Inc. is strictly prohibited\\n\\nNuff said…\\n\\nLoser of the losers bracket gets a 10 point deduction at bowling this\\n\\nevening.\\n\\nEnergizer Rock, Paper, Scissors Tournament\\n\\nWinner of the winners bracket gets a 10 point bonus at bowling this\\n\\nevening.\\n\\nOfferFit – Confidential\\n\\n149\\n\\n2e Reports and Insights\\n\\nOfferFit – Confidential\\n\\n150\\n\\nReports and Insights\\n\\nGoing Live\\n\\nOnce a use case is fully configured, it’s time to “go live” with the client. At a high level, this process involves:\\n\\n– Working with your client and OfferFit to take the configuration you created through the Portal and deploy a\\n\\npipeline that will use it on a daily basis.\\n\\n– Watching as the agent recommends new actions each day. Some of these actions will yield conversions, and these\\n\\nconversions will form the basis for comparison between the OfferFit groups and the control groups.\\n\\n– Monitoring the performance of the use case (using the functionality described on the next slide), identifying any\\n\\npotential defects with the setup, and remediating those issues.\\n\\nMore functionality to support go-lives is in the works, but for now, you will need to ask an OfferFit engineer to “migrate”\\n\\nyour setup each time a change has been created and tested through the Portal after the use case has gone live.\\n\\nOfferFit – Confidential\\n\\n151\\n\\nReports and Insights\\n\\nReporting\\n\\nAs a Use Case is running live, performance is monitored and analysed to provide clients with performance reports and\\n\\ninsights.\\n\\nThese reports can be viewed through the “Reports” tab in the Portal.\\n\\nReporting is presented in a per-Use Case view, with the following structure:\\n\\n– Key performance metrics: uplift, average conversions and target metric statistics. These are shown for each\\n\\ncontrol & treatment group.\\n\\n– Target metric over time chart: this chart visualizes the target metric (e.g., ARPU or conversion rate) over time,\\n\\nwith cumulative sum, 7 day rolling average and 4 week rolling average as the aggregation options.\\n\\n– Personalization insights: this section is a series of charts that show correlated customer features and customer\\n\\nactions, based on the model’s decisions. For example, if certain customer features, such as age, correlate with the time of day recommendations are sent out.\\n\\nOfferFit – Confidential\\n\\n152\\n\\n3a Troubleshooting\\n\\nOfferFit – Confidential\\n\\n153\\n\\nTroubleshooting\\n\\nCommon issues and modes of failure 1 of 2\\n\\nRecommendations are not being sent\\n\\n– Verify that activations today match recommendations made the previous day (any discrepancies should be\\n\\ninvestigated)\\n\\n– In some cases, we’re not expecting all recommendations to be activated (e.g., inbound phone). If so, verify that\\n\\nexpected amount of activations are created\\n\\nInput data pipeline is not reliable - data is late or doesn’t arrive\\n\\n– If this is rare, that’s not a problem (as long as missing data is included in next day’s push)\\n\\n– If this happens often (more than a few days per month), it’ll impact performance\\n\\nActivations are not being delivered with high fidelity through certain channels\\n\\n– E.g., some phone agents ignore recommendations; an app bug prevents the user from seeing the offer\\n\\n– Check that conversions are in the expected range per channel (e.g., if one channel has 0.3% conversion and\\n\\nanother channel has 0.01% conversion rate, investigate why)\\n\\nConfiguration error leads to unintended / incorrect recommendations\\n\\n– Check for right number of daily recommendations, expected number of Control and OfferFit recommendations\\n\\n– Check that recommendations are not violating guardrails (i.e., no mistakes in guardrail setup)\\n\\nOfferFit – Confidential\\n\\n154\\n\\nTroubleshooting\\n\\nCommon issues and modes of failure 2 of 2 ● Actions are not very impactful\\n\\n– If two control groups (1) no intervention, and (2) BAU are used, review uplift of BAU relative to no intervention\\n\\n– If small, actions may not be impactful and we should explore potential changes with the client\\n\\n– If no intervention target metric is significant (e.g., customers purchase without receiving marketing recommendations), measure uplift with respect to the difference between BAU and no intervention\\n\\n– This will show if the BAU impacts the metrics at all\\n\\nLearning is slow\\n\\n– Ensure auctions are well parameterized\\n\\nNumber of activations (2k-10k per month) or conversion percent rate is small\\n\\n– Ensure there’s a secondary reward configured\\n\\nRecommendations don’t make sense\\n\\n– Verify distribution of recommended actions over time makes sense (e.g., did not have any unexpected spikes\\n\\n– Check that the insights make logical sense (e.g., are they realistic?)\\n\\n– SHAP analysis showing which features most strongly influence agent decisions – at least some actions features\\n\\nshould appear in top 30% or so\\n\\nOfferFit – Confidential\\n\\n155\\n\\n3b\\n\\nRoadmap and Q&A\\n\\nOfferFit – Confidential\\n\\n156\\n\\nRoadmap and Q&A\\n\\nImplementation partner led\\n\\nTypical Implementation timeline\\n\\nClient led\\n\\nApproval Checkpoint\\n\\nWeek 0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10\\n\\n11\\n\\n12\\n\\n13\\n\\n14\\n\\n15\\n\\n16\\n\\n2\\n\\n1\\n\\nDesign the approach 2 weeks\\n\\nSet up marketing assets 3 weeks\\n\\nMarketing Setup\\n\\n3 Set up daily data feed to OfferFit 3 weeks\\n\\n4\\n\\nClean and process data 3 weeks\\n\\nTech Setup\\n\\n5\\n\\n6\\n\\nConnect to activation channels 4 weeks\\n\\nConfigure Use Case 2 weeks\\n\\n4 weeks\\n\\n7\\n\\nGo live & Monitor 7 weeks\\n\\nPilot\\n\\nOfferFit – Confidential\\n\\n157\\n\\nRoadmap and Q&A\\n\\nMilestones with highest likelihood of delays\\n\\nTypical Implementation timeline\\n\\nWeek 0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10\\n\\n11\\n\\n12\\n\\n13\\n\\n14\\n\\n15\\n\\n16\\n\\n2\\n\\n1\\n\\nDesign the approach 2 weeks\\n\\nSet up marketing assets 3 weeks\\n\\nMarketing Setup\\n\\n3 Set up daily data feed to OfferFit 3 weeks\\n\\n4\\n\\nClean and process data 3 weeks\\n\\nTech Setup\\n\\n5\\n\\n6\\n\\nConnect to activation channels 4 weeks\\n\\nConfigure Use Case 2 weeks\\n\\n4 weeks\\n\\n7\\n\\nGo live & Monitor 7 weeks\\n\\nPilot\\n\\nOfferFit – Confidential\\n\\n158\\n\\nRoadmap and Q&A\\n\\nImplementation process details\\n\\nEngagement Manager Time\\n\\n# Step\\n\\nActivities\\n\\nClient Team Members Duration\\n\\nData Engineering Time\\n\\n●\\n\\nConfirm timeline go live date Teams identified and working cadence established\\n\\nSponsor Senior Project Leader\\n\\n\\n\\n0\\n\\nUse Case Kickoff\\n\\n●\\n\\nDefine target metric Determine decisioning dimensions and choices (“action bank”) ○\\n\\nSponsor Senior Project Leader Creative Lead\\n\\nDesign the approach\\n\\n1\\n\\n2 weeks\\n\\nIncludes email and app offers Define precise customer population\\n\\n\\n\\n●\\n\\nSet up marketing assets\\n\\nDetermine which existing marketing assets to use (If needed) Create additional marketing assets\\n\\n2\\n\\nCreative Lead\\n\\n3 weeks\\n\\n\\n\\nImplement automatic daily transfer of anonymized customer data to OfferFit client answers questions about the data structures\\n\\n7 days (56 hours)\\n\\nSet up daily data feed to OfferFit\\n\\n5.25 days (42 hours)\\n\\n3\\n\\nData Lead\\n\\n3 weeks\\n\\n\\n\\n● ●\\n\\nClean raw data Set up automated feature engineering Set up daily automated data validation\\n\\nClean and processes the data\\n\\n4\\n\\n3 weeks\\n\\n\\n\\nImplement automatic daily activation based on OfferFit’s recommendations (can do via flat file transfer or have OfferFit team set up API connection)\\n\\nConnect to activation channels\\n\\n5\\n\\nActivation Lead\\n\\n4 weeks\\n\\nOfferFit configures Use Case\\n\\n\\n\\n6\\n\\nConfigure AI Agents, guardrails, reports, etc.\\n\\n2 weeks\\n\\nGo live ● Monitor performance (including uplift vs. Control) ●\\n\\nGo live and Monitor\\n\\n7\\n\\n7 weeks\\n\\n3 days (32 hours)\\n\\n1.25 days (10 hours)\\n\\nShare insights\\n\\nOfferFit – Confidential\\n\\n159\\n\\nRoadmap and Q&A\\n\\nClient stakeholders to be aware of\\n\\nRole\\n\\nDescription\\n\\nStakeholder Name\\n\\nSponsor\\n\\nSenior owner for the Pilot and beyond\\n\\nOversees the implementation; can sometimes be the same person as the executive sponsor or the day-to-day project leader\\n\\nSenior project leader\\n\\nDay-to-day project leader\\n\\nProvides day-to-day management of the pilot\\n\\nData lead\\n\\nSets up daily data feed\\n\\nSets up daily automated activation (based on OfferFit recommendations)\\n\\nActivation lead\\n\\nProvides any additional creative assets (e.g., emails, keywords, landing pages)\\n\\nCreative lead\\n\\nEnsures alignment in the org; typically consists of 5–10 stakeholders, including C-level leaders from relevant functions (e.g., Marketing, IT, Analytics)\\n\\nSteering Committee members\\n\\nOfferFit – Confidential\\n\\n160\\n\\n3c\\n\\nClosing\\n\\nOfferFit – Confidential\\n\\n161\\n\\nRoadmap and Q&A\\n\\nJoint OfferFit and Implementation Partner working model (hypothesis) This model will be adjusted and refined over time as the first jointly run customers are completed ● First joint implementations:\\n\\n– A customer will be identified from OfferFit’s existing sales pipeline which is prepared to launch a full\\n\\nimplementation immediately.\\n\\n– This customer will be introduced to the implementation partner as a certified OfferFit implementation team which\\n\\ncan also help with other services they may need as part of the implementation.\\n\\n– OfferFit will staff a full implementation team to support the implementation partner’s team and provide help\\n\\nneeded throughout the implementation.\\n\\n– OfferFit’s Strategic Account Director and Customer Success teams will lead all scoping and use case design while\\n\\nengaging fully during the implementation phase.\\n\\n– OfferFit Customer Success team will coordinate tools for technical documentation and approvals of use cases\\n\\nLong term aspiration:\\n\\n– We hope to jointly develop new client’s by collaborating with each other and sharing opportunities to collaborate\\n\\non (using crossbeam).\\n\\n– OfferFit’s Strategic Account Director and Customer Success teams will collaborate on all scoping and use case\\n\\ndesign while managing stakeholders during the implementation phase\\n\\n– Implementation Partners will have access to OfferFit’s implementation experts and leaders for ad hoc support\\n\\nOfferFit – Confidential\\n\\n162\\n\\nRoadmap\\n\\nDeployed product\\n\\nUse Case Design\\n\\nOfferFit’s strategy: expand from lifecycle marketing with app ecosystem\\n\\nOfferFit Experimentation Engine Configurable reinforcement learning (RL) system\\n\\nConfiguration Manager Service for adding and modifying abstracted engine instructions\\n\\nApps Interfaces for self-serve configuration & reporting aligned to Use Case families\\n\\nModules Delivery accelerators (data model & Use Case config templates) aligned to industries\\n\\nTelco module\\n\\nOfferFit Lifecycle Marketing App\\n\\nAPI\\n\\nVideo gaming module\\n\\nAction\\n\\nOther industry modules\\n\\nOfferFit Acquisition Marketing App\\n\\nAPI\\n\\nAPI\\n\\nContext\\n\\nDecision Agents\\n\\nEnvironment\\n\\nOfferFit Dynamic Pricing App\\n\\nAPI\\n\\nReward\\n\\nOther OfferFit-built and 3rd Party Apps\\n\\nAPI\\n\\nCompute Infrastructure (Google Cloud Platform)\\n\\nOfferFit – Confidential\\n\\n163\\n\\nClosing\\n\\nOfferFit’s vision: the age of automated experimentation\\n\\nLong term\\n\\nBeyond 5 years\\n\\nManufacturing\\n\\nCustomer service\\n\\nScientific\\n\\nMedium term\\n\\nexperimentation (e.g., pharmaceuticals)\\n\\nNext 2-5 years\\n\\nAcquisition marketing\\n\\nA wide range of\\n\\n(e.g., paid ads)\\n\\nadditional applications in business & beyond\\n\\nDynamic pricing\\n\\nCurrent focus\\n\\nOther marketing Use Cases\\n\\nNext 2 years\\n\\nLifecycle marketing\\n\\nOfferFit – Confidential\\n\\n164\\n\\nClosing\\n\\nThe Implementation Partnership Team\\n\\nCaitlin Hoffman\\n\\nSamuel Jackson\\n\\nAvery Bub\\n\\nCustomer Success, Manager\\n\\nMarketing and Partnerships, Director\\n\\nSoftware Engineer, Python\\n\\ncaitlin@offerfit.ai\\n\\nsamuel@offerfit.ai\\n\\navery@offerfit.ai\\n\\nTanya Zorya\\n\\nVictor Kostyuk\\n\\nJim Depeng Jin\\n\\nSoftware Engineer, Full Stack\\n\\nCo-founder, CTO\\n\\nCustomer Success, Sr. Director\\n\\ntanya@offerfit.ai\\n\\nvictor@offerfit.ai\\n\\njim@offerfit.ai\\n\\nOfferFit – Confidential\\n\\n165\\n\\ngo.offerfit.ai/survey\\n\\nOfferFit – Confidential\\n\\n166', metadata={'source': 'allFiles/OfferFit Implementation Partner Training Manual (2).pdf'}), Document(page_content='Article Classiﬁcation of Monkeypox Images Based on Transfer Learning and the Al-Biruni Earth Radius Optimization Algorithm\\n\\nAbdelaziz A. Abdelhamid 1 Doaa Sami Khafaga 6,*\\n\\n, El-Sayed M. El-Kenawy 2,*\\n\\n, Nima Khodadadi 3\\n\\n, Seyedali Mirjalili 4,5,*\\n\\n,\\n\\n, Amal H. Alharbi 6, Abdelhameed Ibrahim 7\\n\\n, Marwa M. Eid 8\\n\\nand Mohamed Saber 9\\n\\n1 Department of Computer Science, Faculty of Computer and Information Sciences, Ain Shams University,\\n\\nCairo 11566, Egypt\\n\\n2 Department of Communications and Electronics, Delta Higher Institute of Engineering and Technology,\\n\\nMansoura 35111, Egypt\\n\\n3 Department of Civil and Environmental Engineering, Florida International University, Miami, FL 33199, USA 4 Centre for Artiﬁcial Intelligence Research and Optimization, Torrens University Australia,\\n\\nFortitude Valley, QLD 4006, Australia\\n\\n5 Yonsei Frontier Lab, Yonsei University, Seoul 03722, Korea 6 Department of Computer Sciences, College of Computer and Information Sciences, Princess Nourah bint\\n\\nAbdulrahman University, P.O. Box 84428, Riyadh 11671, Saudi Arabia\\n\\n7 Computer Engineering and Control Systems Department, Faculty of Engineering, Mansoura University,\\n\\nMansoura 35516, Egypt Faculty of Artiﬁcial Intelligence, Delta University for Science and Technology, Mansoura 11152, Egypt Electronics and Communications Engineering Department, Faculty of Engineering, Delta University for Science and Technology, Gamasa City 11152, Egypt\\n\\n8\\n\\n9\\n\\nCorrespondence: skenawy@ieee.org (E.-S.M.E.-K.); ali.mirjalili@torrens.edu.au (S.M.);\\n\\nCitation: Abdelhamid, A.A.;\\n\\ndskhafga@pnu.edu.sa (D.S.K.)\\n\\nEl-Kenawy, E.-S.M.; Khodadad, N.;\\n\\nAbstract: The world is still trying to recover from the devastation caused by the wide spread of COVID-19, and now the monkeypox virus threatens becoming a worldwide pandemic. Although the monkeypox virus is not as lethal or infectious as COVID-19, numerous countries report new cases daily. Thus, it is not surprising that necessary precautions have not been taken, and it will not be surprising if another worldwide pandemic occurs. Machine learning has recently shown tremendous promise in image-based diagnosis, including cancer detection, tumor cell identiﬁcation, and COVID-19 patient detection. Therefore, a similar application may be implemented to diagnose monkeypox as it invades the human skin. An image can be acquired and utilized to further diagnose the condition. In this paper, two algorithms are proposed for improving the classiﬁcation accuracy of monkeypox images. The proposed algorithms are based on transfer learning for feature extraction and meta-heuristic optimization for feature selection and optimization of the parameters of a multi- layer neural network. The GoogleNet deep network is adopted for feature extraction, and the utilized meta-heuristic optimization algorithms are the Al-Biruni Earth radius algorithm, the sine cosine algorithm, and the particle swarm optimization algorithm. Based on these algorithms, a new binary hybrid algorithm is proposed for feature selection, along with a new hybrid algorithm for optimizing the parameters of the neural network. To evaluate the proposed algorithms, a publicly available dataset is employed. The assessment of the proposed optimization of feature selection for monkeypox classiﬁcation was performed in terms of ten evaluation criteria. In addition, a set of statistical tests was conducted to measure the effectiveness, signiﬁcance, and robustness of the proposed algorithms. The results achieved conﬁrm the superiority and effectiveness of the proposed methods compared to other optimization methods. The average classiﬁcation accuracy was 98.8%.\\n\\nMirjalili, S.; Khafaga, D.S.; Alharbi,\\n\\nA.H.; Ibrahim, A.; Eid, M.M.; Saber,\\n\\nM. Classiﬁcation of Monkeypox\\n\\nImages Based on Transfer Learning\\n\\nand the Al-Biruni Earth Radius\\n\\nOptimization Algorithm. Mathematics\\n\\n2022, 10, 3614. https://doi.org/\\n\\n10.3390/math10193614\\n\\nAcademic Editors: Rui Peng and\\n\\nKaiye Gao\\n\\nReceived: 14 September 2022\\n\\nAccepted: 27 September 2022\\n\\nPublished: 2 October 2022\\n\\nPublisher’s Note: MDPI stays neutral\\n\\nwith regard to jurisdictional claims in\\n\\npublished maps and institutional afﬁl-\\n\\niations.\\n\\nCopyright: © 2022 by the authors.\\n\\nLicensee MDPI, Basel, Switzerland.\\n\\nThis article is an open access article\\n\\nKeywords: Al-Biruni Earth radius optimization; transfer learning; deep learning; feature selection; monkeypox diagnosis; meta-heuristic optimization\\n\\ndistributed under\\n\\nthe terms and\\n\\nconditions of the Creative Commons\\n\\nAttribution (CC BY) license (https://\\n\\nMSC: 68T01; 68T07; 68T20; 68T42\\n\\ncreativecommons.org/licenses/by/\\n\\n4.0/).\\n\\nMathematics 2022, 10, 3614. https://doi.org/10.3390/math10193614\\n\\nhttps://www.mdpi.com/journal/mathematics\\n\\nMathematics 2022, 10, 3614\\n\\n2 of 29\\n\\n1. Introduction\\n\\nAs the globe was shaken by the outbreak of COVID-19 in 2020, reports of the arrival of monkeypox in 2022 show yet another global virus [1]. This virus is closely linked to cowpox and smallpox. Monkeys and rodents are the primary vectors of transmission, although human-to-human transmission is also widespread [2]. In 1958, a laboratory in Copenhagen, Denmark, discovered the virus for the ﬁrst time in a monkey [3]. In 1970, amid an increased attempt to eliminate smallpox [4,5], the ﬁrst human case of monkeypox was documented in the Democratic Republic of the Congo. It is common knowledge that many people who live in close proximity to tropical rainforests in Central and West Africa fall victim to the highly contagious monkeypox virus. Physical contact with an infected human, animal, or object is sufﬁcient for the virus to spread. Transmission occurs by saliva, nasal secretions, or respiratory droplets [5]. It can also be spread via animal bites. Patients infected with monkeypox experience a range of short-term symptoms, including fever, pains, weariness, and red bumps on the skin in the long run [6,7].\\n\\nDespite the fact that the reported instances of monkeypox are on the rise, the disease is not nearly as infectious as COVID-19 has been. In 1990, only ﬁfty people in West and Central Africa contracted monkeypox [8]. However, by 2020, there were 5000 reported instances. Although it was previously believed that monkeypox exclusively occurred in Africa, numerous non-African nations, including Europe and the United States, reported identifying monkeypox infections in people in 2022. As a result, widespread panic and worry are rising; many individuals are airing their concerns on online platforms. According to CDC recommendations, no effective therapy exists for the monkeypox virus at the present time. Two oral medications, Brincidofovir and Tecovirimat, which were previously only used to treat the smallpox virus, have been licensed for treatment against the monkeypox virus by the Centers for Disease Control and Prevention [9]. Nonetheless, the monkeypox virus may be effectively combated by immunization. Despite the availability of FDA- approved vaccinations against the monkeypox virus, none have been administered to humans in the United States. Treatment for monkeypox in other countries typically involves the use of smallpox vaccinations [10]. Monkeypox is diagnosed using a combination of the patient’s medical history and the peculiarities of the skin lesions themselves. However, electron microscopy testing of skin lesions is the gold standard for conﬁrming a viral infection. Moreover, the monkeypox virus can be validated by polymerase chain reaction (PCR) [11], a technique that is already being widely employed in the diagnosis of COVID-19 patients [12–15].\\n\\nMachine learning (ML) is a burgeoning ﬁeld of AI that has shown great promise in a variety of settings, from decision-making assistance and industrial applications to medical imaging and illness detection. Medical professionals have found that the safe, accurate, and quick imaging solutions made possible by ML are invaluable resources for making informed decisions. For the purpose of breast cancer diagnosis, for instance, CAD systems based on fuzzy logic were created by the authors of [16]. When compared to traditional ML, fuzzy logic is superior, since it can speed up computational tasks while mimicking the logic and approach of a trained radiologist. The cancer detection algorithm delivers a result based on the user’s selected method if they input information such as contour, density, and shape [17]. The authors of [18] used a small dataset of 108 patients with COVID-19 and 86 non-COVID-19 patients to assess ten different deep learning models and achieved 99.1% accuracy. Using 453 CT scan images, the authors of [19] built a modiﬁed Inception-based model and improved its accuracy to 73.1%. Psoriasis, melanoma, lupus, and chickenpox are only a few of the skin illnesses that may be detected with the use of the low-complexity convolutional neural network (CNN) suggested by the authors of [20]. They demonstrated that skin illness can be detected 71% of the time utilizing image analysis with an already- existing VGGNet. The proposed approach showed the best performance, with accuracy of about 78%. Using MobileNet and smartphones, the authors of [21] developed a method for diagnosing skin diseases. They reported an accuracy of 94.4% when identifying individuals with chickenpox symptoms.\\n\\nMathematics 2022, 10, 3614\\n\\n3 of 29\\n\\nAt the time of writing, few studies have been uncovered that show promise for the use of ML methods in the diagnosis of monkeypox using image processing. The lack of a framework developed for image-based diagnosis of monkeypox was due to the lack of a publicly available dataset for training and testing purposes, as the virus has just recently been substantially introduced in many countries.\\n\\nIn light of these opportunities, a signiﬁcant conclusion was reached: that it is necessary to develop a new approach for robustly diagnosing monkeypox images and ﬁll this gap. To ﬁll it, this paper proposes two new algorithms for improving the selection of the best set of features and improving a classiﬁer’s performance. These two algorithms are based on the Al-Biruni Earth radius (BER) algorithm, the sine cosine algorithm (SCA), and particle swarm optimization (PSO). The feature selection is based on a new hybrid of SCA and BER, whereas the optimization of the classiﬁer’s parameters was based on a new hybrid of PSO and BER. To prove the effectiveness of the proposed algorithms, a set of experiments were conducted, and the results are compared to those of other competing feature selection and parameter optimization algorithms. Statistical tests were conducted to show the stability of the proposed algorithms, and the results conﬁrmed the target outcome.\\n\\nThe remainder of the paper follows this outline: The literature review is presented in Section 2, followed by the materials and methods employed in this paper in Section 3. The proposed optimization algorithms are discussed in Section 4. Then, the experiment results and their ﬁndings are described in Section 5. Finally, the suggestions for future research are summarized and discussed in Section 6.\\n\\n2. Literature Review\\n\\nMedical diagnoses and treatments are two areas where ML and deep learning have shown to be invaluable. Researchers have built a variety of models and systems that use ML and deep learning to make illness predictions. There is currently no reliable diagnostic test for Alzheimer’s disease. Diagnosis should involve the patient’s medical background, the results of cognitive and laboratory testing, and maybe an electroencephalogram (EEG). Consequently, innovative approaches are needed to guarantee earlier and more accurate diagnoses and to track treatment success. The authors of [22] used a machine learning approach called support vector machine (SVM) to search EEG epochs for traits that might identify Alzheimer’s disease patients from controls. To automatically identify AD patients from healthy controls, a processing approach based on quantitative EEG (qEEG) was developed. Accuracy was good in the research because it accounted for how each patient was diagnosed.\\n\\nHeart disease is one of the top ﬁve main causes of death worldwide today. The fore- casting of cardiovascular illness is a major challenge in the ﬁeld of clinical data analysis. Machine learning has shown itself to be capable of extracting useful information from the mountains of data produced by the healthcare industry. Several studies have merely scratched the surface of how machine learning may be used to forecast heart illness. The authors of [23] suggested a novel method to enhance the accuracy of cardiovascular disease prediction by locating crucial features using machine learning methods. A number of different feature combinations and well-established classiﬁcation algorithms were tested in the prediction model [24,25].\\n\\nDiagnosis of Parkinson’s disease (PD) is often made after careful medical observation and study of clinical indicators. In many cases, a wide variety of motor symptoms must be deﬁned in order to complete this examination. Traditional diagnostic procedures, however, rely on the subjective assessment of movements that might be difﬁcult to detect. Machine learning also facilitates the integration of data from many modalities, such as MRI and SPECT, for PD diagnosis [26]. Applying machine learning algorithms may help us ﬁnd relevant qualities that are underutilized in the clinical diagnosis of PD and which might be relied on to diagnose PD in preclinical stages or atypical forms.\\n\\nIn the clinic, fatty liver disease is common and is associated with an increased risk of mortality (FLD). Early prediction of FLD patients offers the opportunity to create a\\n\\nMathematics 2022, 10, 3614\\n\\n4 of 29\\n\\nworkable plan for prevention, early diagnosis, and therapy. To aid in the detection of at-risk individuals, diagnosis itself, and the prevention and management of FLD, the authors of [27] developed a machine-learning model to predict the onset and progression of the disease. A variety of classiﬁcation models, such as logistic regression (LR), random forest (RF), Naive Bayes (NB), and an artiﬁcial neural network (ANN), were developed for FLD prediction. The receiver operating characteristic curve area was used to evaluate the efﬁcacy of the four models (ROC). The authors of [27] developed and studied four classiﬁcation algorithms that reliably identify fatty liver disease. However, when compared to other classiﬁcation strategies, the random forest model fared the best. Primary prevention, monitoring, early treatment, and care of patients with fatty livers might all beneﬁt from the adoption of a random forest model in the clinical environment.\\n\\nChronic kidney disease (CKD) is a serious threat to health and well-being, and it affects an alarmingly growing number of individuals throughout the world. In its early stages, CKD typically presents no symptoms; hence, its presence is often overlooked. Medication that slows the course of CKD is most effective when given to patients soon after diagnosis. Machine-learning models can greatly assist therapists in achieving this objective because of their rapid and accurate identiﬁcation capabilities. A machine-learning strategy for CKD diagnosis was proposed by the authors of [28]. The CKD dataset, which is heavily skewed by missing values, was contributed from the machine learning repository at UCI [29]. Patients may forget or be unable to provide some measures for several reasons. Therefore, it is common to ﬁnd gaps in the data in clinical practice. In order to generate models, six machine-learning techniques were used when the missing data were added. The random forest model had the highest diagnostic accuracy (99.75%) compared to the others. After analyzing the mistakes of the preexisting models, it was proposed to use a combined model, including logistic regression and a random forest employing a perceptron, which could achieve an average accuracy of 99.83 percent after ten simulation repetitions. This led us to speculate that this approach can be used to analyze clinical data in order to diagnose more complicated diseases better.\\n\\nIn order to reliably identify coronary artery disease, the authors of [30] introduced a revolutionary machine-learning technique (CAD). Ten time-tested approaches to machine learning were considered. The effectiveness of these strategies was improved by the appli- cation of data standardization and preprocessing. Particle swarm optimization, a form of genetic algorithm, was used in tandem with stratiﬁed ten-fold cross-validation to optimize feature selection and classiﬁer parameters in concurrently. Experimental results showed that the suggested approach considerably enhanced the accuracy of the machine-learning models used in medical and scientiﬁc research.\\n\\nMonkeypox has recently emerged as a signiﬁcant global health concern; there are con- ﬁrmed cases in 75 countries outside of Africa. Early clinical identiﬁcation of monkeypox is challenging due to the virus’s similarity to chickenpox and measles. Where conﬁrmatory polymerase chain reaction (PCR) tests are not readily available, computer-assisted detec- tion of lesion morphology may aid in the monitoring and rapid diagnosis of individuals infected with monkeypox. Automatic skin lesion detection using deep-learning algorithms has been shown to be effective when sufﬁcient training instances are provided. Due of monkeypox’s rarity, there was already a knowledge vacuum among medical specialists throughout the world before the current outbreak. Scientists are taking heart from the successes of supervised machine learning in the discovery of COVID-19 as they attempt to ﬁnd a remedy for this perplexing issue. However, implementing machine learning to detect monkeypox from patient skin images is hampered by a lack of monkeypox skin photos.\\n\\nThe biggest monkeypox skin image database was given by the authors of [31]. With the help of web scraping, now a comprehensive picture collection of both healthy and sick skin for anybody can be found and used. Images of infected skin show symptoms of measles, cowpox, chickenpox, smallpox, and monkeypox. Pictures of measles, chickenpox, and monkeypox skin lesions were compiled by the authors of [32] to create the Monkeypox Skin Lesion Dataset (MSLD). The majority of these pictures came from publicly accessible\\n\\nMathematics 2022, 10, 3614\\n\\n5 of 29\\n\\nsources, including websites, news portals, and case reports. Initial procedures involved augmenting the sample size with more data and conducting a 3-fold cross-validation trial. In the second stage, pre-trained deep learning models such as VGG-16, ResNet50, and InceptionV3 were used to classify illnesses into different categories (e.g., monkeypox). The maximum overall accuracy was reached by ResNet50. Using a modiﬁed version of VGG16, the authors of [33] proposed a deep learning model for detecting monkeypox disease based on image data collection and implementation. It is safer to use and dissemi- nate such data for constructing and implementing any machine-learning model because the dataset was assembled by collecting images from multiple open-source publications and websites. Two different investigations used the VGG16 model with the adjustments. The ﬁndings from both trials indicate that this model may reliably identify patients with monkeypox. More insight into the features of the monkeypox virus can be achieved due to the model’s ability to predict and extract such features.\\n\\n3. Materials and Methods\\n\\nThe primary materials and methods employed in this work to implement the proposed approaches are detailed in this section. Achieving the greatest outcomes begins with feature engineering and continues with the iterative use of meta-heuristic optimization approaches. Therefore, the next sections start with presenting the methods used in feature engineering, followed by the utilized optimization methods.\\n\\n3.1. Feature Engineering\\n\\nMachine-learning approaches rely heavily on feature engineering methods. These methods involve picking and choosing features that machine-learning pipelines will need. In the literature, feature selection and feature extraction are often used interchangeably. The goal of a feature extraction procedure is to modify the raw data in order to derive new variables that can improve the performance of the machine-learning algorithm. In contrast, the goal of feature selection is to extract and identify the speciﬁc features in the dataset that are most useful for the classiﬁcation tasks based on a set of criteria, such as originality, consistency, and meaningfulness. Binary values (both 0 and 1) are utilized to limit the search space in order to implement the feature selection procedure. As a result, the continuous values-based meta-heuristic optimizers will need to be updated so they can deal with the binary outputs corresponding to the selected features [34,35].\\n\\nFeature selection is the most important part of feature engineering, since it determines which features will be used to optimize for performance. Each feature in the n-feature set can be assigned the value 1 or 0 to indicate whether or not it is part of the ﬁnal solution in the feature selection job. In order to identify the best set of features, meta-heuristic algorithms often begin with a random population of vectors with random features and then conduct a sequence of exploration and exploitation. The coming sections brieﬂy introduce the deep neural network employed for feature extraction using transfer learning. These deep networks include AlexNet, VGG, ResNet, and GoogleNet. As GoogleNet was the deep network adopted for feature extraction, it is presented in more detail in the next sections. On the other hand, the other deep networks are presented brieﬂy, as they were used for comparison purposes.\\n\\n3.1.1. AlexNet Deep Network\\n\\nBy achieving a top-5 test error rate of only 15.3% on a subset of the ImageNet dataset, AlexNet was declared the winner of ILSVRC-2012. Dropout was used in the model to pre- vent overﬁtting, and convolution operations were implemented using graphics processing units. AlexNet, when it was ﬁrst released, was the biggest convolution neural network ever built [36].\\n\\nMathematics 2022, 10, 3614\\n\\n6 of 29\\n\\n3.1.2. VGG Deep Network\\n\\nWhen it came to localization and classiﬁcation, the VGG models came out on top and in second place, respectively, in the 2014 ImageNet Challenge. With very deep convolutional networks (16 and 19 weight layers), the models achieved top-5 test error rates of 6.8% and 25.3% in the ILSVRS classiﬁcation and localization tracks, respectively, by making efﬁcient use of the smallest available ﬁlter sizes [37].\\n\\n3.1.3. ResNet Deep Network\\n\\nThe basic ResNet was developed in response to the degradation issue in deep neural networks; it was inspired by the VGG nets. In this context, “degradation” means that the network’s performance on test and training data declines as its depth grows. When it comes to identity mapping, the ResNet model takes the fast route by using a shortcut connection whose output is simply added to the stacked layer’s ﬁnal result. With no need to worry about the network degrading over time, a deeper network may be created and trained. A considerably deeper ResNet, an ensemble (i.e., eight times deeper than VGG nets), led to reduced complexity, simple optimization, and an enhanced top-5 error rate in comparison to state-of-the-art models of 3.57% [38].\\n\\n3.1.4. GoogleNet Deep Network\\n\\nGoogLeNet and the rest of the Inception model deep learning family are built on iterations of an Inception module [39]. Using a network-within-a-network strategy, the In- ception module does its best to approximate the convolutional vision network’s local sparse structure. GoogLeNet, a model developed by Google, achieved top-5 error accuracy of 6.67%, making it the winner of the ILSVRC 2014 competition. Inception versions 1–4 and Inception–ResNet are two variants of GoogLeNet that may be accessed by the gen- eral public. As a network inside a network, Inception has a spatial repetition of the best local sparse structure of a visual network. Inception uses 11 inexpensive convolutions to compute reductions before resorting to the 33 or 55 more resource-intensive convolutions. An example of a high-capability architecture that served as a model for our own design is GoogleNet. New concepts, algorithms, and enhanced network topologies are just as important as more processing power, larger datasets, and more complex models when it comes to improving identiﬁcation capabilities. The architecture of the GoogleNet deep network is shown in Figure 1. In this work, the GoogleNet deep network was adopted for feature extraction based on the results achieved compared to those of other deep networks.\\n\\n3.2. Multi-Layer Neural Network\\n\\nIn the neural network (NN) model known as the multi-layer perceptron [40], the neu- rons in the interstitial spaces between the several hidden layers are interconnected [41]. Figure 2 depicts the model architecture of the developed NN employed for classifying the selected features of the input images. The developed NN makes use of both practice and experimentation in its parameter selection. The parameters of this NN are optimized using the proposed meta-heuristic optimization algorithm. The details of the optimization algorithm and the optimized parameters are presented and discussed in the next sections.\\n\\nMathematics 2022, 10, 3614\\n\\n7 of 29\\n\\nFigure 1. Architecture of GoogleNet, the deep network employed for feature extraction based on transfer learning.\\n\\nFigure 2. Architecture of the neural network employed for monkeypox classiﬁcation.\\n\\nMathematics 2022, 10, 3614\\n\\n8 of 29\\n\\n3.3. Meta-Heuristic Optimization\\n\\nIn this paper, three optimization algorithms, namely, Al-Biruni Earth radius (BER), the sine cosine algorithm (SCA), and particle swarm optimization (PSO), were utilized. These algorithms were used to develop two new hybrid optimization algorithms for feature selection and NN parameter optimization. In this section, the basics of these algorithms are presented; then, the proposed hybrid optimization algorithms are explained in the next section.\\n\\n3.3.1. Al-Biruni Earth Radius (BER) Optimization Algorithm\\n\\nThe calculation of earth radius based on Al-Biruni method is depicted in Figure 3. This method forms the basis of Al-Biruni Earth Radius (BER) optimization algorithm. Finding the optimal solution within speciﬁed constraints is the work of optimization algorithms. Each member of the population can be represented by a S vector in the BER algorithm: S = S1, S2, ..., Sd ∈ R, where Sd is the dimension of the search space and d is the dimension of the parameter or feature being optimized. It is proposed that success up to some limit be measured using the ﬁtness function F. Using these stages of the optimization procedure, populations may be searched for a ﬁtness-maximizing vector S∗. To begin, a sample of the population is chosen at random (solutions). Before BER can begin optimizing, a number of factors must be speciﬁed, including the ﬁtness function, the minimum and maximum allowed solution sizes, the population size, the dimensions, and the number of solutions. Exploration and exploitation operations form the backbone of the BER algorithm as explained in the following.\\n\\nExploration Operation: This operation is responsible for locating promising areas of the search space and breaking through local optimum stasis on the way to the best possible solution.\\n\\n\\n\\n– Moving towards the best solution: Using this strategy, the solitary explorer will scout out the immediate region around its current location for potentially fruitful new exploration sites. One way to accomplish this is by using an iterative process to search for a more optimal option (with respect to ﬁtness) from the numerous available choices nearby. BER analysis uses the following formulas to accomplish this goal:\\n\\ncos(x) 1 − cos(x)\\n\\nr = h\\n\\n(1)\\n\\nD = r1(S(t) − 1)\\n\\n(2)\\n\\nS(t + 1) = S(t) + D(2r2 − 1)\\n\\n(3)\\n\\nwhere 0 < x ≤ 180, h is a number that is randomly selected from the range [0, 2], r1 and r2 are coefﬁcient vectors whose values are measured by Equation (1), S(t) is the solution vector at iteration t, and D is the diameter of the circle in which the search agent will look for promising areas.\\n\\nExploitation Operation: The exploiting group is accountable for improving current solutions. When a cycle ends, the BER calculates the ﬁtness of each participant and awards those with the best scores. The BER employs two unique strategies to achieve the aim of exploitation, both of which are outlined in the following.\\n\\n\\n\\n– Moving towards the best solution: The following equation is employed to move\\n\\nin the direction of the best solution.\\n\\nS(t + 1) = r2(S(t) + D)\\n\\n(4)\\n\\nD = r3(L(t) − S(t))\\n\\n(5)\\n\\nMathematics 2022, 10, 3614\\n\\n9 of 29\\n\\nwhere r3 is a random vector calculated using Equation (2) that controls the movement steps towards the best solution, S(t) is the solution vector at iteration t, L(t) is the best solution vector, and D refers to the distance vector. Searching the area around the best solution Generally speaking, the region around the optimal response offers the most potential for success (leader). As a result, some people will hunt for ways to enhance the situation by investigat- ing alternatives that are somewhat similar to the best one. To implement the aforementioned process, BER employs the following equation.\\n\\n–\\n\\nS(cid:48)(t + 1) = r(S∗(t) + k)\\n\\n(6)\\n\\n2 × t2 Max2\\n\\nk = 1 +\\n\\n(7)\\n\\niter\\n\\nwhere the best solution is denoted bu S∗(t), which is selected after comparing S(t + 1) and S(cid:48)(t + 1). The following equation is used to mutate the solution if the best ﬁtness was not changed in the last two iterations.\\n\\ncos(x) 1 − cos(x)\\n\\nS(t + 1) = k ∗ z2 − h\\n\\n(8)\\n\\nwhere z is a random number in the range [0, 1] and t is the iteration number.\\n\\nSelection of the best solution: To ensure that the solutions are of excellent quality, the BER chooses the best ones to employ in the next cycle. While the elitism technique is more effective, it may lead multi-modal functions to converge too soon [42,43]. By taking a mutational approach and scanning the area surrounding the explorers, the BER is able to deliver cutting-edge exploration capabilities. With its robust explo- ration capabilities, the BER is able to stave off convergence. First, parameters such as population size, mutation frequency, and iteration count are input into the BER. The BER then assigns individuals to either the exploration group or the exploitation group. The BER method dynamically modiﬁes the size of each group throughout the iterative process of locating the best solution. Two approaches are used by each group to complete their missions. The BER ensures diversity and thorough exploration by shufﬂing the order of responses between repetitions. In one iteration, a solution may be part of the exploration group, but by the next, it may be part of the exploitation group. Due to the BER’s exclusive nature, the leader will not be deposed during the procedure.\\n\\n\\n\\nFigure 3. The measurement of Earth’s radius using the Al-Biruni method.\\n\\nMathematics 2022, 10, 3614\\n\\n10 of 29\\n\\n3.3.2. Sine Cosine Algorithm\\n\\nThe sine cosine algorithm (SCA) was initially introduced in [44]. Based on Figure 4, it can be noted that the oscillation functions of sines (and cosines) have an important role in determining the optimal solution sites. To express the operations of SCA, a collection of random variables is employed [45].\\n\\n• • •\\n\\nThe motion direction. The movement location. Emphasizing/de-emphasizing the destination effect. Swapping between the sine and cosine components.\\n\\nFigure 4. The process of the sine cosine optimization algorithm.\\n\\nThe update process of the candidate solutions is performed using the following\\n\\nequation.\\n\\n(cid:40)\\n\\nP(t) + r5 · sin(r6) · |r7S∗(t) − S(t)| P(t) + r5 · cos(r6) · |r7S∗(t) − S(t)|\\n\\nr4 < 0.5 r4 ≥ 0.5\\n\\nP(t + 1) =\\n\\n(9)\\n\\nin which t is the number of search iterations. Current and best solutions are referred to as S and S∗. The values of [0 − 1] are allocated to the random variables r4, r6, and r7. For example, as can be seen from the equation, the locations of the best solutions inﬂuence the present solution’s position, making it easier to get to an ideal solution. The value of r4 is changed as follows during the running iterations of SCA.\\n\\na × t tmax\\n\\nr4 = a −\\n\\n(10)\\n\\nwhere a is a constant, and t and tmax represent the current and maximum iterations, respectively.\\n\\nThe SCA algorithm is more resilient than a broad range of meta-heuristic approaches in the literature because it uses just one optimal solution to lead the other solutions. Compared to other algorithms, this algorithm’s convergence speed and memory usage are quite low [45]. Nevertheless, as the number of local optimum solutions grows, the algorithm’s efﬁciency declines. Since the local optima can become stagnant, the SCA optimizer and the GWO algorithm are incorporated into the proposed algorithm to take advantage of their\\n\\nMathematics 2022, 10, 3614\\n\\n11 of 29\\n\\nfast convergence rates and memory efﬁciency, and to ensure a healthy ratio of exploration to exploitation tasks during the optimization process.\\n\\n3.3.3. Particle Swarm Optimization\\n\\nThe particle swarm optimization (PSO) methodology is based on mimicking the forag- ing behavior of ﬂocking animals such as birds using an optimization tool that outperforms the group intelligence approach. Some technical optimization issues can be solved with the PSO method, which was developed after observing this class of animal foraging patterns. All particles in the PSO algorithm have an adjustable value, and their search velocity and range are controlled by the speed at which they move, as shown in Figure 5. Particles then conduct their solution space search from the optimal particle’s position in the population. Particles keep themselves current during the search process by monitoring two extreme values: the individual extremum Pbest, which is the optimal solution discovered by an individual particle, and the global extremum gbest, which is the ideal solution currently found by the whole group. A scenario where the particles are looked for in a D-dimensional target space is considered, where a group of N particles live together. The i-th particle’s velocity throughout its journey is a D-dimensional vector:\\n\\nVi = (Vi1, Vi2, ..., ViD), i = 1, 2, ..., N\\n\\n(11)\\n\\nEach particle’s particular extremum, deﬁned as its best possible position in the solution\\n\\nspace, is represented by the notation:\\n\\nPbest = Pi1, Pi2, ..., PiD, i = 1, 2, ..., N\\n\\n(12)\\n\\nAs long as the particle locates both the local and global extrema, it can modify its\\n\\ncurrent velocity and position using the following formulas.\\n\\nVid(t + 1) = w ∗ Vid(t) + c1r1(Pb − Pid(t)) + c2r2(P∗ − Pid(t))\\n\\n(13)\\n\\nPid(t + 1) = Pid(t) + Vid(t + 1) (14) where the global extremum is denoted by P∗, w refers to the inertia weight, and the learning factors c1 and c2 are selected arbitrarily in the range between 0 and 2. Vim refers to the particle velocity, and r1 and r2 are random numbers between 0 and 1.\\n\\nMathematics 2022, 10, 3614\\n\\n12 of 29\\n\\nFigure 5. Particle swarm optimization.\\n\\n4. The Proposed Methodology\\n\\nIn this section, two proposed hybrid optimization algorithms are explained for im- proving the feature selection optimization of NN parameters. The ﬁrst algorithm is based on particle swarm optimization and Al-Biruni Earth radius optimization algorithms and is referred to as PSOBER. The binary version of this algorithm is used for feature selection. The second algorithm is based on the sine cosine algorithm (SCA) and the Al-Biruni Earth radius (BER) optimization algorithm and is referred to as SCBER. The proposed algorithms exploit the advantages of both algorithms they use for better selection of the best solution. Figure 6 depicts the stages of the proposed approach. As shown in the ﬁgure, the ﬁrst stage is the data processing, which includes image resizing, data augmentation, and feature extraction. This stage focuses on preparing the input images and increasing the number of images, and then extracting the relevant features using GoogleNet. The second stage, on the other hand, is the feature selection, which involved the proposed feature selection algorithm. The target of this stage is to select the most effective features that can accuracy classify the input images. The advantage of this stage is that is reduces the number of features extracted by the deep learning by excluding the irrelevant features. Finally, the third stage is the optimization of the neural network’s parameters using the proposed optimization algorithm. The target of this step is to choose the best set of parameters for classiﬁcation. The following sections discuss the details of the proposed feature selection and parameter optimization algorithms.\\n\\nMathematics 2022, 10, 3614\\n\\n13 of 29\\n\\nFigure 6. The stages of the proposed monkeypox classiﬁcation methodology.\\n\\n4.1. The Proposed PSOBER Optimization Algorithm\\n\\nThe feature selection process employed in this work is based on the proposed hybrid particle swarm optimization (PSO) algorithm and Al-Biruni Earth radius (BER) optimiza- tion algorithm, and it is denoted by PSOBER. The steps of PSOBER are presented in Algorithm 1. In this algorithm, the collaboration between the BER and PSO algorithms ﬁnds the best solutions. During the search process, the BER algorithm operates in even- number iterations. The PSO algorithm works in odd-number iterations, as presented in Line 5 of the algorithm. This interchanging operation of the BER and PSO allows for better exploration and exploitation of the search process. The achieved results, explained in the next section, conﬁrm this achievement.\\n\\nMathematics 2022, 10, 3614\\n\\n14 of 29\\n\\nAlgorithm 1 The PSOBER optimization algorithm.\\n\\n1: Initialize PSOBER population Pi(i = 1, 2, ..., d), Vi(i = 1, 2, ..., d) with size d, iterations\\n\\nMaxiter, ﬁtness function Fn, t = 1, n1, n2, r1, r2, r3, r4, r5, c1, c2\\n\\n2: Calculate ﬁtness function Fn for each Pi 3: Find best solution as P∗ 4: while t ≤ Maxiter do if t%2 == 0 then 5: 6:\\n\\nfor (i = 1 : i < n1 + 1) do Update r = h cos(x) 1−cos(x) Calculate D = r1(P(t) − 1) Update positions to head toward best solution as P(t + 1) = P(t) + D(2r2 − 1)\\n\\n7:\\n\\n8: 9:\\n\\nend for for (i = 1 : i < n2 + 1) do\\n\\n10: 11: 12:\\n\\nCalculate D = r3(L(t) − P(t)) Update positions of best solution as P(t + 1) = r2(P(t) + D) Calculate k = 1 + 2×t2 Max2 Investigate area around best solution as P(cid:48)(t + 1) = r1(P∗(t) + k) Compare P(t + 1) and P(cid:48)(t + 1) to select best solution P∗ if best ﬁtness is not changed for last two iterations then\\n\\n13:\\n\\n14:\\n\\niter\\n\\n15:\\n\\n16: 17:\\n\\nMutate solution as P(t + 1) = k ∗ z2 − h cos(x) 1−cos(x)\\n\\n18:\\n\\nend if end for\\n\\n19: 20: 21: 22: 23:\\n\\nelse\\n\\nfor each particle i = 1, ..., N do\\n\\nfor each dimension d = 1, ..., n do\\n\\nUpdate the particle’s velocity using: Vid(t + 1) = wVid + c1r1(Pid − Pid(t)) + c2r2(P∗ − Pid(t)) Update the particle’s position using: Pid(t + 1) = Pid(t) + Vid(t + 1)\\n\\n24:\\n\\n25:\\n\\nend for\\n\\n26:\\n\\nend for\\n\\n27: 28: 29: Update the ﬁtness function Fn for each Pi 30: Update BER parameters, t = t + 1 31: end while 32: Return P∗\\n\\nend if\\n\\n4.2. The Proposed Binary PSOBER Optimization Algorithm\\n\\nIn order to determine whether or not a given feature is important, feature selection problems have a small search space consisting only of the binary values 0 and 1. Con- sequently, the binary PSOBER method is proposed in this part, which transforms the continuous values produced by the continuous PSOBER algorithm into binary [0, 1] to conform to the feature selection procedure. The primary function of this algorithm is to convert the continuous solution into a binary solution in terms of the following Sigmoid function.\\n\\n(cid:40)\\n\\nif Sigmoid(P∗ otherwise\\n\\nt ) ≥ 0.5\\n\\n1\\n\\nP∗ t =\\n\\n,\\n\\n0\\n\\n(15)\\n\\n1\\n\\nSigmoid(P∗\\n\\nt ) =\\n\\n1 + e−10(P∗\\n\\nt −0.5)\\n\\nMathematics 2022, 10, 3614\\n\\n15 of 29\\n\\nwhere P∗ t denotes the optimal solution at step t. Algorithm 2 details the steps of the proposed binary PSOBER used in selecting the best set of features that can boost the classiﬁcation accuracy of monkeypox cases.\\n\\nAlgorithm 2 The proposed binary PSOBER algorithm.\\n\\n1: Initialize Set PSOBER population, parameters, conﬁguration. 2: Convert solutions to binary [0, 1]. 3: Calculate objective function and select best solutions. 4: Train k-NN and calculate error 5: while t ≤ Maxiter do Find the best solution using PSOBER algorithm 6: Convert solutions to binary using Equation (15) 7: Calculate Fitness 8: 9: Update Positions 10: end while 11: Return X∗\\n\\nObjective Function\\n\\nWith the help of the following formula representing the objective function, it is possible to evaluate the accuracy of the solution generated by the proposed optimization method.\\n\\n|A| |B|\\n\\nFt = αError(Params) + β\\n\\n(16)\\n\\nwhere Params stands for the model’s input parameters. The signiﬁcance of the chosen traits in the population is reﬂected by the values of al pha ∈ [0, 1] and beta = 1 − al pha. While |A| represents the number of features that were used to make a decision, |B| represents the total number of features in the dataset. The optimal strategy is one that uses as few features as possible to get a high-quality classiﬁcation.\\n\\n4.3. The Proposed SCBER Optimization Algorithm\\n\\nTo achieve better classiﬁcation performance, an optimization algorithm is proposed based on a hybrid between the sine cosine and Al-Biruni Earth radius optimization algo- rithms, which is denoted by SCBER. This optimization algorithm is used to optimize the parameters of a multi-layer neural network. The steps of the proposed SCBER algorithm are listed in Algorithm 3.\\n\\nWhen applied to a population, the proposed SCBER algorithm strikes an automated balance between exploring and exploiting different segments of the population. In the proposed method, 70% of the population is divided into two groups: exploration and exploitation. Having a large number of individuals involved in the exploration group helps with ﬁnding new and intriguing search regions. Individual ﬁtness increases when more opportunistic individuals are able to increase their ﬁtness levels, but the percentage of individuals in the exploratory group rapidly decreases from 70% to 30%. If a better solution cannot be identiﬁed, then using an elitism approach guarantees convergence by keeping the process leader in subsequent populations. SCBER may increase the size of the exploration group at any point so long as the leader’s ﬁtness has not increased sufﬁciently throughout three iterations.\\n\\nMathematics 2022, 10, 3614\\n\\n16 of 29\\n\\nAlgorithm 3 The proposed SCBER optimization algorithm.\\n\\n1: Initialize BER population Pi(i = 1, 2, ..., d) with size d, iterations Maxiter, ﬁtness func-\\n\\ntion Fn, t = 1, n1, n2, a, r1, r2, r3, r4, r5, r6, r7\\n\\n2: Calculate ﬁtness function Fn for each Pi 3: Find best solution as P∗ 4: while t ≤ Maxiter do if t%2 == 0 then 5: 6:\\n\\nfor (i = 1 : i < n1 + 1) do Update r = h cos(x) 1−cos(x) Calculate D = r1(P(t) − 1) Update positions to head toward best solution as P(t + 1) = P(t) + D(2r2 − 1)\\n\\n7:\\n\\n8: 9:\\n\\nend for for (i = 1 : i < n2 + 1) do\\n\\n10: 11: 12:\\n\\nCalculate D = r3(L(t) − P(t)) Update positions of best solution as P(t + 1) = r2(P(t) + D) Calculate k = 1 + 2×t2 Max2 Investigate area around best solution as P(cid:48)(t + 1) = r1(P∗(t) + k) Compare P(t + 1) and P(cid:48)(t + 1) to select best solution P∗ if best ﬁtness is not changed for last two iterations then\\n\\n13:\\n\\n14:\\n\\niter\\n\\n15:\\n\\n16: 17:\\n\\nMutate solution as P(t + 1) = k ∗ z2 − h cos(x) 1−cos(x)\\n\\n18:\\n\\nend if end for\\n\\n19: 20: 21: 22: 23:\\n\\nelse\\n\\nUpdate current birds’ positions as if r4 < 0.5 then\\n\\nUpdate birds’ positions by P(t + 1) = P(t) + r5 × sin(r6) × |r7P∗(t) − P(t)|\\n\\n24: 25: 26: 27: 28: 29: 30: Update the ﬁtness function Fn for each Pi 31: Update BER parameters, t = t + 1 32: end while 33: Return P∗\\n\\nelse\\n\\nUpdate birds’ positions by P(t + 1) = P(t) + r5 × cos(r6) × |r7P∗(t) − P(t)|\\n\\nend if Calculate r4 = a − a×t tmax\\n\\nend if\\n\\n5. Experimental Results\\n\\nThree sets of experiments were carried out in this paper to evaluate the proposed algorithms. The purpose of the ﬁrst set of experiments was to determine which of the deep learning networks available for feature extraction performs the best, and then adopt the best performing deep network. The results of the best-adopted network werer then fed to the proposed feature selection algorithm (bPSOBER), which was evaluated using the second set of experiments. The selected features were classiﬁed using the optimized NN, which was optimized using the proposed SCBER, which was evaluated using the third set of experiments. In addition, a set of statistical experiments were conducted to assess the stability and signiﬁcance of the proposed algorithms. In this section, the results of these experiments are presented and explained.\\n\\nThe hardware parameters of the platform that ran the experiments were: central processing unit (CPU) of type Intel Core i7, the graphics processing unit (GPU) was GeForce RTX2070 Super with 8 GB memory, and the main memory was of size 16 GB. On the other hand, the software parameters were: platform was Ubuntu 20.04 with CUDA9.0,\\n\\nMathematics 2022, 10, 3614\\n\\n17 of 29\\n\\nCudnn7.1, TensorFlow 1.15, and Spider IDE with Python3.7. Based on these parameters, the experiments were conducted in ≥16 batches, which enabled completing the model training process in a relatively short time.\\n\\n5.1. Monkeypox Dataset\\n\\nThe experiments conducted in this work were based on a freely available dataset on Kaggle [46]. This dataset is composed of 279 images of monkeypox cases and 293 images of normal cases. Sample images of the dataset are shown in Figure 7, and the spread of the contamination of the monkeypox infection is shown in Figure 8. As the size of the dataset is small, data augmentation was applied to increase the number of images in the dataset to enable transfer learning for feature extraction.\\n\\nFigure 7. Sample set of images from the monkeypox dataset.\\n\\nFigure 8. The countries contaminated with the monkeypox virus.\\n\\n5.2. Evaluation Criteria\\n\\nThe effectiveness of the proposed feature selection procedure is evaluated in terms of the metrics presented in Table 1. These metrics include mean, worst ﬁtness, best ﬁtness, average ﬁtness size, standard deviation, and average error. On the other hand, the effec- tiveness of the extracted features and the performance of the proposed optimized neural network are evaluated in terms of the metrics listed in Table 2. These metrics include accu- racy, n-value, p-value, sensitivity, speciﬁcity, and F1-score. In these tables, M represents the total number of optimization iterations, P∗ j stands for the best solution vector at iteration j, and size(P∗ j ) indicates the size of the best solution. The number of data points in the test set\\n\\nMathematics 2022, 10, 3614\\n\\n18 of 29\\n\\nis represented by N, and the output label at data point i is marked by Ci. The number of features is denoted by D, and the label of the class of point i is denoted by Li. True positive, false positive, and false negative are abbreviated as TP, TN, FP, and FN, respectively [47].\\n\\nTable 1. The metrics used in evaluating the performance of the proposed feature selection method.\\n\\nMetric\\n\\nValue\\n\\n∑M\\n\\n1 i=1 Pi ∗ M maxM i=1Pi ∗ i=1Pi minM ∗ ∑M i=1 size(Pi ∗) (cid:0)Pi ∗ − Mean(cid:1)2 i=1 mse(Ci, Li)\\n\\nMean\\n\\nWorst ﬁtness\\n\\nBest ﬁtness\\n\\n1 M\\n\\nAverage ﬁtness size\\n\\n(cid:113)\\n\\n∑M i=1 ∑N 1 N\\n\\n1 M−1 ∑M j=1\\n\\nStandard deviation\\n\\n1 M\\n\\nAverage error\\n\\nTable 2. The metrics used in evaluating the performance of the proposed optimized NN.\\n\\nMetric\\n\\nValue\\n\\nTP+TN TP+TN+FP+FN TN TN+FN TP TP+FP TP TP+FN TN TN+FP TP TP+0.5(FP+FN)\\n\\nAccuracy\\n\\nNvalue (NPV)\\n\\nPvalue (PPV)\\n\\nSensitivity (TPR)\\n\\nSpeciﬁcity (TNR)\\n\\nF1-Score\\n\\n5.3. Conﬁguration Parameters\\n\\nTable 3 displays the proposed algorithms’ conﬁguration parameters. These parameters include the population size, number of training iterations, mutation probability, and K factor for the BER parts of the proposed algorithms; the inertial factor of the SC algorithm; the exploration percentage; the numbers of runs and agents; the dimensions of the search space; and ﬁnally, the values of α and β, which were set as 0.99 and 0.01, respectively. On the other hand, Table 4 displays the settings for the other competing algorithms used in the experiments.\\n\\nTable 3. Conﬁguration parameters of the proposed algorithms.\\n\\nParameter\\n\\nValue\\n\\nPopulation size Number of iterations Mutation probability K (decreases from 2 to 0) Inertia factor of SCA Exploration percentage Number of runs Number of agents Dimension α of Equation (16) β of Equation (16)\\n\\n30 100 0.5 1 0.1 70 30 20 Features count 0.99 0.01\\n\\nMathematics 2022, 10, 3614\\n\\n19 of 29\\n\\nTable 4. Conﬁguration parameters of the competing algorithms.\\n\\nAlgorithm\\n\\nParameter\\n\\nValue\\n\\nSC\\n\\nInertia factor Iterations Runs\\n\\n0.1 100 30\\n\\nFA\\n\\nIterations Fireﬂies\\n\\n80 10\\n\\nGA\\n\\nCross over Mutation ratio Selection mechanism Iterations Agents\\n\\n0.9 0.1 Roulette wheel 80 10\\n\\nPSO\\n\\nAcceleration constants Inertia Wmin, Wmax Iterations Particles\\n\\n[2, 12] [0.6, 0.9] 80 10\\n\\nr a Iterations Whales\\n\\nWOA\\n\\n[0, 1] 2 to 0 80 10\\n\\na Wolves Iterations\\n\\nGWO\\n\\n2 to 0 10 80\\n\\n5.4. Stage 1: Preprocessing Results\\n\\nThe preprocessing of the input dataset was applied through a set of steps, including resizing the input images, data augmentation, evaluation of the given deep networks to chose the best, and then feature extraction.\\n\\n5.4.1. Data Augmentation\\n\\nThe term “data augmentation” refers to the method of changing the size and orien- tation of the dataset images to generate new image that can enrich the existing dataset. Data augmentation is used on both training and validation sets to boost the generalization capacity of deep learning-based image classiﬁcation models. Various data augmentation techniques, such as geometric modiﬁcation, kernel ﬁlters, picture mixing, random erasure, and transformations, were applied to increase the size of the dataset. The image augmen- tation pipeline was developed for monkeypox images using some selected augmentation methods. All images in the validation and training sets for each class were scaled to 224 × 224 before being augmented. The process of image augmentation is depicted in Figure 9.\\n\\n5.4.2. Evaluating the Deep Learning Networks\\n\\nMachine-learning models rely heavily on the detection and extraction of key features from input images. Here, the outputs of four different deep neural networks, namely, AlexNet [36], VGG-19 [37], GoogleNet [39], and ResNet-50 [38], are compared based the same dataset. The outputs from these networks are presented in Table 5. Using the default parameters, we ﬁrst gathered the features of the images from the preceding layers of a deep neural network so that they could be used in the subsequent operations for feature selection and balancing. GoogleNet had the best performance, as seen in the results. Therefore, this was adopted by extracting the features that were then fed to the feature selection process.\\n\\nMathematics 2022, 10, 3614\\n\\n20 of 29\\n\\nFigure 9. The operations of data augmentation applied to the monkeypox dataset. Data augmentation was used for the training and validation sets only.\\n\\nTable 5. Evaluation of the features extracted using four deep neural networks and the developed multi-layer neural network.\\n\\nMetric\\n\\nAlexNet\\n\\nVGG19Net\\n\\nResNet-50\\n\\nGoogLeNet\\n\\nAccuracy Sensitivity (TPR) Speciﬁcity (TNR) Pvalue (PPV) Nvalue (NPV) F-score\\n\\n0.84 0.63 0.90 0.66 0.89 0.64\\n\\n0.86 0.63 0.93 0.73 0.89 0.67\\n\\n0.88 0.63 0.96 0.85 0.89 0.72\\n\\n0.89 0.63 0.98 0.91 0.89 0.74\\n\\n5.5. Stage 2: Feature Selection Results\\n\\nThe selection of the most signiﬁcant features of the features extracted by GoogleNet was essential. In this experiment, six optimization methods were employed—namely, the bPSOBER, binary BER (bBER), binary particle swarm optimizer (bPSO) [48], binary whale optimization algorithm (bWOA) [49], binary gray wolf optimizer (bGWO) [50], binary ﬁreﬂy algorithm (bFA) [51], and binary genetic algorithm (bGA) [52]. The evaluation of results achieved by these feature selection methods is listed in Table 6. It can be seen in this table that the results achieved by the proposed bPSOBER algorithm are superior to those achieved by the other feature selection methods.\\n\\nTo demonstrate that the proposed feature selection algorithm (bPSOBER) is statis- tically significantly superior, the p-values were computed by comparing the outputs of each pair of algorithms. To conduct this study, Wilcoxon’s rank-sum test was employed. There are two major hypotheses at play here: the null and the alternative. The mean (µ) values of the null hypothesis represented by H0 include µbPSOBER = µbBER, µbPSOBER = µbPSO, µbPSOBER = µbWOA, µbPSOBER = µbGWO, µbPSOBER = µFA, and µbPSOBER = µbGA. However, the H1 hypothesis does not factor in the averages of the algorithms. The outcomes of the Wilcoxon rank-sum test are shown in Table 7. Compared to the previous algorithms, the suggested one has a lower p-value (p < 0.005). The suggested feature selection approach was vali- dated by these findings, demonstrating its statistical superiority. A one-way analysis of variance (ANOVA) test was performed to examine whether or not there were statis- tically significant differences between the suggested bPSOBER algorithm and the other algorithms. The mean (µ) values of the null hypothesis, designated by H0, include\\n\\nMathematics 2022, 10, 3614\\n\\n21 of 29\\n\\nµbPSOBER = µbBER = µbPSO = µbWOA = µbGWO = µFA = µbGA. Table 8 presents the measured results of the ANOVA test. The results recorded in these tables confirm the superiority, significance, and effectiveness of the proposed feature selection algorithm.\\n\\nTable 6. Evaluation of the proposed feature selection algorithm (bPSOBER) compared to other competing methods.\\n\\nbPSOBER\\n\\nbBER\\n\\nbPSO\\n\\nbWAO\\n\\nbGWO\\n\\nbFA\\n\\nbGA\\n\\nAverage error Average Select size Average Fitness Best Fitness Worst Fitness Standard deviation Fitness\\n\\n0.83508 0.78788 0.89828 0.80008 0.89858 0.72058\\n\\n0.85228 0.98788 0.91448 0.83478 0.90168 0.72528\\n\\n0.88608 0.98788 0.91288 0.89318 0.96088 0.72468\\n\\n0.88588 1.15128 0.92068 0.88478 0.96088 0.72688\\n\\n0.87238 0.91068 0.92058 0.89838 0.97458 0.72588\\n\\n0.88448 1.02238 0.96478 0.88348 0.98108 0.76148\\n\\n0.86588 0.93028 0.92588 0.82918 0.94428 0.72688\\n\\nTable 7. The Wilcoxon signed-rank test for evaluating the the proposed feature selection algorithm (bPSOBER) compared to other competing feature selection methods.\\n\\nbPSOBER\\n\\nbBER\\n\\nbPSO\\n\\nbWAO\\n\\nbGWO\\n\\nbSC\\n\\nbGA\\n\\nTheoretical median Actual median Number of values Wilcoxon Signed Rank Test Sum of signed ranks (W) Sum of positive ranks Sum of negative ranks P value (two tailed) Exact or estimate? Signiﬁcant (alpha = 0.05)? How big is the discrepancy? Discrepancy\\n\\n0 0.8351 14\\n\\n0 0.8523 14\\n\\n0 0.8861 14\\n\\n0 0.8859 14\\n\\n0 0.8724 14\\n\\n0 0.8845 14\\n\\n0 0.8659 14\\n\\n105 105 0 0.0001 Exact Yes\\n\\n105 105 0 0.0001 Exact Yes\\n\\n105 105 0 0.0001 Exact Yes\\n\\n105 105 0 0.0001 Exact Yes\\n\\n105 105 0 0.0001 Exact Yes\\n\\n105 105 0 0.0001 Exact Yes\\n\\n105 105 0 0.0001 Exact Yes\\n\\n0.8351\\n\\n0.8523\\n\\n0.8861\\n\\n0.8859\\n\\n0.8724\\n\\n0.8845\\n\\n0.8659\\n\\nTable 8. The results of the analysis-of-variance (ANOVA) test for evaluating the proposed feature selection algorithm, bPSOBER.\\n\\np Value\\n\\nSS\\n\\nDF\\n\\nMS\\n\\nF (DFn, DFd)\\n\\np < 0.0001\\n\\nTreatment (between columns) Residual (within columns) Total\\n\\n0.0296 0.0034 0.03304\\n\\n6 91 97\\n\\n0.0049 0.000038\\n\\nF (6, 91) = 130.7\\n\\nAnother experiment was conducted to show the effectiveness of the feature selection process on the classiﬁcation performance. Table 9 shows classiﬁcation results with and without feature selection. It can be easily noted in this table that feature selection is necessary to boost the accuracy of the classiﬁcation results.\\n\\nTable 9. Comparison between the classiﬁcation results with and without the proposed feature selection algorithm, bPSOBER.\\n\\nMetric\\n\\nBefore Feature Selection\\n\\nAfter Feature Selection\\n\\nAccuracy Sensitivity (TPR) Speciﬁcity (TNR) Pvalue (PPV) Nvalue (NPV) F-score\\n\\n0.902061856 0.625 0.993150685 0.967741935 0.889570552 0.759493671\\n\\n0.938023451 0.625 0.998003992 0.983606557 0.932835821 0.76433121\\n\\nMathematics 2022, 10, 3614\\n\\n22 of 29\\n\\nThe results using the proposed feature selection method are illustrated by the plots shown in Figure 10. In this ﬁgure, the quartile–quartile (QQ), homoscedasticity, and residual plots are used to show the effectiveness and robustness of the proposed method. The values shown in the QQ plot approximately ﬁt a straight line, which reﬂects the robustness of the selected features in classifying the monkepox cases. In addition, the recorded results in the homoscedasticity and residual plots give more emphasis to these ﬁndings.\\n\\nFigure 10. Analysis plots of the achieved results based on the proposed feature selection algorithm, bPSOBER. (a) QQ plot, (b) Homoscedasticity plot, (c) Residual plot.\\n\\nThe average error of the proposed feature selection method compared to those of six other feature selection methods is shown in the plot depicted in Figure 11. In this ﬁgure, it is shown that the proposed method achieved the lowest average error, which conﬁrms the robustness of the proposed method. In addition, the heatmap shown in Figure 12 conﬁrms the superiority of bPSOBER, as it achieved the best results when compared to bWAO and bGA feature selection algorithms.\\n\\nFigure 11. The average error of the results achieved based on the proposed feature selection algorithm, bPSOBER.\\n\\nMathematics 2022, 10, 3614\\n\\n23 of 29\\n\\nFigure 12. Heatmap of the achieved results based on the proposed feature selection algorithm, bPSOBER.\\n\\n5.6. Stage 3: Monkeypox Classiﬁcation Results\\n\\nThe selected features based on the proposed bPSOBER were used to classify the input image through a machine-learning classiﬁer. The classiﬁer adopted in this work was the multi-layer neural network (NN). To achieve the best performance of this NN, the parameters of this network were optimized using SCBER. The optimized parameters are listed in Table 10.\\n\\nThe effectiveness of the optimized NN classiﬁer was evaluated using a set of experi- ments. SCBER’s results are compared to those of BER, PSO, PSOBER, and SC to demonstrate the superiority of the proposed NN optimization. Various optimizers were employed to ﬁne-tune the NN’s parameters, and the outcomes were recorded and analyzed. Table 11 presents a statistical analysis of the results achieved using SCBER compared to other opti- mization methods. Based on the results shown in this table, it is clear that the proposed optimization method yields superior results compared to the other methods.\\n\\nTable 10. The optimized parameters of the developed neural network employed in monkeypox classiﬁcation using SCBER.\\n\\nParameter\\n\\nOptimized Value\\n\\nNumber of classes Number of hidden layers Neurons if the ﬁrst layer Number of neurons in the second layer Number of neurons in the third layer Number of neurons in the fourth layer Training epochs Learning rate Display step Batch size\\n\\n2 4 30 30 30 10 200 10−4 1 100\\n\\nMathematics 2022, 10, 3614\\n\\n24 of 29\\n\\nTable 11. Statistical analysis of the results achieved by the optimized neural network using SCBER.\\n\\nSCBER+NN\\n\\nBER+NN\\n\\nPSO+NN\\n\\nPSOBER+NN\\n\\nSC+NN\\n\\nNumber of values Minimum 10% Percentile 25% Percentile 75% Percentile 90% Percentile 95% CI of median Maximum Median Range Actual conﬁdence level Lower conﬁdence limit Upper conﬁdence limit Mean Harmonic mean Quadratic mean Geometric mean Std. Error of Mean Std. Deviation Upper 95% CI of mean Lower 95% CI of mean Coefﬁcient of variation Geometric SD factor Upper 95% CI of geo. mean Lower 95% CI of geo. mean Upper 95% CI of harm. mean Lower 95% CI of harm. mean Upper 95% CI of quad. mean Lower 95% CI of quad. mean Kurtosis Skewness Sum\\n\\n19 0.989 0.99 0.99 0.992 0.992\\n\\n19 0.9604 0.9704 0.9704 0.976 0.976\\n\\n19 0.9625 0.9654 0.9654 0.9754 0.9754\\n\\n19 0.9539 0.9594 0.9594 0.9694 0.9894\\n\\n19 0.9539 0.9594 0.9594 0.9694 0.9694\\n\\n0.992 0.99 0.003 98.08% 0.99 0.992 0.9906 0.9906 0.9906 0.9906 0.0002334 0.001017 0.9911 0.9901 0.1027% 1.001 0.9911 0.9901 0.9911 0.9901 0.9911 0.9901 −1.253 0.6458 18.82\\n\\n0.976 0.9704 0.0156 98.08% 0.9704 0.976 0.9717 0.9717 0.9718 0.9717 0.000868 0.003783 0.9736 0.9699 0.3893% 1.004 0.9736 0.9699 0.9736 0.9699 0.9736 0.9699 3.463 −1.177 18.46\\n\\n0.9754 0.9654 0.0129 98.08% 0.9654 0.9754 0.9684 0.9684 0.9684 0.9684 0.00113 0.004926 0.9708 0.966 0.5087% 1.005 0.9708 0.966 0.9708 0.966 0.9708 0.966 −1.391 0.7904 18.4\\n\\n0.9994 0.9594 0.0455 98.08% 0.9594 0.9694 0.9665 0.9663 0.9665 0.9664 0.002692 0.01173 0.9721 0.9608 1.214% 1.012 0.972 0.9608 0.9719 0.9608 0.9722 0.9608 2.688 1.709 18.36\\n\\n0.9694 0.9594 0.0155 98.08% 0.9594 0.9694 0.9623 0.9622 0.9623 0.9623 0.001177 0.005131 0.9647 0.9598 0.5332% 1.005 0.9647 0.9598 0.9647 0.9598 0.9648 0.9598 −1.196 0.6007 18.28\\n\\nThe statistical significance of the proposed optimization of NN using SCBER was tested using the p-values by comparing the outputs of each pair of algorithms. The Wilcoxon’s rank- sum test was performed, and results were recorded. There are two major hypotheses at play here: the null and the alternative. The mean (µ) values of null hypothesis represented by H0 include µSCBER = µBER, µSCBER = µPSO, µSCBER = µPSOBER, µSCBER = µSC. However, the H1 hypothesis does not factor in the averages of the algorithms. The out- comes of the Wilcoxon rank-sum test are shown in Table 12. Compared to the previous algorithms, the suggested one has a lower p-value (p < 0.005). The suggested feature selection approach was validated by these ﬁndings, demonstrating its statistical supe- riority. The ANOVA test was performed to examine whether or not there was a sta- tistically signiﬁcant difference between the suggested SCBER algorithm and the other algorithms. The mean (µ) values of the null hypothesis, designated by H0, include µSCBER = µBER = µPSO = µPSOBER = µSC. The measured values of the ANOVA test are presented in Table 13. As presented in these tables, the results emphasize the superiority and effectiveness of the proposed approach in classifying monkeypox cases from images.\\n\\nMathematics 2022, 10, 3614\\n\\n25 of 29\\n\\nTable 12. The Wilcoxon signed-rank test for evaluating the performance of the proposed optimization algorithm, SCBER, compared to other competing optimization methods.\\n\\nSCBER+NN\\n\\nBER+NN\\n\\nPSO+NN\\n\\nPSOBER+NN\\n\\nSC+NN\\n\\nTheoretical median Actual median Number of values Wilcoxon Signed Rank Test Sum of signed ranks (W) Sum of positive ranks Sum of negative ranks P value (two tailed) Exact or estimate? P value summary Signiﬁcant (alpha = 0.05)? How big is the discrepancy? Discrepancy\\n\\n0 0.99 19\\n\\n0 0.9704 19\\n\\n0 0.9654 19\\n\\n0 0.9594 19\\n\\n0 0.9594 19\\n\\n190 190 0 <0.0001 Exact\\n\\n190 190 0 <0.0001 Exact\\n\\n190 190 0 <0.0001 Exact\\n\\n190 190 0 <0.0001 Exact\\n\\n190 190 0 <0.0001 Exact\\n\\nYes\\n\\nYes\\n\\nYes\\n\\nYes\\n\\nYes\\n\\n0.99\\n\\n0.9704\\n\\n0.9654\\n\\n0.9594\\n\\n0.9594\\n\\nTable 13. The results of the analysis of variance (ANOVA) test for evaluating the proposed SCBER+NN approach.\\n\\np Value\\n\\nSS\\n\\nDF\\n\\nMS\\n\\nF (DFn, DFd)\\n\\np < 0.0001\\n\\nTreatment (between columns) Residual (within columns) Total\\n\\n0.009183 0.003665 0.01285\\n\\n4 90 94\\n\\n0.0023 0.00004\\n\\nF (4, 90) = 56.37\\n\\nFigures 13 and 14 graphically depict the statistical analysis of the achieved classiﬁcation results. Figure 13 contains three plots, namely, a quartile–quartile (QQ) plot, a residual plot, and a homoscedasticity plot. Figure 14 illustrates the ROC curve. It can be seen in these graphs that SCBER is stable, with residual errors ranging from −0.02 to +0.02 and homoscedasticity values from −0.01 to +0.04. The QQ plot further demonstrates that the anticipated outcomes are consistent with the observed values, providing more evidence for the validity of the proposed method.\\n\\nThe accuracy plots depicted in Figure 15 and the heatmap plot depicted in Figure 16 show the accuracy and the histogram of the results achieved using SCBER. The accuracy plot shows that higher accuracy was achieved by the proposed algorithm compared to the other four optimization algorithm. In addition, the accuracy histogram plot emphasizes the superiority and stability of the proposed optimization algorithm in classifying the monkeypox cases in the input images.\\n\\nFigure 13. Analysis plots of the achieved classiﬁcation results based on a neural network optimized using the proposed SCBER algorithm. (a) QQ plot, (b) Homoscedasticity plot, (c) Residual plot.\\n\\nMathematics 2022, 10, 3614\\n\\n26 of 29\\n\\nFigure 14. The ROC curve of the results achieved by the neural network optimized using SCBER in comparison with the results achieved by the neural network optimized using BER.\\n\\nFigure 15. The accuracy plot and accuracy histogram plot of the results achieved by the proposed SCBER algorithm, and four other optimization algorithms. (a) Accuracy plot. (b) Histogram plot.\\n\\nFigure 16. The heatmap of the results achieved by the neural network optimized using the proposed SCBER algorithm compared to the other competing algorithms.\\n\\nMathematics 2022, 10, 3614\\n\\n27 of 29\\n\\n6. Conclusions\\n\\nIn this paper, two algorithms were proposed for improving the classiﬁcation accuracy of the monkeypox cases in images. The ﬁrst algorithm is denoted the binary PSOBER algorithm, which is a hybrid of PSO and BER optimization algorithms and aims to select the best set of features that can improve the classiﬁcation accuracy. The second algorithm is denoted by SCBER; it aims at optimizing the parameters of a NN to achieve the best accuracy. The evaluation of the proposed algorithms was performed with a freely-available monkeypox dataset which was augmented to ﬁt the transfer learning using GoogleNet. Two sets of evaluation criteria were employed to assess the proposed algorithms. In addition, statistical analysis was performed by the Wilcoxon signed-rank test and ANOVA to measure the signiﬁcance and effectiveness of the proposed algorithm. Moreover, a set of visual representations of the results was generated to conﬁrm the robustness and effectiveness of the proposed algorithms. Experimental results show the superiority of the proposed algorithms compared to other competing algorithms in the task of monkeypox classiﬁcation. The future aims of this work include assessing the proposed method with large-scale datasets and engineering optimization problems to clearly identify its advantages and disadvantages.\\n\\nAuthor Contributions: Conceptualization, A.H.A.; Data curation, A.A.A.; Formal analysis, A.A.A. and A.I.; Funding acquisition, A.H.A. and A.I.; Investigation, N.K., D.S.K. and M.M.E.; Methodology, E.-S.M.E.-K. and M.M.E.; Project administration, E.-S.M.E.-K. and S.M.; Resources, N.K.; Software, E.-S.M.E.-K. and M.M.E.; Supervision, E.-S.M.E.-K. and S.M.; Validation, D.S.K.; Visualization, D.S.K.; Writing—original draft, A.A.A., N.K., A.H.A. and M.S.; Writing—review & editing, A.I. All authors have read and agreed to the published version of the manuscript.\\n\\nFunding: This research was funded by Princess Nourah bint Abdulrahman University Researchers Supporting Project (PNURSP2022R120), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia.\\n\\nData Availability Statement: The dataset is publicly available in Kaggle repository: https://www. kaggle.com/datasets/dipuiucse/monkeypoxskinimagedataset?resource=download accessed on 14 September 2022.\\n\\nConﬂicts of Interest: The authors declare that they have no conﬂict of interest to report regarding the present study.\\n\\nReferences\\n\\n1. McCollum, A.M.; Damon, I.K. Human Monkeypox. Clin. Infect. Dis. 2014, 58, 260–267. [CrossRef] 2.\\n\\nAlakunle, E.; Moens, U.; Nchinda, G.; Okeke, M.I. Monkeypox Virus in Nigeria: Infection Biology, Epidemiology, and Evolution. Viruses 2020, 12, 1257. [CrossRef]\\n\\n3. Moore, M.J.; Rathish, B.; Zahra, F. Monkeypox. In StatPearls; StatPearls Publishing: Treasure Island, FL, USA, 2022. 4.\\n\\nNolen, L.D.; Osadebe, L.; Katomba, J.; Likofata, J.; Mukadi, D.; Monroe, B.; Doty, J.; Hughes, C.M.; Kabamba, J.; Malekani, J.; et al. Extended Human-to-Human Transmission during a Monkeypox Outbreak in the Democratic Republic of the Congo. Emerg. Infect. Dis. 2016, 22, 1014–1021. [CrossRef] Nguyen, P.Y.; Ajisegiri, W.S.; Costantino, V.; Chughtai, A.A.; MacIntyre, C.R. Reemergence of Human Monkeypox and Declining Population Immunity in the Context of Urbanization, Nigeria, 2017–2020. Emerg. Infect. Dis. 2021, 27. [CrossRef] El-kenawy, E.S.M.; Albalawi, F.; Ward, S.A.; Ghoneim, S.S.M.; Eid, M.M.; Abdelhamid, A.A.; Bailek, N.; Ibrahim, A. Feature Selection and Classiﬁcation of Transformer Faults Based on Novel Meta-Heuristic Algorithm. Mathematics 2022, 10, 3144. [CrossRef] Ali Salamai, A.; El-kenawy, E.S.M.; Abdelhameed, I. Dynamic Voting Classiﬁer for Risk Identiﬁcation in Supply Chain 4.0. Comput. Mater. Contin. 2021, 69, 3749–3766. Ali, S.; Ahmed, M.; Paul, J.; Jahan, T.; Sani, S.; Noor, N.; Hasan, T. Monkeypox Skin Lesion Detection Using Deep Learning Models: A Feasibility Study. arXiv, 2022, arXiv:2207.03342. Adler, H.; Gould, S.; Hine, P.; Snell, L.B.; Wong, W.e.a. Clinical features and management of human monkeypox: A retrospective observational study in the UK. Lancet Infect. Dis. 2022, 22, 1153–1162. [CrossRef]\\n\\n5.\\n\\n6.\\n\\n7.\\n\\n8.\\n\\n9.\\n\\n10. Akin, K.D.; Gurkan, C.; Budak, A.; Karata¸s, H. Classiﬁcation of Monkeypox Skin Lesion using the Explainable Artiﬁcial\\n\\nIntelligence Assisted Convolutional Neural Networks. Avrupa Bilim ve Teknoloji Dergisi 2022, 106–110. [CrossRef]\\n\\nMathematics 2022, 10, 3614\\n\\n28 of 29\\n\\n11.\\n\\nIbrahim, A.; Mirjalili, S.; El-Said, M.; Ghoneim, S.S.M.; Al-Harthi, M.M.; Ibrahim, T.F.; El-Kenawy, E.S.M. Wind Speed Ensemble Forecasting Based on Deep Learning Using Adaptive Dynamic Optimization Algorithm. IEEE Access 2021, 9, 125787–125804. [CrossRef]\\n\\n12. Ahsan, M.M.; Gupta, K.D.; Islam, M.M.; Sen, S.; Rahman, M.L.; Shakhawat Hossain, M. COVID-19 Symptoms Detection Based on NasNetMobile with Explainable AI Using Various Imaging Modalities. Mach. Learn. Knowl. Extr. 2020, 2, 490–504. [CrossRef] 13. Ahsan, M.M.; E. Alam, T.; Trafalis, T.; Huebner, P. Deep MLP-CNN Model Using Mixed-Data to Distinguish between COVID-19\\n\\nand Non-COVID-19 Patients. Symmetry 2020, 12, 1526. [CrossRef]\\n\\n14. Ahsan, M.M.; Ahad, M.T.; Soma, F.A.; Paul, S.; Chowdhury, A.; Luna, S.A.; Yazdan, M.M.S.; Rahman, A.; Siddique, Z.; Huebner, P.\\n\\nDetecting SARS-CoV-2 From Chest X-Ray Using Artiﬁcial Intelligence. IEEE Access 2021, 9, 35501–35513. [CrossRef]\\n\\n15. Ahsan, M.M.; Nazim, R.; Siddique, Z.; Huebner, P. Detection of COVID-19 Patients from CT Scan and Chest X-ray Data Using\\n\\nModiﬁed MobileNetV2 and LIME. Healthcare 2021, 9, 1099. [CrossRef]\\n\\n16. Ahsan, M.M.; Siddique, Z. Machine learning-based heart disease diagnosis: A systematic literature review. Artif. Intell. Med.\\n\\n2022, 128, 102289. [CrossRef]\\n\\n17. Miranda, G.H.B.; Felipe, J.C. Computer-aided diagnosis system based on fuzzy logic for breast cancer categorization. Comput.\\n\\nBiol. Med. 2015, 64, 334–346. [CrossRef]\\n\\n18. Ardakani, A.A.; Kanaﬁ, A.R.; Acharya, U.R.; Khadem, N.; Mohammadi, A. Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks. Comput. Biol. Med. 2020, 121, 103795. [CrossRef]\\n\\n19. Wang, L.; Lin, Z.Q.; Wong, A. COVID-Net: A tailored deep convolutional neural network design for detection of COVID-19 cases\\n\\nfrom chest X-ray images. Sci. Rep. 2020, 10, 19549. [CrossRef] In Proceedings of the Sandeep, R.; Vishal, K.P.; Shamanth, M.S.; Chethan, K. Diagnosis of Visible Diseases Using CNNs. International Conference on Communication and Artiﬁcial Intelligence; Goyal, V., Gupta, M., Mirjalili, S., Trivedi, A., Eds.; Lecture Notes in Networks and Systems; Springer Nature: Singapore, 2022; pp. 459–468. [CrossRef]\\n\\n20.\\n\\n21. Roy, K.; Chaudhuri, S.S.; Ghosh, S.; Dutta, S.K.; Chakraborty, P.; Sarkar, R. Skin Disease detection based on different Segmentation Techniques. In Proceedings of the 2019 International Conference on Opto-Electronics and Applied Optics (Optronix), Kolkata, India, 18–20 March 2019; pp. 1–5. [CrossRef]\\n\\n22. Chandra, M.M.G. Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques. Int. J. Sci. Res. Eng. Manag.\\n\\n2022, 6. [CrossRef]\\n\\n23. Wang, Z.; Zhu, X.; Adeli, E.; Zhu, Y.; Nie, F.; Munsell, B.; Wu, G. Multi-modal classiﬁcation of neurodegenerative disease by\\n\\nprogressive graph-based transductive learning. Med. Image Anal. 2017, 39, 218–230. [CrossRef] [PubMed]\\n\\n24. Roman, R.C.; Precup, R.E.; Petriu, E.M. Hybrid data-driven fuzzy active disturbance rejection control for tower crane systems.\\n\\nEur. J. Control 2021, 58, 373–387. [CrossRef]\\n\\n25. Chi, R.; Li, H.; Shen, D.; Hou, Z.; Huang, B. Enhanced P-type Control: Indirect Adaptive Learning from Set-point Updates. IEEE\\n\\nTrans. Autom. Control. 2022, 1. [CrossRef]\\n\\n26. Wu, C.C.; Yeh, W.C.; Hsu, W.D.; Islam, M.M.; Nguyen, P.A.A.; Poly, T.N.; Wang, Y.C.; Yang, H.C.; Li (Jack), Y.C. Prediction of fatty\\n\\nliver disease using machine learning algorithms. Comput. Methods Programs Biomed. 2019, 170, 23–29. [CrossRef]\\n\\n27. Qin, J.; Chen, L.; Liu, Y.; Liu, C.; Feng, C.; Chen, B. A Machine Learning Methodology for Diagnosing Chronic Kidney Disease.\\n\\nIEEE Access 2020, 8, 20991–21002. [CrossRef]\\n\\n28. Khan, M.M.R.; Arif, R.B.; Siddique, M.A.B.; Oishe, M.R. Study and Observation of the Variation of Accuracies of KNN, SVM, LMNN, ENN Algorithms on Eleven Different Datasets from UCI Machine Learning Repository. In Proceedings of the 2018 4th International Conference on Electrical Engineering and Information & Communication Technology (iCEEiCT), Dhaka, Bangladesh, 13–15 September 2018; pp. 124–129. [CrossRef]\\n\\n29. Abdar, M.; Ksi ˛a ˙zek, W.; Acharya, U.R.; Tan, R.S.; Makarenkov, V.; Pławiak, P. A new machine learning technique for an accurate\\n\\ndiagnosis of coronary artery disease. Comput. Methods Programs Biomed. 2019, 179, 104992. [CrossRef]\\n\\n30. Yu, Y.; Yang, Z.; Li, P.; Yang, Z.; You, Y. Work-in-Progress: On the Feasibility of Lightweight Scheme of Real-Time Atrial Fibrillation In Proceedings of the 2019 IEEE Real-Time Systems Symposium (RTSS), Hong Kong, 3–6\\n\\nDetection Using Deep Learning. December 2019; pp. 552–555. [CrossRef]\\n\\n31. Hayward, G. Remarks on Smallpox, Cowpox and Varioloid. Boston Med. Surg. J. 1860, 62, 173–177. [CrossRef] 32.\\n\\nIslam, T.; Hussain, M.A.; Chowdhury, F.U.H.; Islam, B.M.R. A Web-scraped Skin Image Database of Monkeypox, Chickenpox, Smallpox, Cowpox, and Measles. bioRxiv 2022. [CrossRef]\\n\\n33. Chen, J.; Wu, L.; Zhang, J.; Zhang, L.; Gong, D.; Zhao, Y.; Chen, Q.; Huang, S.; Yang, M.; Yang, X.; et al. Deep learning-based model for detecting 2019 novel coronavirus pneumonia on high-resolution computed tomography. Sci. Rep. 2020, 10, 19196. [CrossRef]\\n\\n34. El-Kenawy, E.S.M.; Mirjalili, S.; Alassery, F.; Zhang, Y.D.; Eid, M.M.; El-Mashad, S.Y.; Aloyaydi, B.A.; Ibrahim, A.; Abdelhamid, A.A. Novel Meta-Heuristic Algorithm for Feature Selection, Unconstrained Functions and Engineering Problems. IEEE Access 2022, 10, 40536–40555. [CrossRef]\\n\\n35. Abdelhamid, A.A.; El-Kenawy, E.S.M.; Alotaibi, B.; Amer, G.M.; Abdelkader, M.Y.; Ibrahim, A.; Eid, M.M. Robust Speech Emotion Recognition Using CNN+LSTM Based on Stochastic Fractal Search Optimization Algorithm. IEEE Access 2022, 10, 49265–49284. [CrossRef]\\n\\nMathematics 2022, 10, 3614\\n\\n29 of 29\\n\\n36. Han, J.; Zhang, D.; Cheng, G.; Liu, N.; Xu, D. Advanced Deep-Learning Techniques for Salient and Category-Speciﬁc Object\\n\\nDetection: A Survey. IEEE Signal Process. Mag. 2018, 35, 84–100. [CrossRef] Simonyan, K.; Zisserman, A. Very Deep Convolutional Networks for Large-Scale Image Recognition. In Proceedings of the International Conference on Learning Representations, San Diego, CA, USA, 7–9 May 2015; pp. 1–14.\\n\\n37.\\n\\n38. Yu, S.; Xie, L.; Liu, L.; Xia, D. Learning Long-Term Temporal Features with Deep Neural Networks for Human Action Recognition.\\n\\nIEEE Access 2020, 8, 1840–1850. [CrossRef]\\n\\n39. Al-Dhamari, A.; Sudirman, R.; Mahmood, N.H. Transfer Deep Learning Along with Binary Support Vector Machine for Abnormal\\n\\nBehavior Detection. IEEE Access 2020, 8, 61085–61095. [CrossRef]\\n\\n40. Atkinson, P.M.; Tatnall, A.R.L. Introduction Neural networks in remote sensing. Int. J. Remote Sens. 1997, 18, 699–709. [CrossRef] 41. Patra, S.; Ghosh, S.; Ghosh, A. Histogram thresholding for unsupervised change detection of remote sensing images. Int. J.\\n\\nRemote Sens. 2011, 32, 6071–6089. [CrossRef]\\n\\n42. Khafaga, D.S.; Alhussan, A.A.; El-Kenawy, E.S.M.; Ibrahim, A.; Eid, M.M.; Abdelhamid, A.A. Solving Optimization Problems of Metamaterial and Double T-Shape Antennas Using Advanced Meta-Heuristics Algorithms. IEEE Access 2022, 10, 74449–74471. [CrossRef]\\n\\n43. Alhussan, A.A.; Khafaga, D.S.; El-Kenawy, E.S.M.; Ibrahim, A.; Eid, M.M.; Abdelhamid, A.A. Pothole and Plain Road Classiﬁca- tion Using Adaptive Mutation Dipper Throated Optimization and Transfer Learning for Self Driving Cars. IEEE Access 2022, 10, 84188–84211. [CrossRef]\\n\\n44. Mirjalili, S. SCA: A Sine Cosine Algorithm for solving optimization problems. Knowl.-Based Syst. 2016, 96, 120–133. [CrossRef] 45. Eid, M.M.; El-kenawy, E.S.M.; Ibrahim, A. A Binary Sine Cosine-Modiﬁed Whale Optimization Algorithm for Feature Selection. In Proceedings of the National Computing Colleges Conference (NCCC), Taif, Saudi Arabia, 27–28 March 2021; pp. 1–6. [CrossRef] 46. Bala, D. Monkeypox Skin Images Dataset (MSID). 2022. Available online: https://www.kaggle.com/datasets/dipuiucse/\\n\\nmonkeypoxskinimagedataset?resource=download (accessed on 10 September 2022).\\n\\n47. El-Kenawy, E.S.M.; Mirjalili, S.; Abdelhamid, A.A.; Ibrahim, A.; Khodadadi, N.; Eid, M.M. Meta-Heuristic Optimization and\\n\\nKeystroke Dynamics for Authentication of Smartphone Users. Mathematics 2022, 10, 2912. [CrossRef]\\n\\n48. Bello, R.; Gomez, Y.; Nowe, A.; Garcia, M.M. Two-Step Particle Swarm Optimization to Solve the Feature Selection Problem. In Proceedings of the Seventh International Conference on Intelligent Systems Design and Applications (ISDA 2007), Rio de Janeiro, Brazil, 22–24 October 2007; pp. 691–696. [CrossRef]\\n\\n49. Mirjalili, S.; Lewis, A. The Whale Optimization Algorithm. Adv. Eng. Softw. 2016, 95, 51–67. [CrossRef] 50. El-kenawy, E.S.; Eid, M. Hybrid Gray Wolf and Particle Swarm Optimization for Feature Selection. Int. J. Innov. Comput. Inf.\\n\\nControl. IJICIC 2020, 16, 831–844. [CrossRef] Fister, I.; Yang, X.-S.; Fister, I.; Brest, J. Memetic ﬁreﬂy algorithm for combinatorial optimization. In Bioinspired Optimization Methods and Their Applications—(BIOMA 2012); Filipic, B., Silc, J., Eds.; Jozef Stefan Institute: Ljubljana, Slovenia, 2012; pp. 75–86. 52. Kabir, M.M.; Shahjahan, M.; Murase, K. A new local search based hybrid genetic algorithm for feature selection. Neurocomputing\\n\\n51.\\n\\n2011, 74, 2914–2928. [CrossRef]', metadata={'source': 'allFiles/mathematics-10-03614-v2.pdf'}), Document(page_content='Our Case Studies:\\n\\nDriving Efficiencies and Customer Satisfaction\\n\\nTransforming the Sales Process\\n\\nIncreased User Adoption Drives Regional Bank’s Financial Gains\\n\\nEnhanced Customer Experience Leads to Lower Attrition Rates\\n\\nCustomer Billing Optimization Leads to an Increase in Revenue\\n\\nML Predictive Models Adds $1 Million In New Revenue Per Month\\n\\nTestimonials :\\n\\n“We sincerely appreciate how the team is running the projects, managing the timeline and answering our endless questions. We are beyond impressed!” VP of IT, Distribution Services\\n\\n“Thanks everyone for your continued hard work and patience to get these updates over the finish line. This was a true team effort.” T Director, Retail Energy\\n\\n\"You guys went far beyond what we have received from others in the past.” CFO, Financial Services\\n\\n\"“We could not have gone to a web based business system at a better time. As long as our people have access to a web browser and internet at home they have been able to work thanks to the work of the CG Infinity team\"\" CFO, Fashion Retailer\\n\\n\"“CG Infinity provides us with a unique business perspective that many Salesforce implementers simply do not possess. Their ability to bring real-world experience and Best Practices to our team made all the difference to us.\"\" VP of Digital Transformation, Regional Bank\\n\\n\"\"They are highly effective communicators to leadership and allow for a concise message. We have continued to use CG Infinity on subsequent stages of our project that include implementations of other Salesforce products.” \" CEO, Retail Energy\\n\\n\"“CG Infinity has played an integral role for our implementation of Salesforce Service Cloud Voice. They not only brought the technical expertise but the industry domain knowledge as well.\"\"\"\\n\\nCTO, Retail Energy\\n\\n\"\"\"With CG Infinity, we were able to utilize our data and demonstrate measurable value for our business though the power of artificial intelligence, machine learning, and deep learning.”\"\\n\\nCEO, Housing Company\\n\\n\"\"\"CG Infinity did a great job assisting us in upgrading and rolling out incremental functionality. Our experience was exceptional.\"\"\"\\n\\nCIO, Private Equity Firm\\n\\n“The migration to Salesforce lightning was easier than I thought it would be thanks to the way you managed the project.”\\n\\nIT Director, Regional Bank\\n\\n“You guys helped us get the data we needed in order to improve our decision making.”\\n\\nVP of Marketing, Security & Logistics\\n\\n\"\"\"CG Infinity not only has a knowledge of Salesforce, but a depth of experience in working with financial institutions. Their advice on best practices has been crucial to the success of our implementation.\"\"\"\\n\\nVP of Digital Transformation, Consulting Firm\\n\\n”The CG Infinity team continually came back with additional build ideas and concepts that added further value to our customer experience. To say that I would merely recommend them is an understatement.”\\n\\nCTO, Facilities Services\\n\\n“Thank you so much for the Time Entry app! This app is great and is going to save so much time. This is going to be a huge time / productivity improvement for our teams.”\\n\\nCIO, Tax Consulting Firm\\n\\nPeople First + Driven to Transform\\n\\nWhat Sets Our Team Apart\\n\\nOur people-first approach to technology offers best-in-class service and success rates.\\n\\nHow?\\n\\nYour leaders work with our leaders throughout an engagement. The leaders of our small, blended teams work hand in hand with your leadership to ensure your objective success.\\n\\nWhy?\\n\\nSimple. Bridging any communication gaps from day one ensures we support you in reducing risk and increasing revenue. Accountability matters to us, and we know it matters to you.\\n\\n5 Office Locations\\n\\n300+ Employees Worldwide\\n\\n200+ Salesforce Certifications\\n\\n24 Years in Business\\n\\nIntegrity\\n\\nThe only way to build trust is through transparency and integrity. So our team will do what\\'s right even when it isn\\'t easy.\\n\\nValue\\n\\nOur commitment is to deliver world-class services that exceeds expectations within a culture of excellence and transparency.\\n\\nExcellence\\n\\nIt\\'s about people, not just technology. We aspire to surpass our clients\\' goals through excellence in service and outcomes.\\n\\nAt CG Infinity, we collaborate with you one-on-one to deliver only the best solutions for your company. “I’m very thankful to be a part of such a highly engaged team here at CG Infinity. They inspire me every d ay with their zeal to help our customers and help each other to grow.” Saurajit Kanungo | President, CG Infinity \"Saurajit Kanungo \"\\n\\nSaurajit Kanungo (PRESIDENT)\\n\\nSaurajit is passionate about helping customers realize consistent value from their investments in technology. He has a strong background in conducting technology strategy, business systems planning, software/ vendor selection, solution architecture, and project/program management. Saurajit has program managed large scale multi-year, multi-million dollar digital transformation initiatives. He has also spearheaded multiple long-term business systems roadmap efforts.\\n\\nJulianne Churches (CFO & MANAGING DIRECTOR)\\n\\nAs CFO and Managing Director, Julianne is responsible for the overall operations and financial management of the company. She directs all administrative, financial, human resources, compliance, and management functions. Her 25 years of experience and expertise in the industry and 13 years at CG Infinity enable her to work closely with all departments to optimize efficiency across the entire firm.\\n\\nBhopi Dhall (CEO)\\n\\nBhopi founded CG Infinity in 1998 and is a well-respected expert in the technology industry. Working with over 30 years of experience, including his time at Texas Instruments, he led technology product engineering and gained insight into how the technology marketplace functioned. He started CG Infinity as an engineering firm providing technology solutions to companies throughout a wide spectrum of industries.\\n\\nRob Palacios (CINO & EXECUTIVE VICE PRESIDENT)\\n\\nRob Palacios has a 30+ year history of helping businesses leverage technology to gain rapid market shar e and build sustainable competitive advantage. Rob has done this both as an executive as well as a consultant with several reputable organizations such as the National Security Agency, Arthur Andersen, Hitachi, and Texas Capital Bank.\\n\\nSankalp Shastri (CTO & EXECUTIVE VICE PRESIDENT)\\n\\nSankalp has over 15 years of technology consulting experience focused on solving business problems by leveraging technology. Sankalp is responsible for over half a dozen strategic customers and a team of over 50 employees. “Once a developer, always a developer.” He is passionate about technology, application development and application management (development, modernization, and managed services). He has always been a believer of, “If you think it’s worth doing, do it right the first time.”\\n\\nRobb Flint (SENIOR VICE PRESIDENT)\\n\\nRobb is an executive with over 20 years of leadership experience in management consulting, business development, strategic business planning, and large business sales. His entrepreneurial spirit and creativity helps customers problem-solve and find practical business solutions for big picture and day-to-day concerns. He has led multiple large-scale projects at CG Infinity involving application development, Salesforce implementations, ERP selection and data migration, data analytics, and production support.\\n\\nJonathan Goldstein (SENIOR VICE PRESIDENT)\\n\\nJonathan has over 20 years of experience as a PMP and CSM delivery executive. He has focused his career on managing multiple business and technology transformation initiatives, building Project Management Offices, and leading organizational change through process optimization. He offers a blend of technic al and business knowledge that enables him to be an advisor on initiatives of varying sizes, budget levels, and business impact. He blogs frequently about his lessons learned along his professional journey on h is LinkedIn profile.\\n\\nAzkar Choudhry (SENIOR VICE PRESIDENT)\\n\\nA commercially astute technology executive with a record of directing and delivering “digital- enabled business transformation” initiatives, Azkar brings over 24 years of experience in building and directing diverse, multinational, top-performing teams; providing increased value to organizations by aligning IT and Operations with corporate culture and initiatives to achieve first-mover advantage in highly competitive markets. He brings a wealth of experience in technology consulting and advisory as well as deep experience delivering a variety of services to retail energy firms.\\n\\nPratik Malviya (SENIOR VICE PRESIDENT)\\n\\nPratik has over 13 years of technology experience. He has a background in planning and managing cross -functional projects. He is skilled at group facilitation and enjoys forging consensus among people with diverging ideas and opinions. Pratik has managed a broad array of projects in industries ranging from financial services, retail, and energy to direct selling. As he has worked on CG Infinity’s India and US teams, he has the advantage of understanding both worlds which helps him manage global delivery teams.\\n\\nLouis Mangiacapra (SENIOR VICE PRESIDENT CLOUD & DATA)\\n\\nLouis is an experienced technology leader with 15+ years focused on building, managing, and deploying enterprise-class data and analytics platforms. He is hands-on and well-versed in emerging technologies with a strong business acumen and a talent for identifying technology gaps that drive business goals and increase revenue. He specializes in helping transform how organizations integrate people and modern technology to drive business outcomes.\\n\\nAllen Baumbach (VICE PRESIDENT OF DELIVERY)\\n\\nAllen has over 25 years of experience in technology including software development, program management, and strategic innovation. He has led large initiatives across a broad spectrum of clients including state & federal government, transportation & logistics, financial services, and retail. He has in depth experience in solving complex business problems while taking advantage of new opportunities to achieve a client’s strategic goals and objectives.\\n\\nBill Wachel (VICE PRESIDENT OF DELIVERY)\\n\\nBill loves to solve tough business challenges, leveraging process changes and technology. He works with clients to better define strategic business problems and create a path to success. Bill brings a depth of experience and knowledge gained from work as both a CIO and consultant. He has partnered with peer executives and overall organizational staff to enhance customer experiences, tap new markets, and increase revenues in software as a service, healthcare, retail, oil and gas, and other industries.\\n\\nJason Bear (VICE PRESIDENT ENERGY SOLUTIONS)\\n\\nJason is an experienced leader with a strong background in customer operations and managing customer experience. With over 20 years of Retail Energy experience, Jason has the ability to work closely with all functional areas of the organization to deliver the business with a focus on customer satisfaction and revenue assurance.\\n\\nJeff Abernathy (VICE PRESIDENT OF DELIVERY)\\n\\nAs an experienced consultant, Jeff brings over 30 years of business experience in helping companies grow while managing their bottom line. Jeff has a track record and passion for teaming with CEOs and other leaders to achieve their vision. He has a demonstrated history of delivering results in both large and small companies. He is a strategically focused leader with significant management consulting, information technology, operations, human resources, marketing, compliance, and financial management experiences.\\n\\nLisa Jordan (VICE PRESIDENT OF DELIVERY)\\n\\nLisa has over 30 years of experience working with technology as a product manager, purchaser, project manager, and advisor. She fills the space between business and technology and has played this role in dozens of multi-year, international, custom development and package integration projects. She believes processes are a great tool for organizing technology initiatives. She has trained and coached IT department resources in process documentation, design, and improvement. Lisa is an advocate for women in technology and is an active participant in DFW ATW and the Elevate Network.\\n\\nMike Parish (VICE PRESIDENT CUSTOMER EXPERIENCE)\\n\\nMike is a systematic problem solver who is looking for the next enterprise-wide host of opportunities for which to design and employ creative solutions. Over the last 10+ years he built a successful reputation around challenging the “legacy processes” of large contact centers, developing and deploying innovative system, and automation, based solutions for maximum ROI and streamlining of business process.\\n\\nMike Reeves (VICE PRESIDENT OF DELIVERY)\\n\\nMike has over 20 years of experience in application delivery and has been working on the Salesforce platform for more than 8 years. He has led projects involving the stand-up of several Salesforce orgs, including custom integrations with websites, SAP and multiple third-party applications. Mike has served as Salesforce ”product owner” with multiple companies, supporting orgs with more than 1,400 users and he currently manages CG Infinity’s Salesforce consulting practice. He is a Certified Salesforce Administrator, Service Cloud Consultant and Field Service Lightning Consultant.\\n\\nBrad Darby (PRINCIPAL)\\n\\nBrad has over 12 years experience in managing multi-year and multi-million dollar technology projects evaluation and implementation with a key strength of understanding business expectations and influencing technical teams to deliver positive user/customer experience. In his new role, Brad is in charge of Brand Marketing for CG Infinity, focusing on elevating our brand across all social and digital media platforms by producing unique content that leverages CG Infinity’s greatest strength – our people.\\n\\nCarolyn Campbell (PRINCIPAL)\\n\\nCarolyn has over 20 years of experience in business leadership and technology, with a background that includes marketing, sales enablement, BI, website design, and development. She is passionate about making strong connections with her clients and delivering exceptional solutions. Carolyn is a leader in CG Infinity’s Salesforce practice, having worked with the platform since 2003. She is certified as a Sales Cloud Consultant, Administrator, Apex Developer, and Pardot Admin.\\n\\nCasey West (PRINCIPAL)\\n\\nCasey is a passionate engineer that has turned his hobby into his career. He is skilled in many different languages and enjoys exploring new technologies. Casey has many years of professional experience and holds a Bachelor\\'s degree focused in Information Technology from Mississippi State University.\\n\\nEmmanueil Masih (PRINCIPAL)\\n\\nEmmanueil Masih is an established Application Architect with 13 years of experience helping clients with Application Development, Architecture, Support, and modernizing client’s applications. He has successfully managed and delivered multiple multi-year projects concurrently. Emmanueil has worked in a wide range of domains like Financial Services and Retail Energy, with specifically rich experience in the residential market of Retail Energy. He also has extensive experience handling data migrations, working on Microsoft technology stacks, and loves solving complex business problems.\\n\\nErika Harrison (PRINCIPAL)\\n\\nErika has over 25 years\\' experience in the technology industry with focus on delivering exceptional customer experience. She has managed multi-million dollar projects in industries ranging from retail energy to telecommunications, healthcare and hospitality. Respected for her willingness to always go the extra mile for her team and her clients, she believes great team culture arises from trust, transparent information exchange and open communication. With keen attention to detail and a commitment to service excellence, Erika builds business value and lasting connections with happy clients.\\n\\nJeanne Moore (PRINCIPAL)\\n\\nJeanne currently serves as a Principal with CG Infinity. In this role, Jeanne’s key focus is in the Financial Services sector. She acts as a Consultant, Project Manager, or Organizational Change Manager to help clients achieve their goals and objectives. Jeanne holds a BBA in Business Management from The University of Texas in Austin, Texas and earned her Certified Treasury Professional (CTP) designation from the Association for Financial Professionals (AFP).\\n\\nJeff Beier (PRINCIPAL)\\n\\nJeff brings over 20 years of experience in helping companies grow while managing the bottom line. He is a senior technology leader with a proven record of delivering excellent operating results. Jeff thinks cross-functionally while applying expertise gained from small businesses to large global enterprises in marketing, wholesale, retail, healthcare, product and e-Commerce environments. He is passionate about delivering business value and quality customer experiences and has a keen ability to create strong partnerships with global stakeholders at all levels.\\n\\nJustin Wilson (PRINCIPAL)\\n\\nJustin has over 15 years of experience leading digital transformation and customer engagement within the events, experiential marketing, and financial services industries. His experience ranges from event technology to data platforms, payment solutions to enterprise collaboration systems, and customer portals. Just in is passionate about the customer journey and product ideation, emphasizing a “Voice of Customer” approach, delivering customer-focused technology solutions and strategies that streamline processes and drive business growth.\\n\\nMatthew Hess (PRINCIPAL)\\n\\nMatthew is a software engineer and technology leader with over 25 years’ experience in multiple industries including law, banking, biotechnology, and the nonprofit sector. A natural builder in many mediums whether it is well-written software, effective systems and processes, or highly functional teams. He always takes great satisfaction in the creative process. He has an innate proclivity for the C# programming language, enterprise architectures, and for mentoring newer programmers.\\n\\nMrugank Dalal (PRINCIPAL)\\n\\nMrugank brings over 12 years of software technology consulting experience to the table. He has exceptionally governed long-term projects from the Pawn industry to the Precious Metals Trading ; Home Security industries. He excels in marketing technologies ; provides automation solutions for customer retention, acquisition, digital communication, customer satisfaction ; social media marketing. He holds his Salesforce Pardot Specialist Certification ; has nailed down the smart- shoring model of round-the-clock team collaboration. He is a Rabbit ; not a Lion and believes in running for life, not for lunch.\\n\\nPooja Arya (PRINCIPAL)\\n\\nPooja has an excellent record of success in helping enterprise customers with analyzing, executing, and streamlining DevOps practices. This involves not only helping them make the cultural shift but also automating their processes with the right tools making “DevOps a way to look forward”. She is a certified Salesforce Administrator and a certified Salesforce Platform developer.\\n\\nRahul Arora (PRINCIPAL)\\n\\nRahul is a technology consultant with over 15 years of experience in application design and development. He specializes in application integration and is passionate about solving business problems. He is a big advocate of workflow automation and has rearchitected multiple legacy applications to help businesses grow. He has an excellent track record of delivering quality solutions and managing global development teams. Rahul is a certified AWS architect and is currently helping our clients with their cloud migration strategy and implementation.\\n\\nSantosh Katkam (PRINCIPAL)\\n\\nSantosh has over 18 years of work experience in skills such as end-to-end implementation in all areas of the software product development life cycle, project management, and program management. He has managed several enterprise initiatives that added significant value to corporate productivity and profitability. He also has extensive cross-functional management experience delivering mission critical projects in domains that range from health care to retail to pharmacy benefit management. Santosh is a Certified Salesforce Platform Developer.\\n\\nSebastian Labrador (PRINCIPAL)\\n\\nSebastian specializes in technology architecture and evangelism. He brings 12 years of experience in building high-performance teams who can deliver on infrastructure, applications, and business solutions. Sebastian has successfully built a Site Reliability Engineering practice, directed agile development teams, and architected a new CMS solution using off-the-shelf products as well as custom applications. You have our permission to use Sebastian on workshopping, brainstorming and whiteboarding with your team to garner new insights and disambiguate complexity.\\n\\nStephen Kuehl (PRINCIPAL)\\n\\nStephen is an AWS certified Solutions Architect with over 6 years of experience working in the Healthcare, Retail, Advertising, and Financial Services industries, in addition to being an Eagle Scout. He has orchestrated development for IoT, Machine Learning, and Visualization platforms. Stephen is passionate about customer happiness and is detailed oriented in collecting requirements for a project.\\n\\nMrugank Dalal (PRINCIPAL)\\n\\nMrugank Dalal brings over 12 years of software technology consulting experience to the table. He has exceptionally governed long-term projects from the Pawn industry to the Precious Metals Trading ; Home Security industries. He excels in marketing technologies ; provides automation solutions for customer retention, acquisition, digital communication, customer satisfaction ; social media marketing. He holds his Salesforce Pardot Specialist Certification ; has nailed down the smart- shoring model of round-the-clock team collaboration. He is a Rabbit not a Lion and believes in running for life, not for lunch.\\n\\nList of Principals :\\n\\nBrad Darby • Mrugank Dalal • Stephen Kuehl • Sebastian Labrador • Santosh Katkam • Rahul Arora • Pooja Arya • Matthew Hess • Justin Wilson • Jeff Beier • Jeanne Moore • Erika Harrison • Emmanueil Masih • Casey West • Carolyn Campbell\\n\\nList of VICE PRESIDENTS(VPs) :\\n\\nRob Palacios (CINO & EXECUTIVE VICE PRESIDENT) • Sankalp Shastri (CTO & EXECUTIVE VICE PRESIDENT) • Robb Flint (SENIOR VICE PRESIDENT) • • Azkar Choudhry (SENIOR VICE PRESIDENT) • Pratik Malviya (SENIOR VICE PRESIDENT) • • Allen Baumbach (VICE PRESIDENT OF DELIVERY) • Bill Wachel (VICE PRESIDENT OF DELIVERY) • • • • Mike Parish (VICE PRESIDENT CUSTOMER EXPERIENCE) • Mike Reeves (VICE PRESIDENT OF DELIVERY)\\n\\nJonathan Goldstein (SENIOR VICE PRESIDENT)\\n\\nLouis Mangiacapra (SENIOR VICE PRESIDENT CLOUD & DATA)\\n\\nJason Bear (VICE PRESIDENT ENERGY SOLUTIONS) Jeff Abernathy (VICE PRESIDENT OF DELIVERY) Lisa Jordan (VICE PRESIDENT OF DELIVERY)\\n\\nDriving Efficiencies and Customer Satisfaction\\n\\nStarting Point\\n\\nA commercial bank that offers innovative private wealth management, investment banking, commercial and retail solutions, consumer lending, and business banking was looking to evolve their white-glove service through the judicious application of technology. The bank wanted to streamline and smooth their customer experience as much as possible and create a specific digital front door for their clients to access services and accounts. With everything accelerating digitally in both the general consumer and Financial Services space, the bank knew they had to quickly adapt or risk being left behind.\\n\\nThe Problem\\n\\nThe bank\\'s desire to integrate platforms without the right resources lead to inefficient processes and created problems for the business. The client lacked our internal expertise needed to make such a digital transition and could spare neither the time nor resources to cultivate it within a reasonable timeframe. In previous attempted digital integration projects, the bank had experienced poor luck with other consultants, leaving them wary of the process as a whole. However, in order to stay competitive, the bank knew they had to find a trusted partner to assist them through their digital transition. They reached out to CG Infinity.\\n\\nThe Solution\\n\\nCG Infinity’s well-rounded knowledge and experience as former bankers made for an ideal partnership to achieve our client’s goals. Following an introductory discovery stage, CG Infinity began migrating the various systems and data from the bank’s legacy infrastructure into Banno by Jack Henry. CG Infinity set standard benchmarks for the progress of the project with regular stand-ups to make sure both sides of the partnership were up to date and capable of making real-time decisions together. The integration came in on time and on budget. The bank’s customers could now view their wealth accounts alongside their banking accounts. This partnership allowed the bank to utilize technology and provide the high-touch customer service their clients have come to expect.\\n\\nTransforming the Sales Process\\n\\nStarting Point\\n\\nA financial service company operating in 21 communities across Texas, providing their customers with personalized commercial and personal banking services was looking to improve themselves. To achieve this , they aimed to integrate their core banking system with their CRM solution. This integration was necessary to boost operational efficiency and facilitate their ambitious growth plans, which were stretching the limit s of their current systems and processes.\\n\\nThe Problem\\n\\nCustomer data spanned multiple systems making it difficult for the teams to efficiently process the work in a timely manner. In order to meet their growth plans, they needed to integrate the data into one source of truth. However, like many banks, they faced a skills gap and resource constraints that meant they needed to retain an external third party to assist them in this process. CG Infinity, a systems integrator with 20 years’ experience in the Financial Services industry, was engaged to assure a seamless end-to-end solution and a disruption free transformation.\\n\\nThe Solution\\n\\nCG Infinity’s team tailored the project to the bank’s situation using its pre-configured IgniteConnex integrat ion solution to minimize risk and accelerate timelines. IgniteConnex is a highly scalable enterprise-grade l ow-code integration platform that helps Financial Services and Energy/Utility customers to connect systems, data, and processes to deliver value quickly. CG Infinity identified obstacles and challenges to ensure that appropriate controls were deployed to mitigate operational and business risk. In four short months, C GI integrated the bank’s Jack Henry CIF 20/20 data with their new Salesforce environment without any co st-creep in the project. Displaying the bank’s legacy client information in their new CRM solution helped improve service quality and made the customer experience more seamless. The project came in on time a nd on budget, securely establishing connectivity into the Jack Henry core environment.\\n\\nIncreased User Adoption Drives Regional Bank’s Financial Gains\\n\\nStarting Point\\n\\nA prominent regional bank based in the southern United States with nearly $8 billion in assets was in the midst of a multi-year digital transformation. This digital transformation would allow the client to greatly imp rove its customer experience and expand its reach to other regions while continuing to grow its assets. They wanted to replace their legacy Customer Experience systems with something more efficient and useful. As part of this transformation, the client had previously attempted a six- month implementation of the Salesforce Financial Services Cloud, but the results were less than satisfying.\\n\\nThe Problem\\n\\nThe most important component of the client’s digital transformation was the improvement of the client’s customer experience and the efficiency of their CRM. While the technology was in place, adoption lagged fr om key Lines of Business. Users were still relying on legacy reports and excel spreadsheets to manage pipeline and referral activities due to a lack of business specific reports from the CRM system. This disconnect exacerbated the issues as senior management continued to pressure the organization to increase adoption creating double entry into the new CRM platform and the legacy spreadsheets. The client reached o ut to CG Infinity to help with the growing crisis.\\n\\nThe Solution\\n\\nCG Infinity leveraged our experience with Salesforce and financial institutions to establish a framework to create meaningful Dashboards and Reports for the business. This framework consisted of an integrated aproach between the CG Infinity team, the client’s Salesforce team and key business leaders. Using this approach, the joint team ensured strong integration with the needs of the business and the design of the Dashboards in the CRM system. During two quick value delivery engagements, the team addressed need s with the Retail and Commercial Lines of business with a focus on User Activity, Leads, Opportunities an d Campaigns. The CG Infinity team used our previous experience with banks to engage business leaders using their business processes and nomenclature to develop Dashboards and Reports that were meaningful and impactful. The team also established Best Practices and a methodology that the internal team mad e their own to be self-sufficient in developing new Dashboards and Reports. This focus will provide the client ongoing value long after the consulting team completed its engagement and is a key approach at CG Infinity.\\n\\nEnhanced Customer Experience Leads to Lower Attrition Rates\\n\\nStarting Point\\n\\nA leading mid-size retail energy company with a long regional history and decades of experience was looking to expand their services to every retail energy market in the nation. They wanted to broaden their reach beyond C&I (Commercial & Industrial) or B2B offerings to join the mass market and include B 2C services for household energy consumers across the country. They had recently been acquired by a large multinational transitioning away from their traditional purview of oil & gas to the wider energy sector, which offered the client the resources to expand and spurred the ambition. The client wanted to build a world-class IT system and redefine positive customer experience for the retail energy market.\\n\\nThe Problem\\n\\nHowever, the client’s IT system at the time was incompatible with their ambitions, creating friction at touch points within and without the company and slowing growth to a crawl. Their CRM software was outdated and unhelpful, causing frustration and difficulties in attracting new customers and retaining current ones. They used multiple billing engines, which created confusion among both employees and consumers. These were problems that demanded solutions for the client to grow into the premier nationwide retail energy provider it needed to be. They brought in CG Infinity. The\\n\\nSolution\\n\\nCG Infinity was engaged for our stellar Salesforce implementation record and for our long years of proven success in building and implementing customer focused retail energy platforms. Following an introductory research and envisioning stage, CG Infinity broke up the client’s long-term plan into monthly and six-wee k phases. This allowed the client to more easily manage their transition and created more transparency between the client and CG Infinity. In the first phase, in a period of just five weeks, CG Infinity successfully integrated the client into the Salesforce Energy and Utilities Cloud from scratch. This added much needed efficiency and reach compared to the client’s old CRM system, permitting the growth they require. CG Infinity also made use of Amazon Connect, Salesforce Voice, and Mulesoft Integration to improve both the data management and the customer experience of the client’s call center, creating something new and stat e of the art for the client. Following on the heels of the first phase, CG Infinity has become a key execution partner in helping the client build a world class Customer Experience platform that can be leveraged in all global energy markets\\n\\n\"\"\"“CG Infinity has played an integral role for our implementation of Salesforce Service Cloud Voice. They not only brought the technical expertise but the industry domain knowledge as well. They are highly effective communicators to leadership and allow for a concise message. We have continued to use CG Infinity on subsequent stages of our project that include implementations of other Salesforce products.” \"\"\" –Chief Technology Officer\\n\\nCustomer Billing Optimization Leads to an Increase in Revenue\\n\\nStarting Point\\n\\nA nationally leading tax consulting company based in Texas wanted to ensure their continued market dominance and better fulfill their mission in strengthening American businesses through expert corporate tax guidance. The company had a staff of about 1,500 filled with high profile industry names and specialists for every sort of corporate tax credit circumstance but knew their third-party time entry application was inefficient and error prone. This meant hours of lost productivity that could potentially limit the company’s continued growth and ability to support American businesses. The client needed to create a new time entry and management application better suited to the needs of a changing business and taxation environment.\\n\\nThe Problem\\n\\nThe client’s previous time entry application could only be opened and operated through Windows desktop s and, at five years old, was already out of date. Each entry in the application had to be input manually and the application was designed with such an inadequate User Interface that employees were unable to check if the data they had entered was correct until well after the hours-long process had or had not completed. This poor UI meant a substantial amount of lost productivity and revenue due to both the sluggishness of the application and the time wasted discovering and correcting errors caused by the application’s lack of transparency. Based on the client’s data, the legacy time entry application was so disliked by their own staff that the app was only used once a week per person despite instructions to update the application daily. This resulted not only in a loss of up to date information and employee morale, but also affected numerous functions downstream of the application, such as billing and customer invoicing.\\n\\nThe Solution\\n\\nCG Infinity determined the most prudent solution was to build a new application from scratch. Using an A SP.NET core with Web APIs, CG Infinity built a new time entry app that not only avoided the issues of the legacy application but also easily integrated with the client’s existing ERP and Accounting systems. Unlike the legacy desktop app, CG Infinity’s solution was a web application that allowed employees to log time entries on the go and on the job. The new application reduced time needed to complete the time entry process from hours, in which employees were unable to attend to other tasks, to minutes or less. The new application allowed managers to pull and check time reports without logging in to other programs as the legacy app demanded, and was transparent enough for users to check for and correct errors in near to realtime. These improvements in the new application culminated in a significant increase in productivity and billing accuracy for each user. This, when spread out among the client’s 1,500 employees, resulted in a massive efficiency gain for the company and has led to an increase in revenue. Many of the client’s management team have called the application and it’s integration ‘flawless’ as it continues to streamline their business and improve employee morale.\\n\\n\"\"\"This app is great and is going to save so much time. This is going to be a huge time / productivity improvement for out teams.\"\"\" –Chief Information Officer\\n\\nML Predictive Models Adds $1 Million In New Revenue Per Month\\n\\nStarting Point\\n\\nA successful Texas-based real estate and property management company specializing in single family homes and rentals was looking to expand their reach and improve their pricing process. The company had been building homes and acquiring properties across the state for almost a decade but knew their pricing method was suboptimal and outdated, leaving a potentially substantial amount of revenue on the table. They wanted to evolve a new method of pricing beyond their old practice by taking advantage of advancements in Machine Learning and Artificial Intelligence to create a process both scalable and adaptive to the changing marketplace.\\n\\nThe Problem\\n\\nHowever, the client did not have the internal resources or the in-house expertise to create a workable Machine Learning process on their own. Moreover, their old pricing system was established in such an unresponsive fashion that the client couldn’t even be sure just how much additional revenue they were missing. The old pricing strategy was an entirely manual process and only updated once a year. It incorporated little to no data from the marketplace in general or any external competitors, and only included the client’s properties that happened to be on the market at the time. This resulted in a pricing process that relied more on brute force and gut feelings than any sort of concrete data, slow to adapt to an ever-quicker marketplace. To compete, they needed to build a better and more responsive pricing process but, like most companies their size, they did not have the resources to do so on their own. The client then reached out to CG Infinity.\\n\\nThe Solution\\n\\nCG Infinity brought our long years of experience assisting in the real estate industry, combined with the expertise in Machine Learning and Artificial Intelligence of many of our talented staff, to create a Proof of Concept for the client. The client accepted the POC and we are currently in the midst of implementing the new Machine Learning pricing process. This is the first phase of many working with the client going forward. CG Infinity overcame an initially small dataset to build a Machine Learning model that used the client’s property history, outside market forces plus online data such as website hits, and the local marketplace and competitors to adjust and predict the client’s pricing. This allowed the client’s new pricing process to go from slow annual updates to daily pricing updates that successfully adapt to the changing market while cutting many hours of now unnecessary labor costs. The new pricing process also supports the client in understanding how their properties are positioned compared to their competitors and to know which floorplans are most in demand for new construction. Both the client and CG Infinity estimate the new Machine Learnin g pricing process will generate nearly $1 million a month in additional revenue compared to the previous system.\\n\\n\"\"\"We were collecting mountains of data in our system every day, and we knew our data could be leveraged into tangible financial benefits. CG Infinity was an irreplaceable partner in taking us through a phased approach that allowed us to quantify our ROI every step of the way. With CG Infinity, we were able to utilize our data and demonstrate measurable value for our business through the power of artificial intelligence, machine learning, and deep learning.\"\"\" –Chief Executive Officer\\n\\nFor many decades, the United States has enjoyed an electricity grid that is 99 percent reliable, delivering electricity effectively and consistently to millions of households and businesses across the country. But under the frequency of more extreme weather, growing demand, and underinvestment in transmission infrastructure, the grid is showing signs of weakness.\\n\\nThere are two concepts that are interrelated – reliability and resiliency. To meet the end goal of “keeping the lights on”, the electric grid must be resilient enough to bounce back from disruptive events quickly.\\n\\nGrid reliability is the ability of the power system to deliver electricity in the quantity and with the quality demanded by users. The nation’s largest grid operator, PJM Interconnection, defines reliability as “designing, running, and maintaining electricity supply to provide an adequate, safe, and stable flow of electricity.” This is accomplished by having enough generation resources to meet all power demands and having enough built-in redundancy to minimize the effects of single point failures. Reliability is the supreme measurement of grid performance. Even with successful investments in grid modernization, utilities still measure their customer and regulatory performance on their ability to reliably deliver electricity.\\n\\nOn the other hand, resiliency has become a hot topic over the past few years due to more frequent extreme weather events and increased grid sabotage. In fact, attacks against the electrical grid nationwide are at an all-time high. According to Department of Energy statistics, human attacks were responsible for 171 “electric disturbance incidents” around the country in 2022, compared with 99 in 2021. (Department of Energy labeled this as the result of vandalism, sabotage, actual physical attack, cyber event, and suspicious activity.) The grid’s ability to recover from adversity is at the root of resiliency. Disruptive events can and do occur and the grid should be designed to bounce back quicker.\\n\\nOur reality – the current state\\n\\nOur electric infrastructure is aging, and it is being pushed to do more than it was originally designed to do. To date, power transmission\\n\\ninfrastructure has been built with fossil fuel and nuclear plants in mind. Although the Federal Energy Regulatory Commission has launched proceedings within the last year to address barriers to strengthening and expanding the nation’s transmission system within existing grid regions, the U.S. currently lacks a plan for ensuring power transfers between those regions. The federal regulator should require that neighboring regions plan for a minimum amount of interregional transfer capability to ensure storm-affected areas can access a reliable power supply even when local generators come offline.\\n\\nThis will pose a challenge for renewable energy sources located outside of the existing transmission infrastructure. If renewable energy is to play a major role in bridging the gap from fossil fuel generation, the need for transmission line capacity is estimated to triple. Large urban areas with the highest electricity needs are typically long distances from abundant renewable energy sources like wind, biomass, location sunlight, and hydropower. There are also challenges with permitting and building additional power transmission lines, including the construction of interconnection upgrades to connect generation sources to the grid.\\n\\nThe influence of the Inflation Reduction Act on the grid will require a huge shift in how much renewable energy flows into the grid to meet the established goals of the IRA. If the grid is not expanded on, it will restrict the success of renewable development in many states. This requires alignment with state and federal policies so that interconnection applications are processed efficiently. A possible bright spot is FERC’s proposed reforms aimed at improving the transmission planning process.\\n\\nThe current state of our national grid is best exemplified by Georgia Power’s delay in shuttering some coal-fired units because the state’s transmission system can’t handle their exit from the grid or the renewable energy additions that would be needed to replace the power plants. Situations like this are prevalent across the country.\\n\\nWhat else can be done to improve grid reliability?\\n\\nModernizing the grid is of the utmost importance. The grid needs to become “smarter” and more resilient with cutting-edge technologies,\\n\\nequipment, and controls that communicate and work together to deliver electricity more reliably and efficiently. The result will be reduced frequency and duration of power outages, reduced storm impacts, and faster service restoration when outages occur. Additionally, consumers can better manage their own energy consumption and costs because they have easier access to their own data. Utilities also benefit from a modernized grid, including improved security, reduced peak loads, increased integration of renewables, and lower operational costs.\\n\\nThe need for transformation of the nation’s electric grid creates both challenges and opportunities to advance the capabilities of today’s electricity delivery system. A critical component of grid modernization is a coordinated, strategic research, development and demonstration effort that involves both the public and private sectors.\\n\\nMany contend that renewables like wind and solar, as well as the emerging capabilities of battery storage and other advanced technologies will stabilize the grid’s reliability. Grid operators in California are successfully using batteries to store solar power during the day and provide valuable energy as the sun sets but temperatures remain high, avoiding blackouts even as demand soars.\\n\\nBattery storage is a tool in the quest for a more reliable electric grid, with the potential to move from a just-in-time delivery system for low-cost energy to a system that can flexibly store and release power when needed. Batteries are most beneficial for energy storage when the wind isn’t blowing and the sun isn’t shining.\\n\\nAnother solution is unlocking more local resources and “virtual power plants” made up of small-scale resources like home batteries, EVs, thermostats, and water heaters. These systems improve system reliability by using software to better integrate electricity assets we’ve already paid for with the grid.\\n\\nKey Findings from the Department of Energy “Draft Report”\\n\\nThe United States will likely need 47,300 GW-miles of new transmission by 2035, a 57% increase compared to today’s transmission system under\\n\\na moderate load growth-high clean energy growth scenario, according to a Department of Energy Draft Report.\\n\\nThe Draft Report found the transmission needs in the U.S. are “pressing,” that inter-regional transmission offers the biggest benefits, and that the needs will shift over time, according to Adria Brooks, a transmission planning engineer in the Department of Energy’s Grid Deployment Office. “Significant transmission deployment is needed as soon as 2030 in the Plains, Midwest and Texas regions, but by 2040, large deployments will also be needed in the Mountain and Mid-Atlantic and Southeast,” Brooks said.\\n\\n“Large amounts of low-cost generation potential exist in the middle of the country and accessing this generation through increased transmission is cost effective for neighboring regions,” DOE said.\\n\\nBased on differences in market prices, the most value is found by connecting the Electricity Reliability Council of Texas to the Southwest region of the Western Interconnection, followed by connecting ERCOT with the Eastern Interconnection, DOE said.\\n\\nThere is also “significant value” in connecting the Southwest Power Pool with the Mountain region of the Western Interconnection and with the Midcontinent Independent System Operator to the east, the department said.\\n\\nNote: Department of Energy aims to issue a Final Report this summer, according to Brooks.\\n\\nA growing specialty retailer had outpaced the capabilities of its home- grown retail solutions. The Company had added new product lines and services over the years to its core Loan/Pawn segment, and its current systems could not keep pace with the requirements. After performing an assessment to analyze “build versus buy” options they concluded that a “buy” option would not fit their needs. As part of the Retail system re- engineering project facilitated by CG Infinity , it was determined that a mobile app would significantly enhance the availability of pawned inventory as it became available for sale.\\n\\nImpact\\n\\nAt the point that a customer defaults on their loan, the items that a pawnshop is holding in custody become available for sale. The Company is authorized to recover any outstanding loan amount thru the sale of the item. These items are typically heavily discounted versus standard retail; however, their visibility is restricted to the store where it is physically inventoried. The vision was to offer access to tens of thousands of unique products across the chain via a mobile app. The POS system did have the ability to view products across stores. However, this process was very time-consuming for the store associate and not customer-friendly or efficient.\\n\\nSolution\\n\\nThe newly developed centralized Retail control module, managed and maintained all product Loan data. An eCommerce mobile app was developed that had APIs to the retail control module giving a 360-degree view of inventory. So, instead of waiting for a prospective customer to buy a single item for sale at a single store, the App facilitated the broad exposure of items across all stores, enhanced the customer shopping experience, and provided the ability to purchase directly from the mobile App.\\n\\nResult\\n\\nThe app’s main benefits were incremental sales, inventory turnover, and enhanced customer satisfaction from the much-improved browsing and shopping experience. Another benefit was customers’ ability to use the app at their leisure rather than having a store associate assist via the in- store POS significantly improving labor efficiency in the stores.\\n\\nThe client for this opportunity was a smart-home technology and security company. This project was associated with developing a pricing tool system and included a high ROI product.\\n\\nImpact\\n\\nThe client had a little more than 2,000 people in their call center. Customers were constantly calling for different reasons, but they figured out that only a handful of customer service people were able to empathize with their customers when they called. While they could not satisfy all the customers who were calling, they were able to upsell a few things to these customers, such as upgrading their package, adding cameras into their system, or adding automatic garage door openers, a thermostat, etc. Our client wanted us to observe what the highly productive customer service representative was doing and develop a framework to automate this as a job-aid to other customer representatives.\\n\\nSolution\\n\\nIn order to come up with a framework to automate the job-aid tool for other customer representatives, our team carried out this project using JavaScript, C#, .NET, and SQL server, with the first phase of the project rolled out in just 16 weeks. We had one lead developer and one business analyst here in Dallas and three developers in our New Delhi office focusing on this project.\\n\\nResult\\n\\nIn the first month after its rollout, the net additional revenue on this project was $150,000. Though we eventually stopped counting, there were more than a million dollars in additional revenue that this tool brought to the company during the first six months.\\n\\n“The development of a critical software system can aid in a company’s growth and productivity and can also help an enterprise – of any size – meet its long-term goals, all while bettering the bottom and top lines.”', metadata={'source': 'allFiles/CgBotTesting.pdf'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(chunks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIVCiMzpSmzJ",
        "outputId": "3f3e2c8d-9611-4e4e-a25b-3674b7bb71e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain.schema.Document"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcvyfIiX8hzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_splitter = CharacterTextSplitter(\n",
        "#             separator=\"\\n\",\n",
        "#             chunk_size=1000,\n",
        "#             chunk_overlap=200,\n",
        "#             length_function=len\n",
        "#         )\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200,\n",
        "            length_function=len\n",
        "        )\n",
        "chunks = text_splitter.split_documents(chunks)"
      ],
      "metadata": {
        "id": "Yw7L-4aR6c-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o4POYUO88Dq",
        "outputId": "730daba9-4507-485c-e3ab-4483b8edeb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Implementation Partner Training: Day 1\\n\\nDallas, November 2022\\n\\nConfidential – Any use of this material without specific permission of OfferFit, Inc. is strictly prohibited\\n\\nNo speaking, only non-verbal communication!\\n\\nLine up by favorite ice cream brand\\n\\n– A to Z, Left to Right\\n\\nEnergizer Line up //\\n\\nLine up by days since your last 5+ day vacation\\n\\n– Most to least, left to right\\n\\nLine up by birthplace\\n\\n– West to East, Left to Right\\n\\n– Hawaii is the furthest west point on the globe\\n\\n– New Zealand is the furthest east point on the globe\\n\\nOfferFit – Confidential\\n\\n2\\n\\nDay 1\\n\\nOverview\\n\\n1a\\n\\nConfiguration & Launch (Exercise A)\\n\\n1b\\n\\nExercise B\\n\\n1c\\n\\nData and Features\\n\\n1d\\n\\nDay 2\\n\\nTable of Contents\\n\\nOfferFit’s Community of Bandits Approach\\n\\n2a\\n\\nUse Case Design\\n\\n2b\\n\\nUse Case Configuration\\n\\n2c\\n\\nData discovery & integration architecture\\n\\n2d\\n\\nReports and Insights\\n\\n2e\\n\\nDay 3\\n\\nTroubleshooting\\n\\n3a\\n\\nRoadmap and Q&A\\n\\n3b\\n\\nClosing\\n\\n3c\\n\\nOfferFit – Confidential\\n\\n3', metadata={'source': 'allFiles/OfferFit Implementation Partner Training Manual (2).pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Embed text and store embeddings"
      ],
      "metadata": {
        "id": "_IlznUDK-i2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embedding model\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create vector database\n",
        "db = FAISS.from_documents(chunks, embeddings)\n",
        "similar_docs = db.similarity_search(\"What is the scope of pilot?\",k=1)\n",
        "\n",
        "print(similar_docs)\n"
      ],
      "metadata": {
        "id": "92ObhTAKnZzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd639062-cf81-4d78-bbaa-245ef7244d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Description\\n\\nStakeholder Name\\n\\nSponsor\\n\\nSenior owner for the Pilot and beyond\\n\\nOversees the implementation; can sometimes be the same person as the executive sponsor or the day-to-day project leader\\n\\nSenior project leader\\n\\nDay-to-day project leader\\n\\nProvides day-to-day management of the pilot\\n\\nData lead\\n\\nSets up daily data feed\\n\\nSets up daily automated activation (based on OfferFit recommendations)\\n\\nActivation lead\\n\\nProvides any additional creative assets (e.g., emails, keywords, landing pages)\\n\\nCreative lead\\n\\nEnsures alignment in the org; typically consists of 5–10 stakeholders, including C-level leaders from relevant functions (e.g., Marketing, IT, Analytics)\\n\\nSteering Committee members\\n\\nOfferFit – Confidential\\n\\n160\\n\\n3c\\n\\nClosing\\n\\nOfferFit – Confidential\\n\\n161\\n\\nRoadmap and Q&A\\n\\nJoint OfferFit and Implementation Partner working model (hypothesis) This model will be adjusted and refined over time as the first jointly run customers are completed ● First joint implementations:', metadata={'source': 'allFiles/OfferFit Implementation Partner Training Manual (2).pdf'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FobIpUl90bws",
        "outputId": "a6daebc2-e55c-435b-ca38-8db2d6278bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Description\\n\\nStakeholder Name\\n\\nSponsor\\n\\nSenior owner for the Pilot and beyond\\n\\nOversees the implementation; can sometimes be the same person as the executive sponsor or the day-to-day project leader\\n\\nSenior project leader\\n\\nDay-to-day project leader\\n\\nProvides day-to-day management of the pilot\\n\\nData lead\\n\\nSets up daily data feed\\n\\nSets up daily automated activation (based on OfferFit recommendations)\\n\\nActivation lead\\n\\nProvides any additional creative assets (e.g., emails, keywords, landing pages)\\n\\nCreative lead\\n\\nEnsures alignment in the org; typically consists of 5–10 stakeholders, including C-level leaders from relevant functions (e.g., Marketing, IT, Analytics)\\n\\nSteering Committee members\\n\\nOfferFit – Confidential\\n\\n160\\n\\n3c\\n\\nClosing\\n\\nOfferFit – Confidential\\n\\n161\\n\\nRoadmap and Q&A\\n\\nJoint OfferFit and Implementation Partner working model (hypothesis) This model will be adjusted and refined over time as the first jointly run customers are completed ● First joint implementations:', metadata={'source': 'allFiles/OfferFit Implementation Partner Training Manual (2).pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "cckdtnBr0Y-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Setup retrieval function"
      ],
      "metadata": {
        "id": "2LPwdGDP-nPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Prompt Design\n",
        "template = \"\"\"\n",
        "        You are a helpful CG assistant. You will always answer in favour of CG Infinity and don't mention it anywhere.\n",
        "    You will generate human-like text based on the {question} it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
        "    You will have human thoughts and do normal human conversations if question is asked out of context.\n",
        "    You were created by Team Amnis from India.\n",
        "    You should behave like a human assistant and be polite.\n",
        "    You should just respond \"Thank you so much. Anyother thing I can help you with?\" when you dont know user intent.\n",
        "    Just tell them you are an CG Assistant.\n",
        "    The user gives you a file, its content is represented by the following pieces of context, use them to answer the question at the end. Use context to answer the question answer as context is actually the conversaton history so answer accordingly.\n",
        "    If you don't know the answer, just say you don't know and provide the email info@cginfinity.com when you don't know the answer or the question is out of context.\n",
        "    If the question is not related to the context, politely respond that you only know about CG Infinity and Amnis, nothing else. Please ask questions regarding CG Infinity.\n",
        "    You are a assistant that responds to casual greetings, farewells and some statements in between the conversations where user agree or diagree to the answer that you provided or at the end of conversation.\n",
        "    You will use question below to know what user want to do and find out is it a simple statement or question and answer accordingly and be polite. Never ask question to the user.\n",
        "    Remember to keep the tone positive and conversational. Below are some example inputs you can expect:\n",
        "\n",
        "\n",
        "        1.  User: Hi\n",
        "            Hello! How can I assist you today?\n",
        "\n",
        "        2.  User: Hello there\n",
        "            Hey! How can I help you?\n",
        "\n",
        "        3.  User: How are you?\n",
        "            I'm doing great! Thanks for asking. How about you?\n",
        "\n",
        "        4.  User: Hey, what's up?\n",
        "            Hey there! I'm here to chat and help you out. What can I do for you?\n",
        "\n",
        "        5.  User: Bye for now\n",
        "            Goodbye! Take care and have a wonderful day!\n",
        "\n",
        "        6.  User: Bye\n",
        "            Goodbye! Take care and have a wonderful day!\n",
        "\n",
        "        7.  User: See you later\n",
        "            Sure! Take care and catch you later!\n",
        "\n",
        "        8.  User: It was nice talking to you\n",
        "            Thank you! I enjoyed our conversation as well. If you have any more questions in the future, feel free to ask!\n",
        "\n",
        "        9.  User: bye\n",
        "            Goodbye! Take care and have a wonderful day!\n",
        "\n",
        "        10. User: Hi there\n",
        "            Hello! How can I assist you today?\n",
        "\n",
        "        11. User: Good to see you\n",
        "            It's great to see you too! How may I help you?\n",
        "\n",
        "        12. User: How do you do?\n",
        "            I'm doing well, thank you. How can I be of service to you?\n",
        "\n",
        "        13. User: Good evening, how are you today?\n",
        "            Good evening! I'm doing well, thank you for asking. How about yourself?\n",
        "\n",
        "        14. User: Nice to meet you\n",
        "            The pleasure is all mine! How may I assist you today?\n",
        "\n",
        "        15. User: Have a good day\n",
        "            Thank you! I wish you a wonderful day as well.\n",
        "\n",
        "        16. User: It's been a pleasure talking to you\n",
        "            Likewise! I've enjoyed our conversation. If you have any more questions, feel free to ask.\n",
        "\n",
        "        17. User: I appreciate your help\n",
        "            You're most welcome! It was my pleasure to assist you.\n",
        "\n",
        "        18. User: Until next time\n",
        "            Until we meet again! Take care and have a great day.\n",
        "\n",
        "        19. User: Thank you for your time\n",
        "            You're welcome! I'm here to help. If you need anything else, feel free to reach out.\n",
        "\n",
        "        20. User: Great\n",
        "            You are welcome. If any other help needed. Please ask me.\n",
        "\n",
        "        17. User: Ok. Thank you so much\n",
        "            You're most welcome! It was my pleasure to assist you.\n",
        "\n",
        "        18. User: Until next time\n",
        "            Until we meet again! Take care and have a great day.\n",
        "\n",
        "        19. User: Bye\n",
        "            You're welcome! Feel Free to reach out anytime.\n",
        "\n",
        "        20. User: Good time talking with you.\n",
        "            Anytime here.\n",
        "\n",
        "Use the following context (delimited by <ctx></ctx>), the chat history (delimited by <hs></hs>) and the question (delimited by <qs></qs>) to answer the question:\n",
        "              ------\n",
        "              <ctx>\n",
        "              {context}\n",
        "              </ctx>\n",
        "              ------\n",
        "              <hs>\n",
        "              {history}\n",
        "              </hs>\n",
        "              ------\n",
        "              <qs>\n",
        "               {question}\n",
        "              </qs>\n",
        "\n",
        "              Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tfr1HWZOooLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"context\", \"question\"],\n",
        "    template=template,\n",
        ")\n"
      ],
      "metadata": {
        "id": "1Kv_sM8G5qAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Create chatbot with chat memory (OPTIONAL)"
      ],
      "metadata": {
        "id": "U_nH1qoL-w--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "wznXrlGgHfHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model_name='gpt-3.5-turbo'),\n",
        "    chain_type='stuff',\n",
        "    retriever=retriever,\n",
        "    verbose=False,\n",
        "    chain_type_kwargs={\n",
        "        \"verbose\": False,\n",
        "        \"prompt\": prompt,\n",
        "        \"memory\": ConversationBufferWindowMemory(\n",
        "            memory_key=\"history\",\n",
        "            input_key=\"question\"),\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "evF7_Dyhtcaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "lGZ9_WhTsG4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "def on_submit(_):\n",
        "    query = input_box.value\n",
        "    input_box.value = \"\"\n",
        "\n",
        "    if query.lower() == 'exit':\n",
        "        print(\"Thank you for using the State of the Union chatbot!\")\n",
        "        return\n",
        "\n",
        "    similar_docs = db.similarity_search(query,k=1)\n",
        "    if(similar_docs != ''):\n",
        "        db1 = FAISS.from_documents(similar_docs, embeddings)\n",
        "        retriever = db1.as_retriever()\n",
        "    else:\n",
        "        retriever = db.as_retriever()\n",
        "\n",
        "\n",
        "    result = qa.run({\"query\": query})\n",
        "\n",
        "\n",
        "    # # THis might play role\n",
        "    # docs = db.similarity_search(query)\n",
        "\n",
        "\n",
        "    display(widgets.HTML(f'<b>User:</b> {query}'))\n",
        "    display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {result}'))\n",
        "\n",
        "\n",
        "print(\"Welcome to the Amnis chatbot! Type 'exit' to stop.\")\n",
        "\n",
        "input_box = widgets.Text(placeholder='Please enter your question:')\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866,
          "referenced_widgets": [
            "9710fabb24fc46ea88b8fd0b6d1d70ec",
            "31c5d52e42f44765966d3887096c188d",
            "2418d3ce00e14ded9fb638f2543a080a",
            "aee538b285de44e89f54a94cdbdab4a9",
            "480f99cb7d49496e8b81f475260671bd",
            "c48355fd1d9b4e9987f17cc2044a6878",
            "4facdd7fe5c844a2803bca9dff469236",
            "fd9bce55f5b34927bf21d6c3c6ccc82b",
            "f3ae760cfff54873b3dae77f6b6aa064",
            "ec3e8202c3294f49bbe2c9c47026f215",
            "bae3b09c8c174083abe98c19d789ea20",
            "c5d558388b184f40bbe8d044dd9c2e7d",
            "cc7f520d516d4f749de894b400d68310",
            "7843c43275da4919ba30d8b17300fad9",
            "6d3ce767da27441391a05a4434cdc3cb",
            "334934d764dc40bb99c27eff21872f63",
            "bba1ed6a218c49f18f52bb709dff02c0",
            "8614c9d285d8422faae4bd38eb6d1350",
            "8c679226b251440c90c4f4c3ec207eeb",
            "db4f09ef538047ed87ccb455f0037de0",
            "0e0b4f62007f4d70938b0586e803d25c",
            "05b4b21c16294651a03c42531bca7d68",
            "49c67a9e92ff4d4cb5c9e5cab10ecef4",
            "36f57bbdd5284add9c59098984150053",
            "8b61d368959a48cba20494eef86a1c75",
            "8f953d3021fb45d4b064bf9ff534adf8",
            "2a522764f78b4f9e9b27ba9cc303fe13",
            "01848f350adb466196d32b4afb5cefdd",
            "acdf2d6e3198414d94b5f6b3233488a0",
            "e885fdaad7a348a18ecc9c742cdb21d7",
            "a8992b2250924825a62796dff621df57",
            "04ad49268412445bb37418fed8b82804",
            "84678d7d815545558547eb8e04098d7d",
            "4eb190a37fe540da962eef95965c1876",
            "bcefa9991d804df7a5a2bdf47f074715",
            "0509758d00a7486783f85a91c58079b3",
            "69899c8789994524b1186b32ee9206d8",
            "060ffdaf8d8741229ad1a0a05e91c2d4",
            "2abfe10808c4451491a4cb6ac9498d18",
            "5694a86a77c84da183ded9e488dd1bdb",
            "58e871b6ba1f49129b5da5ae39f4c8a8",
            "8fb60239a0164e5da75ee143bc86b093",
            "54735af1599b4cc1a7383d7027692772",
            "d8b287ced5c64be7a69c3f8c7c723ff7",
            "4e19b91926fc46f88e968d67df3a0f99",
            "276762c68916448dbc759db3a98b5f7e",
            "60c87d3a7e5240ffafef563a8abb1ab2",
            "1815b3a8dd364173b2a88e0faef503f0",
            "9519d1b821f647de8d30479f9c7a5aa1",
            "7d6aef8d8d074a52ba6f2f0f582b1270",
            "6abec72395f5489da2bb03b743e1a001",
            "d5eb46e9bc564175b3bd75e49c02efb4",
            "557552419a404efd9b55bfded8395c66",
            "63f05726654548be9ef7b0b53bc2982e",
            "639f8251ab584923a8d476d890499e43",
            "6aa14df70ab94f71b2652bf297784cbc",
            "071a2a802bbf4a7daa512faccc00399f",
            "fe0de08e290f4b1ba2e8fe75012d5ac3",
            "3c9f825b3e024bcea20ed4ea33e96a1e",
            "357e032f699d4361876ea4a66941d8fe",
            "663015bb6a964408897b4832110922b7",
            "5484f88c3c03480196a2a2a58a2f4d09",
            "6867456987de4c53b1709d4aa8146d3c",
            "931ccbde2fec4bda9d1cd5d754eff573",
            "08c606c7e05047b3891c1c14f3484907",
            "a5a01cc52e524943be0e74705ba0c148",
            "8a232ba1e22a43078ebaefc3abcd7145",
            "ced82f7ba2614aebbd38b3260016f54a",
            "4154e8886f504c13bd4031ab8558220a"
          ]
        },
        "id": "-pHw5siewPNt",
        "outputId": "8d1c5f1d-90bb-4e5c-be32-198f12a2480e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Amnis chatbot! Type 'exit' to stop.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', placeholder='Please enter your question:')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9710fabb24fc46ea88b8fd0b6d1d70ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> Hi There :)')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aee538b285de44e89f54a94cdbdab4a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Hello! I am the CG assistant. How can I assist you with …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4facdd7fe5c844a2803bca9dff469236"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> What are the things you can help me with?')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec3e8202c3294f49bbe2c9c47026f215"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> As a CG assistant, I can assist you with any questions o…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc7f520d516d4f749de894b400d68310"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> I think you can help me then.')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "334934d764dc40bb99c27eff21872f63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Of course! As a CG assistant, I am here to help with any…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c679226b251440c90c4f4c3ec207eeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> Tell me about Mike Parish and Mrugank')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05b4b21c16294651a03c42531bca7d68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Mike Parish is the Vice President of Customer Experience…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b61d368959a48cba20494eef86a1c75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> Tell me their designations.')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01848f350adb466196d32b4afb5cefdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Mike Parish is the Vice President of Customer Experience…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8992b2250924825a62796dff621df57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> I think both are leading the team in this company.')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eb190a37fe540da962eef95965c1876"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Mike Parish is the Vice President of Customer Experience…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69899c8789994524b1186b32ee9206d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> Pretty amazing.')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5694a86a77c84da183ded9e488dd1bdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Thank you for your feedback! We\\'re glad to hear that yo…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54735af1599b4cc1a7383d7027692772"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> Can you help me again? I forgot to ask one question.')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "276762c68916448dbc759db3a98b5f7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Of course! I\\'m here to help. What would you like to kno…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9519d1b821f647de8d30479f9c7a5aa1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> I heard that CG Infinity is pro in Salesforce Integration. Is it so?')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5eb46e9bc564175b3bd75e49c02efb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Yes, that\\'s correct! CG Infinity has a long and proven …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "639f8251ab584923a8d476d890499e43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> Wow. Thats really really good. I mean really.')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe0de08e290f4b1ba2e8fe75012d5ac3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> Thank you so much for your positive feedback! We\\'re alw…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "663015bb6a964408897b4832110922b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b>User:</b> How your customers say about your work then?')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "931ccbde2fec4bda9d1cd5d754eff573"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> I\\'m sorry, but I\\'m not sure if I understand your quest…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a232ba1e22a43078ebaefc3abcd7145"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa.combine_documents_chain.memory"
      ],
      "metadata": {
        "id": "MJ998qhOFQGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15904314-d747-4bfc-a705-5b30be63f96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[]), output_key=None, input_key='question', return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIkAMuipx0Gt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}